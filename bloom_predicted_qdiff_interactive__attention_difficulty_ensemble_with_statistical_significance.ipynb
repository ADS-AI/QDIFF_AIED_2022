{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"bloom_predicted_qdiff_interactive__attention_difficulty_ensemble_with_statistical_significance.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"widgets":{"application/vnd.jupyter.widget-state+json":{"bde76eeed0e74265ae3fa11223645ad5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_03d5cac2b7fd49cb81f7e27528f7b457","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7377f316b2514b29b5385a4d3d167649","IPY_MODEL_905274be8581474e8f6a93d187912182","IPY_MODEL_fbc384945bdf4693813ffaaab4242b90"]}},"03d5cac2b7fd49cb81f7e27528f7b457":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7377f316b2514b29b5385a4d3d167649":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_981dfb57b349430ca7b12eeb626904b8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_da6d0486cd98403786a8c8e98e24c6f5"}},"905274be8581474e8f6a93d187912182":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8b9cc9afedea4c129fd52a04b80309f6","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_23dd892465d74cafa0a27aa884a97ed5"}},"fbc384945bdf4693813ffaaab4242b90":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e81367b790e14660bbf59971926f6bd3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 1.63MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ec6cb9e20be044de9aa1612dc3cc0202"}},"981dfb57b349430ca7b12eeb626904b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"da6d0486cd98403786a8c8e98e24c6f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8b9cc9afedea4c129fd52a04b80309f6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"23dd892465d74cafa0a27aa884a97ed5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e81367b790e14660bbf59971926f6bd3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ec6cb9e20be044de9aa1612dc3cc0202":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a1282cb64c6f4d8c827734e9890a1b32":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e3e7e59682854c2880aaf7dc49ebdf20","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c1d9a51a16fa4028b14a69170d592df1","IPY_MODEL_22ccf0234532411d92f5a46233162407","IPY_MODEL_90c9c928619242b2adf95df7872a18d4"]}},"e3e7e59682854c2880aaf7dc49ebdf20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c1d9a51a16fa4028b14a69170d592df1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_11ba5c504e304b2f9ceefa258e79ee7e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_61ed2402da334adf8dd644bd7da14f1a"}},"22ccf0234532411d92f5a46233162407":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_19aeac66ae9b470fa171be5b0f09e94b","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_af5d7ac69e3c44aaa0d783fcb3c8538b"}},"90c9c928619242b2adf95df7872a18d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_38eeac47c86a4496b5b26323ed4d68b6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:00&lt;00:00, 11.9kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_274dd46a471945bba696ae3a397f618f"}},"11ba5c504e304b2f9ceefa258e79ee7e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"61ed2402da334adf8dd644bd7da14f1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"19aeac66ae9b470fa171be5b0f09e94b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"af5d7ac69e3c44aaa0d783fcb3c8538b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"38eeac47c86a4496b5b26323ed4d68b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"274dd46a471945bba696ae3a397f618f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1295c91918b845a88a2ce70e4fceff2f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f950b3eed3a34da4bf605b2435a0bb04","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_05f2e725fe1d47429421976390a0c7e7","IPY_MODEL_13d3566026bf49d9a0995a9002d32ada","IPY_MODEL_29520efc30524df78ffd449fe943ec4a"]}},"f950b3eed3a34da4bf605b2435a0bb04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"05f2e725fe1d47429421976390a0c7e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2deb4f10f927424ea334890c7872f204","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9eb1a756ac4e4ceda13db1cab4e04a48"}},"13d3566026bf49d9a0995a9002d32ada":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8896a7b161cd417d8d3db99228b6bba4","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ea758d7070cc4a7881c0e74fce39ba38"}},"29520efc30524df78ffd449fe943ec4a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9e36610fe72142f6b9ece0e1fc53a85c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [00:39&lt;00:00, 15.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3eb02f086a0e46cd8aeb215f3ce8f9d3"}},"2deb4f10f927424ea334890c7872f204":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9eb1a756ac4e4ceda13db1cab4e04a48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8896a7b161cd417d8d3db99228b6bba4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ea758d7070cc4a7881c0e74fce39ba38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9e36610fe72142f6b9ece0e1fc53a85c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3eb02f086a0e46cd8aeb215f3ce8f9d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"sR9av2JU3kf6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"49cae1fd-9f3b-4e0b-e2a1-fdfe4598f56b","executionInfo":{"status":"ok","timestamp":1643563840760,"user_tz":-330,"elapsed":6544,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","import torch\n","import logging\n","logging.basicConfig(level=logging.ERROR)\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla K80\n"]}]},{"cell_type":"code","metadata":{"id":"zXHEZXXXIrDD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"942adfdf-7b80-4d55-dc7f-f66300176a8b","executionInfo":{"status":"ok","timestamp":1643563847337,"user_tz":-330,"elapsed":4643,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["!pip install torchtext==0.3.1"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchtext==0.3.1\n","  Downloading torchtext-0.3.1-py3-none-any.whl (62 kB)\n","\u001b[?25l\r\u001b[K     |█████▎                          | 10 kB 15.4 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 20 kB 21.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 30 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 40 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 51 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 61 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 62 kB 840 kB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.3.1) (1.10.0+cu111)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.3.1) (4.62.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.3.1) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.3.1) (1.19.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.3.1) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.3.1) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.3.1) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.3.1) (2021.10.8)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.3.1) (3.10.0.2)\n","Installing collected packages: torchtext\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.11.0\n","    Uninstalling torchtext-0.11.0:\n","      Successfully uninstalled torchtext-0.11.0\n","Successfully installed torchtext-0.3.1\n"]}]},{"cell_type":"code","metadata":{"id":"ATfPIQGkqp_u","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d4001180-b429-4417-9969-3d340b8f5067","executionInfo":{"status":"ok","timestamp":1643563873573,"user_tz":-330,"elapsed":24331,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"BzKeqoCs3kgA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c891d2ff-0d5f-454a-993b-43141a9abf1a","executionInfo":{"status":"ok","timestamp":1643563879152,"user_tz":-330,"elapsed":5585,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["\n","!pip install transformers==3.2.0"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers==3.2.0\n","  Downloading transformers-3.2.0-py3-none-any.whl (1.0 MB)\n","\u001b[?25l\r\u001b[K     |▎                               | 10 kB 18.9 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 20.1 MB/s eta 0:00:01\r\u001b[K     |█                               | 30 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██                              | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 276 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 286 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 296 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 307 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 317 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 327 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 337 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 348 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 358 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 368 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 378 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 389 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 399 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 409 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 419 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 430 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 440 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 450 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 460 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 471 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 481 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 491 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 501 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 512 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 522 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 532 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 542 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 552 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 563 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 573 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 583 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 593 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 604 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 614 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 624 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 634 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 645 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 655 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 665 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 675 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 686 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 696 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 706 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 716 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 727 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 737 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 747 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 757 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 768 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 778 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 788 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 798 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 808 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 819 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 829 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 839 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 849 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 860 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 870 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 880 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 890 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 901 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 911 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 921 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 931 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 942 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 952 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 962 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 972 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 983 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 993 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0 MB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (4.62.3)\n","Collecting sentencepiece!=0.1.92\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 40.2 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (2019.12.20)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (1.19.5)\n","Collecting tokenizers==0.8.1.rc2\n","  Downloading tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 26.2 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (3.4.2)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 47.0 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.2.0) (3.0.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2.0) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2.0) (1.24.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.2.0) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.2.0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.2.0) (7.1.2)\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.47 sentencepiece-0.1.96 tokenizers-0.8.1rc2 transformers-3.2.0\n"]}]},{"cell_type":"code","metadata":{"id":"GsADhaO93kgD","colab":{"base_uri":"https://localhost:8080/","height":419},"outputId":"bb076ad2-0dcd-4e8e-f02f-ce4db98427a0","executionInfo":{"status":"ok","timestamp":1643564326770,"user_tz":-330,"elapsed":655,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["import pandas as pd\n","\n","final_data = pd.read_csv(\"train_skill_name_difficulty.csv\")\n","final_data"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-92992dfa-ed82-40c8-9e3e-75049f63f5d1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>board_syllabus</th>\n","      <th>question_answer</th>\n","      <th>skill_label</th>\n","      <th>difficulty_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Raj English&gt;&gt;XII&gt;&gt;Biology&gt;&gt;Domestication, Cult...</td>\n","      <td>Among the following, freshwater fish is rohu ...</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Maharashtra New&gt;&gt;VI&gt;&gt;General Science&gt;&gt;Sound&gt;&gt;P...</td>\n","      <td>Which of the following statement is true? Sou...</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ICSE OLD&gt;&gt;XI&gt;&gt;Computer Science&gt;&gt;Functions&gt;&gt;Con...</td>\n","      <td>The process of using multiple constructors wi...</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>CBSE&gt;&gt;VI&gt;&gt;Science&gt;&gt;Separation of Substances&gt;&gt;S...</td>\n","      <td>Sieving is based on the difference in the siz...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>AP&gt;&gt;X&gt;&gt;Biology&gt;&gt;Excretion - The Wastage Dispos...</td>\n","      <td>The removal of toxic and unwanted waste subst...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>39124</th>\n","      <td>CAPS(South Africa)&gt;&gt;Grade 7&gt;&gt;Natural Sciences&gt;...</td>\n","      <td>How heat loss problems are prevented by birds...</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>39125</th>\n","      <td>CBSE&gt;&gt;X&gt;&gt;Science&gt;&gt;Metals and Non-Metal</td>\n","      <td>Give reasons why copper is used to make hot w...</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>39126</th>\n","      <td>CBSE&gt;&gt;VII&gt;&gt;Science&gt;&gt;Motion and Time</td>\n","      <td>The horizontal line in the graph is denoted as...</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>39127</th>\n","      <td>Tamil Nadu&gt;&gt;VI&gt;&gt;Science&gt;&gt;Term 1&gt;&gt;Physics&gt;&gt;Forc...</td>\n","      <td>SI unit of force is newton The SI unit of for...</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>39128</th>\n","      <td>Tamil Nadu&gt;&gt;VIII&gt;&gt;Science&gt;&gt;Term 1&gt;&gt;Physics&gt;&gt;Fo...</td>\n","      <td>In machines sliding frictions is replaced to ...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>39129 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92992dfa-ed82-40c8-9e3e-75049f63f5d1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-92992dfa-ed82-40c8-9e3e-75049f63f5d1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-92992dfa-ed82-40c8-9e3e-75049f63f5d1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                          board_syllabus  ... difficulty_label\n","0      Raj English>>XII>>Biology>>Domestication, Cult...  ...                0\n","1      Maharashtra New>>VI>>General Science>>Sound>>P...  ...                2\n","2      ICSE OLD>>XI>>Computer Science>>Functions>>Con...  ...                0\n","3      CBSE>>VI>>Science>>Separation of Substances>>S...  ...                1\n","4      AP>>X>>Biology>>Excretion - The Wastage Dispos...  ...                1\n","...                                                  ...  ...              ...\n","39124  CAPS(South Africa)>>Grade 7>>Natural Sciences>...  ...                1\n","39125             CBSE>>X>>Science>>Metals and Non-Metal  ...                2\n","39126                CBSE>>VII>>Science>>Motion and Time  ...                1\n","39127  Tamil Nadu>>VI>>Science>>Term 1>>Physics>>Forc...  ...                2\n","39128  Tamil Nadu>>VIII>>Science>>Term 1>>Physics>>Fo...  ...                1\n","\n","[39129 rows x 4 columns]"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"A0Ja4jiFhmdg","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3debe086-6fef-4133-c205-7895caf9a54d","executionInfo":{"status":"ok","timestamp":1643565100668,"user_tz":-330,"elapsed":584,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["final_data[\"question_answer\"].values"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([' Among the following, freshwater fish is rohu Rohu is a fresh water fish. Other common freshwater fish are catla, common carp.',\n","       ' Which of the following statement is true? Sound requires a medium for propagation. Sound travels through a medium (solid, liquid or gas). It cannot travel through vacuum.',\n","       ' The process of using multiple constructors with the same name but with different parameters is known as: Constructor overloading Constructor overloading is a technique in Java in which a class can have any number of constructors that differ in parameter lists.',\n","       ...,\n","       'The horizontal line in the graph is denoted as the X-axis. The horizontal line points in the horizontal direction and is denoted as the X-axis in the graph.',\n","       ' SI unit of force is newton The SI unit of force is Newton (N), named after famous scientist Isaac Newton who discovered force of gravitation.',\n","       ' In machines sliding frictions is replaced to rolling by use of ball bearings Ball bearing roll to produce rolling;friction.'],\n","      dtype=object)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"iQhO6qqt6lge","colab":{"base_uri":"https://localhost:8080/"},"outputId":"acb9e548-f50a-4132-d4d6-5f2c8e95f8d2","executionInfo":{"status":"ok","timestamp":1643565103130,"user_tz":-330,"elapsed":397,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["final_data['skill_label'].value_counts()"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3    11376\n","4    10707\n","2     8619\n","1     4997\n","0     3430\n","Name: skill_label, dtype: int64"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"9exlBELH5oq9","executionInfo":{"status":"ok","timestamp":1643565218538,"user_tz":-330,"elapsed":2130,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["\n","\n","!cp \"/content/drive/My Drive/research_skill_name_prediction/label_encoder_difficulty_Lstm\"  /content"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"IMBf0kH7TOyd","executionInfo":{"status":"ok","timestamp":1643565218540,"user_tz":-330,"elapsed":7,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["!cp \"/content/drive/My Drive/research_skill_name_prediction/label_encoder_skill_lstm\"  /content"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"YlpZo0VvTSMb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643565219993,"user_tz":-330,"elapsed":679,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}},"outputId":"c5e8f3bd-8eb8-46df-dd41-5d13fb8fa4f8"},"source":["import joblib\n","LE_skill = joblib.load(\"label_encoder_skill_lstm\")"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n","  UserWarning,\n"]}]},{"cell_type":"code","metadata":{"id":"-OBarOLBz2nO","executionInfo":{"status":"ok","timestamp":1643565221316,"user_tz":-330,"elapsed":6,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["def get_labels(prediction):\n","    predicted_label =  LE.inverse_transform([prediction])\n","    return predicted_label[0]"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"XqWem79lbn1J","colab":{"base_uri":"https://localhost:8080/","height":280},"outputId":"edfef075-edf9-47b3-c13e-1226f1a5f2bb","executionInfo":{"status":"ok","timestamp":1643565224815,"user_tz":-330,"elapsed":653,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["final_data['difficulty_label'].value_counts().sort_values(ascending=False).plot(kind='bar')"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7ff44a94dfd0>"]},"metadata":{},"execution_count":15},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"RxliBQEJ9eTG","executionInfo":{"status":"ok","timestamp":1643565245644,"user_tz":-330,"elapsed":615,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["val = pd.read_csv(\"val_skill_name_difficulty.csv\")"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"07eBaI9wA2hL","colab":{"base_uri":"https://localhost:8080/","height":419},"outputId":"a236df59-f839-45f2-a7e4-579eaa950435","executionInfo":{"status":"ok","timestamp":1643565246264,"user_tz":-330,"elapsed":8,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["val"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-a1994d94-ceed-403d-a296-2a59a0055e11\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>board_syllabus</th>\n","      <th>question_answer</th>\n","      <th>skill_label</th>\n","      <th>difficulty_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AP&gt;&gt;VII&gt;&gt;Science&gt;&gt;Animal Fibre&gt;&gt;Silk</td>\n","      <td>Name the two types of protein from which silk...</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Maharashtra New&gt;&gt;VIII&gt;&gt;General Science&gt;&gt;Man Ma...</td>\n","      <td>Give reasons: (i) Thermocol is used for the p...</td>\n","      <td>4</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>CBSE&gt;&gt;VI&gt;&gt;Science&gt;&gt;Fun with Magnets&gt;&gt;Demagneti...</td>\n","      <td>Identify the odd option. Rubbing a magnetic m...</td>\n","      <td>4</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Tamil Nadu&gt;&gt;VIII&gt;&gt;Science&gt;&gt;Term 1&gt;&gt;Physics&gt;&gt;Li...</td>\n","      <td>Find the speed of light in glass of refractiv...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Raj English&gt;&gt;XII&gt;&gt;Biology&gt;&gt;Integumentary Syste...</td>\n","      <td>Which of the following function is associated...</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2055</th>\n","      <td>CBSE&gt;&gt;XI&gt;&gt;Chemistry&gt;&gt;Chemistry : Part I&gt;&gt;Equil...</td>\n","      <td>The solubility of A 2 X 3 is y mol.dm -3 . So...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2056</th>\n","      <td>CBSE&gt;&gt;VI&gt;&gt;Computer Science&gt;&gt;Using Mail Merge&gt;&gt;...</td>\n","      <td>To create an invitation letter, click on Mail...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2057</th>\n","      <td>CBSE&gt;&gt;XII&gt;&gt;Physics&gt;&gt;Physics : Part - II&gt;&gt;Ray O...</td>\n","      <td>Choose the correct option about the intensity...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2058</th>\n","      <td>ICSE OLD&gt;&gt;VII&gt;&gt;Biology&gt;&gt;Organ System of Human ...</td>\n","      <td>Which of the following instrument is used to ...</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2059</th>\n","      <td>CBSE&gt;&gt;X&gt;&gt;Science&gt;&gt;Carbon and its Compounds&gt;&gt;Al...</td>\n","      <td>Identify the correct statement about allotrop...</td>\n","      <td>4</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2060 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1994d94-ceed-403d-a296-2a59a0055e11')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a1994d94-ceed-403d-a296-2a59a0055e11 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a1994d94-ceed-403d-a296-2a59a0055e11');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                         board_syllabus  ... difficulty_label\n","0                  AP>>VII>>Science>>Animal Fibre>>Silk  ...                0\n","1     Maharashtra New>>VIII>>General Science>>Man Ma...  ...                2\n","2     CBSE>>VI>>Science>>Fun with Magnets>>Demagneti...  ...                2\n","3     Tamil Nadu>>VIII>>Science>>Term 1>>Physics>>Li...  ...                0\n","4     Raj English>>XII>>Biology>>Integumentary Syste...  ...                0\n","...                                                 ...  ...              ...\n","2055  CBSE>>XI>>Chemistry>>Chemistry : Part I>>Equil...  ...                0\n","2056  CBSE>>VI>>Computer Science>>Using Mail Merge>>...  ...                1\n","2057  CBSE>>XII>>Physics>>Physics : Part - II>>Ray O...  ...                0\n","2058  ICSE OLD>>VII>>Biology>>Organ System of Human ...  ...                1\n","2059  CBSE>>X>>Science>>Carbon and its Compounds>>Al...  ...                0\n","\n","[2060 rows x 4 columns]"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"g8tVsjiWj-cF","colab":{"base_uri":"https://localhost:8080/","height":419},"outputId":"ce276f1a-fcae-444c-d3be-5668ff880cae","executionInfo":{"status":"ok","timestamp":1643565248149,"user_tz":-330,"elapsed":13,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["test = pd.read_csv(\"test_skill_name_difficulty.csv\")\n","test"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-818c5177-6b6a-43ab-8b26-1e57f713d353\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>board_syllabus</th>\n","      <th>question_answer</th>\n","      <th>skill_label</th>\n","      <th>difficulty_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>CBSE&gt;&gt;Nursery&gt;&gt;Environmental Science&gt;&gt;Common V...</td>\n","      <td>Write down the names of some common vegetable...</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>CBSE&gt;&gt;XII&gt;&gt;Physics&gt;&gt;Physics : Part - II&gt;&gt;Atoms</td>\n","      <td>Name the series of hydrogen atom which lies i...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ICSE OLD&gt;&gt;XI&gt;&gt;Political Science&gt;&gt;State, Govern...</td>\n","      <td>Which of the following is not the element of ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Maharashtra New&gt;&gt;VII&gt;&gt;General Science&gt;&gt;Static ...</td>\n","      <td>The process of electrically charging an objec...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Tamil Nadu&gt;&gt;IX&gt;&gt;Science&gt;&gt;Physics&gt;&gt;Measurement&gt;...</td>\n","      <td>The mass of an object is measured in kilogram...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4572</th>\n","      <td>ICSE OLD&gt;&gt;VIII&gt;&gt;Biology&gt;&gt;Nervous System And Se...</td>\n","      <td>Which of the following is the first cranial n...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4573</th>\n","      <td>CBSE&gt;&gt;VII&gt;&gt;Computer Science&gt;&gt;Advance features ...</td>\n","      <td>To ungroup the worksheets: Right-click on any...</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4574</th>\n","      <td>CBSE&gt;&gt;VIII&gt;&gt;Science&gt;&gt;Chemical Effects of Elect...</td>\n","      <td>After passing electricity through a solution ...</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4575</th>\n","      <td>CLSP&gt;&gt;Stage 9&gt;&gt;Science&gt;&gt;Chemistry&gt;&gt;Material pr...</td>\n","      <td>Identify the scientists who gave the “plum-pu...</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4576</th>\n","      <td>AP&gt;&gt;VIII&gt;&gt;Physical Science&gt;&gt;Physical Science (...</td>\n","      <td>What do you understand by the term static ele...</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4577 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-818c5177-6b6a-43ab-8b26-1e57f713d353')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-818c5177-6b6a-43ab-8b26-1e57f713d353 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-818c5177-6b6a-43ab-8b26-1e57f713d353');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                         board_syllabus  ... difficulty_label\n","0     CBSE>>Nursery>>Environmental Science>>Common V...  ...                2\n","1        CBSE>>XII>>Physics>>Physics : Part - II>>Atoms  ...                1\n","2     ICSE OLD>>XI>>Political Science>>State, Govern...  ...                0\n","3     Maharashtra New>>VII>>General Science>>Static ...  ...                1\n","4     Tamil Nadu>>IX>>Science>>Physics>>Measurement>...  ...                1\n","...                                                 ...  ...              ...\n","4572  ICSE OLD>>VIII>>Biology>>Nervous System And Se...  ...                1\n","4573  CBSE>>VII>>Computer Science>>Advance features ...  ...                0\n","4574  CBSE>>VIII>>Science>>Chemical Effects of Elect...  ...                2\n","4575  CLSP>>Stage 9>>Science>>Chemistry>>Material pr...  ...                0\n","4576  AP>>VIII>>Physical Science>>Physical Science (...  ...                1\n","\n","[4577 rows x 4 columns]"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"FIrS5sxE3kgk","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["bde76eeed0e74265ae3fa11223645ad5","03d5cac2b7fd49cb81f7e27528f7b457","7377f316b2514b29b5385a4d3d167649","905274be8581474e8f6a93d187912182","fbc384945bdf4693813ffaaab4242b90","981dfb57b349430ca7b12eeb626904b8","da6d0486cd98403786a8c8e98e24c6f5","8b9cc9afedea4c129fd52a04b80309f6","23dd892465d74cafa0a27aa884a97ed5","e81367b790e14660bbf59971926f6bd3","ec6cb9e20be044de9aa1612dc3cc0202"]},"outputId":"658e51e7-ed96-4eff-f83a-b84cb3529d75","executionInfo":{"status":"ok","timestamp":1643565261682,"user_tz":-330,"elapsed":3993,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["from transformers import BertTokenizer\n","\n","# Load the BERT tokenizer.\n","print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading BERT tokenizer...\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bde76eeed0e74265ae3fa11223645ad5","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"wp64MkNB3kg1","executionInfo":{"status":"ok","timestamp":1643565261684,"user_tz":-330,"elapsed":9,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["\n","def get_labels(prediction):\n","    predicted_label =  LE.inverse_transform([prediction])\n","    return predicted_label[0]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"uPgTmJPS3kg4","colab":{"base_uri":"https://localhost:8080/","height":106},"outputId":"8c14a530-f3b6-408d-b311-e7dab346197a","executionInfo":{"status":"ok","timestamp":1643565262393,"user_tz":-330,"elapsed":17,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["import joblib\n","from sklearn.preprocessing import LabelEncoder\n","\n","LE = LabelEncoder()\n","LE = joblib.load('label_encoder_difficulty_Lstm')\n","\n","get_labels(0)"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n","  UserWarning,\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Difficult'"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"I_UpqLMG3kg9","colab":{"base_uri":"https://localhost:8080/","height":419},"outputId":"f4e46c2f-7ac5-4187-b43d-a05e3cfabb79","executionInfo":{"status":"ok","timestamp":1643565262394,"user_tz":-330,"elapsed":12,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["final_data"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-0bf1f744-e109-4511-b102-1cc31fde38c4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>board_syllabus</th>\n","      <th>question_answer</th>\n","      <th>skill_label</th>\n","      <th>difficulty_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Raj English&gt;&gt;XII&gt;&gt;Biology&gt;&gt;Domestication, Cult...</td>\n","      <td>Among the following, freshwater fish is rohu ...</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Maharashtra New&gt;&gt;VI&gt;&gt;General Science&gt;&gt;Sound&gt;&gt;P...</td>\n","      <td>Which of the following statement is true? Sou...</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ICSE OLD&gt;&gt;XI&gt;&gt;Computer Science&gt;&gt;Functions&gt;&gt;Con...</td>\n","      <td>The process of using multiple constructors wi...</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>CBSE&gt;&gt;VI&gt;&gt;Science&gt;&gt;Separation of Substances&gt;&gt;S...</td>\n","      <td>Sieving is based on the difference in the siz...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>AP&gt;&gt;X&gt;&gt;Biology&gt;&gt;Excretion - The Wastage Dispos...</td>\n","      <td>The removal of toxic and unwanted waste subst...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>39124</th>\n","      <td>CAPS(South Africa)&gt;&gt;Grade 7&gt;&gt;Natural Sciences&gt;...</td>\n","      <td>How heat loss problems are prevented by birds...</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>39125</th>\n","      <td>CBSE&gt;&gt;X&gt;&gt;Science&gt;&gt;Metals and Non-Metal</td>\n","      <td>Give reasons why copper is used to make hot w...</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>39126</th>\n","      <td>CBSE&gt;&gt;VII&gt;&gt;Science&gt;&gt;Motion and Time</td>\n","      <td>The horizontal line in the graph is denoted as...</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>39127</th>\n","      <td>Tamil Nadu&gt;&gt;VI&gt;&gt;Science&gt;&gt;Term 1&gt;&gt;Physics&gt;&gt;Forc...</td>\n","      <td>SI unit of force is newton The SI unit of for...</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>39128</th>\n","      <td>Tamil Nadu&gt;&gt;VIII&gt;&gt;Science&gt;&gt;Term 1&gt;&gt;Physics&gt;&gt;Fo...</td>\n","      <td>In machines sliding frictions is replaced to ...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>39129 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0bf1f744-e109-4511-b102-1cc31fde38c4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0bf1f744-e109-4511-b102-1cc31fde38c4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0bf1f744-e109-4511-b102-1cc31fde38c4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                          board_syllabus  ... difficulty_label\n","0      Raj English>>XII>>Biology>>Domestication, Cult...  ...                0\n","1      Maharashtra New>>VI>>General Science>>Sound>>P...  ...                2\n","2      ICSE OLD>>XI>>Computer Science>>Functions>>Con...  ...                0\n","3      CBSE>>VI>>Science>>Separation of Substances>>S...  ...                1\n","4      AP>>X>>Biology>>Excretion - The Wastage Dispos...  ...                1\n","...                                                  ...  ...              ...\n","39124  CAPS(South Africa)>>Grade 7>>Natural Sciences>...  ...                1\n","39125             CBSE>>X>>Science>>Metals and Non-Metal  ...                2\n","39126                CBSE>>VII>>Science>>Motion and Time  ...                1\n","39127  Tamil Nadu>>VI>>Science>>Term 1>>Physics>>Forc...  ...                2\n","39128  Tamil Nadu>>VIII>>Science>>Term 1>>Physics>>Fo...  ...                1\n","\n","[39129 rows x 4 columns]"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"MHdVe13Fr3vt","executionInfo":{"status":"ok","timestamp":1643565280310,"user_tz":-330,"elapsed":627,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["new_data = final_data"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"AkyM7gqv3khI","executionInfo":{"status":"ok","timestamp":1643565280863,"user_tz":-330,"elapsed":3,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["question_answer = new_data[\"question_answer\"].values\n","categories = new_data[\"difficulty_label\"].values"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ndpw0p1SBUoZ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6f7618f7-ed8b-4417-a25f-cfd787ddebf9","executionInfo":{"status":"ok","timestamp":1643565282550,"user_tz":-330,"elapsed":7,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["question_answer"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([' Among the following, freshwater fish is rohu Rohu is a fresh water fish. Other common freshwater fish are catla, common carp.',\n","       ' Which of the following statement is true? Sound requires a medium for propagation. Sound travels through a medium (solid, liquid or gas). It cannot travel through vacuum.',\n","       ' The process of using multiple constructors with the same name but with different parameters is known as: Constructor overloading Constructor overloading is a technique in Java in which a class can have any number of constructors that differ in parameter lists.',\n","       ...,\n","       'The horizontal line in the graph is denoted as the X-axis. The horizontal line points in the horizontal direction and is denoted as the X-axis in the graph.',\n","       ' SI unit of force is newton The SI unit of force is Newton (N), named after famous scientist Isaac Newton who discovered force of gravitation.',\n","       ' In machines sliding frictions is replaced to rolling by use of ball bearings Ball bearing roll to produce rolling;friction.'],\n","      dtype=object)"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"tFkS_H_83khL","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"11e4ede6-ebb2-4f15-fbfe-3da1bb561dc5","executionInfo":{"status":"ok","timestamp":1643565283832,"user_tz":-330,"elapsed":15,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["question_answer[0]"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["' Among the following, freshwater fish is rohu Rohu is a fresh water fish. Other common freshwater fish are catla, common carp.'"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"ian7gSDE3khR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a6a3a741-daed-45d4-d209-3d42cd6f048e","executionInfo":{"status":"ok","timestamp":1643565289034,"user_tz":-330,"elapsed":638,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["len(categories)"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["39129"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"Y_ZeuHc63khU","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c7e7fb1f-3102-43ff-83ec-80feac7609bd","executionInfo":{"status":"ok","timestamp":1643565343691,"user_tz":-330,"elapsed":49878,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["input_ids = []\n","attention_masks = []\n","\n","for sent in question_answer:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 128,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        truncation=True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', question_answer[0])\n","print('Token IDs:', input_ids[0])"],"execution_count":29,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Original:   Among the following, freshwater fish is rohu Rohu is a fresh water fish. Other common freshwater fish are catla, common carp.\n","Token IDs: tensor([  101,  2426,  1996,  2206,  1010, 12573,  3869,  2003, 20996,  6979,\n","        20996,  6979,  2003,  1037,  4840,  2300,  3869,  1012,  2060,  2691,\n","        12573,  3869,  2024,  4937,  2721,  1010,  2691, 29267,  1012,   102,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0])\n"]}]},{"cell_type":"code","metadata":{"id":"iVGvVZb13kha","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4c97696b-3907-4ef1-98b4-4f0ff2ed485c","executionInfo":{"status":"ok","timestamp":1643565366600,"user_tz":-330,"elapsed":358,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["print('Original: ', len(question_answer[1]))\n","print('Token IDs:', len(input_ids[1]))"],"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Original:  171\n","Token IDs: 128\n"]}]},{"cell_type":"code","metadata":{"id":"5nmRiaBbA9OH","executionInfo":{"status":"ok","timestamp":1643565368286,"user_tz":-330,"elapsed":4,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["val_text = val[\"question_answer\"].values\n","val_labels = val[\"difficulty_label\"].values\n","test_text = test[\"question_answer\"].values\n","test_labels = test[\"difficulty_label\"].values"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"E-s_H1WdyvCw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"75cb1531-31a4-49a5-aa6c-5a0aeb5f7cc9","executionInfo":{"status":"ok","timestamp":1643565370214,"user_tz":-330,"elapsed":8,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["test_labels"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2, 1, 0, ..., 2, 0, 1])"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"YF-mKCC1CUjD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"125e72e6-3703-4cae-ecb5-362c3c64ef69","executionInfo":{"status":"ok","timestamp":1643565371774,"user_tz":-330,"elapsed":13,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["val_labels"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 2, 2, ..., 0, 1, 0])"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"sOQuDahhAzOO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2a370eb1-9a12-4669-c058-9a6653870fce","executionInfo":{"status":"ok","timestamp":1643565379302,"user_tz":-330,"elapsed":2955,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["val_input_ids = []\n","val_attention_masks = []\n","\n","for sent in val_text:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 128,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        truncation=True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    val_input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    val_attention_masks.append(encoded_dict['attention_mask'])\n","# Convert the lists into tensors.\n","val_input_ids = torch.cat(val_input_ids, dim=0)\n","val_attention_masks = torch.cat(val_attention_masks, dim=0)\n","\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', val_text[0])\n","print('Token IDs:', val_attention_masks[0])"],"execution_count":34,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Original:   Name the two types of protein from which silk is made. Sericin and fibroin \n","Token IDs: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0])\n"]}]},{"cell_type":"code","metadata":{"id":"Siskea7qDLUG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f47de2b6-7fdd-4e3b-f2c9-64fde7abd283","executionInfo":{"status":"ok","timestamp":1643565379304,"user_tz":-330,"elapsed":10,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["print('Original: ', val_text[1])\n","print('Token IDs:', val_input_ids[1])"],"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Original:   Give reasons: (i) Thermocol is used for the packing of delicate items. (ii) Name two diseases that may develop in people working in thermocol industries. (i) Thermocol is a good shock-absorber, therefore, it is used for packing of delicate items. (ii) People working in thermocol industries may suffer from blood cancer such as leukemia and lymphoma or have problems in eyes and respiratory system. \n","Token IDs: tensor([  101,  2507,  4436,  1024,  1006,  1045,  1007,  1996, 10867, 24163,\n","         2140,  2003,  2109,  2005,  1996, 14743,  1997, 10059,  5167,  1012,\n","         1006,  2462,  1007,  2171,  2048,  7870,  2008,  2089,  4503,  1999,\n","         2111,  2551,  1999,  1996, 10867, 24163,  2140,  6088,  1012,  1006,\n","         1045,  1007,  1996, 10867, 24163,  2140,  2003,  1037,  2204,  5213,\n","         1011, 16888,  2121,  1010,  3568,  1010,  2009,  2003,  2109,  2005,\n","        14743,  1997, 10059,  5167,  1012,  1006,  2462,  1007,  2111,  2551,\n","         1999,  1996, 10867, 24163,  2140,  6088,  2089,  9015,  2013,  2668,\n","         4456,  2107,  2004, 25468,  1998,  1048, 24335,  8458,  9626,  2030,\n","         2031,  3471,  1999,  2159,  1998, 16464,  2291,  1012,   102,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0])\n"]}]},{"cell_type":"code","metadata":{"id":"irMTimjf3khd","executionInfo":{"status":"ok","timestamp":1643565382344,"user_tz":-330,"elapsed":729,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["labels = torch.tensor(categories)\n","val_labels = torch.tensor(val_labels)"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"PdOgWP_LKTHi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e4245b9b-3851-4ebd-e150-ec4b26fe1e72","executionInfo":{"status":"ok","timestamp":1643565382957,"user_tz":-330,"elapsed":7,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["val_labels"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0, 2, 2,  ..., 0, 1, 0])"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"OJJ0I8Ud3khf","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"036b5d61-03de-4f40-d90f-3e03cc437f27","executionInfo":{"status":"ok","timestamp":1643565383809,"user_tz":-330,"elapsed":856,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["get_labels(1)"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Easy'"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"Z1ZAbQRfiG63","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5644402c-225b-42d0-8257-48e7cde71ce1","executionInfo":{"status":"ok","timestamp":1643565383810,"user_tz":-330,"elapsed":13,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["len(set(final_data[\"question_answer\"].values).intersection(val[\"question_answer\"].values))"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"BNDW74Ny3khj","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e48a612a-58ae-4040-c5b7-246e23da4b63","executionInfo":{"status":"ok","timestamp":1643565384231,"user_tz":-330,"elapsed":4,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["num_classes = len(list(set(categories)))\n","list(set(categories))"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0, 1, 2]"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"ZmaLk5Ab3khl","executionInfo":{"status":"ok","timestamp":1643565388918,"user_tz":-330,"elapsed":5,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["from torch.utils.data import TensorDataset, random_split\n","# train_poincare_tensor = torch.tensor(poincare_embeddings_final,dtype=torch.float)\n","# difficulty_tensor = torch.tensor(difficulty_level_vectors,dtype=torch.float)\n","# Combine the training inputs into a TensorDataset.\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","val_dataset = TensorDataset(val_input_ids, val_attention_masks,val_labels) \n","# Create a 90-10train-validation split.\n","\n","# Calculate the number of samples to include in each set.\n","# train_size = int(0.90 * len(dataset))\n","# val_size = len(dataset) - train_size\n","\n","# # Divide the dataset by randomly selecting samples.\n","# train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","# print('{:>5,} training samples'.format(train_size))\n","# # print('{:>5,} validation samples'.format(val_size))"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"D_lTinod3kho","executionInfo":{"status":"ok","timestamp":1643565388919,"user_tz":-330,"elapsed":5,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","batch_size = 34\n","train_dataloader = DataLoader(\n","            dataset,  # The training samples.\n","            sampler = RandomSampler(dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), \n","            batch_size = batch_size \n","        )"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"_2tmAMlw3khr","executionInfo":{"status":"ok","timestamp":1643565388920,"user_tz":-330,"elapsed":6,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["from transformers import BertModel, AdamW, BertConfig\n","\n","# # Loads BertForSequenceClassification, the pretrained BERT model with a single \n","# model = BertModel.from_pretrained(\n","#     \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n","# )\n","\n","# # Tell pytorch to run this model on the GPU.\n","# model.cuda()"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"DkDmTZhVChN6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"247f0301-3004-49db-ebe2-716961ac6624","executionInfo":{"status":"ok","timestamp":1643565393545,"user_tz":-330,"elapsed":767,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["\n","\n","\n","\n","set(test[\"question_answer\"].values).intersection(set(final_data[\"question_answer\"].values))"],"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["set()"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"JJvEax7_uTEh","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2ec6ebf1-3f6e-440e-8fc5-2e666a42d3c8","executionInfo":{"status":"ok","timestamp":1643565409158,"user_tz":-330,"elapsed":15618,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["!unzip \"/content/drive/MyDrive/research_skill_name_prediction/model_bert_skill_prediction.zip\"\n","!unzip \"/content/drive/MyDrive/research_skill_name_prediction/model_bert_difficulty_prediction.zip\""],"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/drive/MyDrive/research_skill_name_prediction/model_bert_skill_prediction.zip\n","   creating: model_bert_skill_prediction/\n","  inflating: model_bert_skill_prediction/tokenizer_config.json  \n","  inflating: model_bert_skill_prediction/model_weights  \n","  inflating: model_bert_skill_prediction/vocab.txt  \n","  inflating: model_bert_skill_prediction/special_tokens_map.json  \n","Archive:  /content/drive/MyDrive/research_skill_name_prediction/model_bert_difficulty_prediction.zip\n","   creating: model_bert_difficulty_prediction/\n","  inflating: model_bert_difficulty_prediction/tokenizer_config.json  \n","  inflating: model_bert_difficulty_prediction/model_weights  \n","  inflating: model_bert_difficulty_prediction/vocab.txt  \n","  inflating: model_bert_difficulty_prediction/special_tokens_map.json  \n"]}]},{"cell_type":"code","metadata":{"id":"8CFbt2CWqSLz","colab":{"base_uri":"https://localhost:8080/"},"outputId":"27ee9c12-3b85-42ac-d0c4-adf88b195163","executionInfo":{"status":"ok","timestamp":1643565424100,"user_tz":-330,"elapsed":14980,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["!unzip \"/content/drive/MyDrive/research_skill_name_prediction/model_bert_multi_task_prediction.zip\""],"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/drive/MyDrive/research_skill_name_prediction/model_bert_multi_task_prediction.zip\n","   creating: model_bert_multi_task_prediction/\n","  inflating: model_bert_multi_task_prediction/model_weights  \n","  inflating: model_bert_multi_task_prediction/tokenizer_config.json  \n","  inflating: model_bert_multi_task_prediction/special_tokens_map.json  \n","  inflating: model_bert_multi_task_prediction/vocab.txt  \n"]}]},{"cell_type":"code","metadata":{"id":"MJ9iUjJiHI7k","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6ec284f3-02b6-4f31-9ea6-b0dd11d2e4b8","executionInfo":{"status":"ok","timestamp":1643565444200,"user_tz":-330,"elapsed":20119,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["!unzip \"/content/drive/MyDrive/research_skill_name_prediction/model_bert_multi_task_interactive_final.zip\""],"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/drive/MyDrive/research_skill_name_prediction/model_bert_multi_task_interactive_final.zip\n","   creating: model_bert_multi_task_interactive_final/\n","  inflating: model_bert_multi_task_interactive_final/special_tokens_map.json  \n"," extracting: model_bert_multi_task_interactive_final/tokenizer_config.json  \n","  inflating: model_bert_multi_task_interactive_final/vocab.txt  \n","  inflating: model_bert_multi_task_interactive_final/model_weights  \n"]}]},{"cell_type":"code","metadata":{"id":"drz7amvtT4ju","executionInfo":{"status":"ok","timestamp":1643565483570,"user_tz":-330,"elapsed":39392,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["!cp -r \"/content/drive/MyDrive/research_skill_name_prediction/model_bert_multi_task_interactive_pre_trained_skill_bert\" /content"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"id":"lJjikk9efqJP","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c4b60a0e-779a-493d-854d-5757f0024560","executionInfo":{"status":"ok","timestamp":1643565491487,"user_tz":-330,"elapsed":7921,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["!pip install torchtext\n","import torchtext"],"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (0.3.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.19.5)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.10.0+cu111)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.62.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext) (3.10.0.2)\n"]}]},{"cell_type":"code","metadata":{"id":"fsD6CUxrvnL0","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c3139b28-96c7-4e62-fad6-d730e367f501","executionInfo":{"status":"ok","timestamp":1643565513415,"user_tz":-330,"elapsed":21960,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["!unzip \"/content/drive/MyDrive/research_skill_name_prediction/model_bert_skill_cascade.zip\"\n","!unzip \"/content/drive/MyDrive/research_skill_name_prediction/model_save_BLOOM_difficulty_Lstm.zip\"\n","!unzip \"/content/drive/MyDrive/research_skill_name_prediction/model_save_gru_difficulty_name.zip\""],"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/drive/MyDrive/research_skill_name_prediction/model_bert_skill_cascade.zip\n","   creating: model_bert_skill_cascade/\n","  inflating: model_bert_skill_cascade/model_weights  \n","  inflating: model_bert_skill_cascade/tokenizer_config.json  \n","  inflating: model_bert_skill_cascade/special_tokens_map.json  \n","  inflating: model_bert_skill_cascade/vocab.txt  \n","Archive:  /content/drive/MyDrive/research_skill_name_prediction/model_save_BLOOM_difficulty_Lstm.zip\n","   creating: model_save_BLOOM_difficulty_Lstm/\n","  inflating: model_save_BLOOM_difficulty_Lstm/model_weights  \n","Archive:  /content/drive/MyDrive/research_skill_name_prediction/model_save_gru_difficulty_name.zip\n","   creating: model_save_gru_difficulty_name/\n","  inflating: model_save_gru_difficulty_name/model_weights  \n"]}]},{"cell_type":"code","metadata":{"id":"YBoO8oWNFf2z","colab":{"base_uri":"https://localhost:8080/"},"outputId":"48056d3c-9681-45fe-f9a9-b953fd9922c4","executionInfo":{"status":"ok","timestamp":1643565529444,"user_tz":-330,"elapsed":16040,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["!unzip \"/content/drive/MyDrive/research_skill_name_prediction/model_bert_difficulty_cascade.zip\"\n"],"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/drive/MyDrive/research_skill_name_prediction/model_bert_difficulty_cascade.zip\n","   creating: model_bert_difficulty_cascade/\n","  inflating: model_bert_difficulty_cascade/model_weights  \n","  inflating: model_bert_difficulty_cascade/special_tokens_map.json  \n","  inflating: model_bert_difficulty_cascade/tokenizer_config.json  \n","  inflating: model_bert_difficulty_cascade/vocab.txt  \n"]}]},{"cell_type":"code","metadata":{"id":"-7yA8H4kHJvv","executionInfo":{"status":"ok","timestamp":1643565550467,"user_tz":-330,"elapsed":21045,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["\n","text = torchtext.data.Field(lower=True, batch_first=True, tokenize='spacy', include_lengths=True)\n","target = torchtext.data.Field(sequential=False, use_vocab=False, is_target=True)\n","# use field objects to read training, validation and test sets\n","train = torchtext.data.TabularDataset(path='train_skill_name_difficulty.csv', format='csv',\n","                                      fields={'question_answer': ('text',text),\n","                                              'difficulty_label': ('target',target)})\n","val = torchtext.data.TabularDataset(path='val_skill_name_difficulty.csv', format='csv',\n","                                    fields={'question_answer': ('text',text),\n","                                              'difficulty_label': ('target',target)})\n","test_text = torchtext.data.TabularDataset(path='test_skill_name_difficulty.csv', format='csv',\n","                                     fields={'difficulty_label': ('label', target),\n","                                             'question_answer': ('text',text)})"],"execution_count":52,"outputs":[]},{"cell_type":"code","metadata":{"id":"NHKLEuKxHL5A","executionInfo":{"status":"ok","timestamp":1643565550468,"user_tz":-330,"elapsed":26,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["batch_size = 34\n","train_iter = torchtext.data.Iterator(dataset=train,\n","                                           batch_size=batch_size,\n","                                           sort_key=lambda x: x.text.__len__(),\n","                                           shuffle=True,\n","                                           sort_within_batch=True) \n","val_iter = torchtext.data.Iterator(dataset=val,\n","                                         batch_size=batch_size,\n","                                         sort_key=lambda x: x.text.__len__(),\n","                                         train=False,\n","                                         sort_within_batch=True)\n","test_iter = torchtext.data.Iterator(dataset=test_text,\n","                                          batch_size=batch_size,\n","                                          sort=False,\n","                                          sort_within_batch=False)"],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"id":"miKcDNXuHNop","executionInfo":{"status":"ok","timestamp":1643565550470,"user_tz":-330,"elapsed":27,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["import torchtext.vocab as vocab\n"],"execution_count":54,"outputs":[]},{"cell_type":"code","metadata":{"id":"spmW5b5ufklC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643565761161,"user_tz":-330,"elapsed":210717,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}},"outputId":"26c64b10-0ce1-481d-809c-ac80b33b6432"},"source":["text.build_vocab(train, val, test_text,vectors=\"glove.6B.100d\", min_freq=3)\n"],"execution_count":55,"outputs":[{"output_type":"stream","name":"stderr","text":[".vector_cache/glove.6B.zip: 862MB [02:40, 5.38MB/s]                           \n","100%|█████████▉| 399999/400000 [00:23<00:00, 17009.42it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"-sLtbTYSfklC","colab":{"base_uri":"https://localhost:8080/"},"outputId":"851824f2-89bf-4060-a024-0a8a12ff0319","executionInfo":{"status":"ok","timestamp":1643565761163,"user_tz":-330,"elapsed":12,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["print(text.vocab.vectors.shape)\n","print(f\"Unique tokens in text vocabulary: {len(text.vocab)}\")"],"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([17896, 100])\n","Unique tokens in text vocabulary: 17896\n"]}]},{"cell_type":"code","metadata":{"id":"5a0Hs7nZi8TW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"deec24b9-ce96-44ca-d596-189aced1fe6d","executionInfo":{"status":"ok","timestamp":1643567077070,"user_tz":-330,"elapsed":458,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["num_classes"],"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","metadata":{"id":"ZA_r6iiReO4N","executionInfo":{"status":"ok","timestamp":1643567077678,"user_tz":-330,"elapsed":3,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["# attention layer code inspired from: https://discuss.pytorch.org/t/self-attention-on-words-and-masking/5671/4\n","from torch import nn\n","class Attention(nn.Module):\n","    def __init__(self, hidden_size, batch_first=False):\n","        super(Attention, self).__init__()\n","\n","        self.hidden_size = hidden_size\n","        self.batch_first = batch_first\n","\n","        self.att_weights = nn.Parameter(torch.Tensor(1, hidden_size), requires_grad=True)\n","\n","        stdv = 1.0 / np.sqrt(self.hidden_size)\n","        for weight in self.att_weights:\n","            nn.init.uniform_(weight, -stdv, stdv)\n","\n","    def get_mask(self):\n","        pass\n","\n","    def forward(self, inputs, lengths):\n","        if self.batch_first:\n","            batch_size, max_len = inputs.size()[:2]\n","        else:\n","            max_len, batch_size = inputs.size()[:2]\n","            \n","        # apply attention layer\n","        weights = torch.bmm(inputs,\n","                            self.att_weights\n","                            .permute(1, 0)  \n","                            .unsqueeze(0)  \n","                            .repeat(batch_size, 1, 1) \n","                            )\n","    \n","        attentions = torch.softmax(F.relu(weights.squeeze()), dim=-1)\n","\n","        mask = torch.ones(attentions.size(), requires_grad=True).cuda()\n","        for i, l in enumerate(lengths):  # skip the first sentence\n","            if l < max_len:\n","                mask[i, l:] = 0\n","\n","        masked = attentions * mask\n","        _sums = masked.sum(-1).unsqueeze(-1)  # sums per row\n","        \n","        attentions = masked.div(_sums)\n","\n","        weighted = torch.mul(inputs, attentions.unsqueeze(-1).expand_as(inputs))\n","\n","        representations = weighted.sum(1).squeeze()\n","\n","        return representations, attentions"],"execution_count":58,"outputs":[]},{"cell_type":"code","metadata":{"id":"aHmQK0OP9mv-","executionInfo":{"status":"ok","timestamp":1643567079632,"user_tz":-330,"elapsed":2,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["from torch import nn\n","class MultiClassClassifierGRU(nn.Module):\n","  def __init__(self, pretrained_lm, hidden_dim=228, lstm_layer=2, dropout=0.2):\n","        super(MultiClassClassifierGRU, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","        self.embedding = nn.Embedding.from_pretrained(pretrained_lm)\n","        self.embedding.weight.requires_grad = False\n","        self.gru1 = nn.GRU(input_size=self.embedding.embedding_dim,\n","                            hidden_size=hidden_dim,\n","                            num_layers=1, \n","                            bidirectional=True)\n","        self.atten1 = Attention(hidden_dim*2, batch_first=True) # 2 is bidrectional\n","        self.gru2 = nn.GRU(input_size=hidden_dim*2,\n","                            hidden_size=hidden_dim,\n","                            num_layers=1, \n","                            bidirectional=True)\n","        self.atten2 = Attention(hidden_dim*2, batch_first=True)\n","        self.fc1 = nn.Sequential(nn.Linear(hidden_dim*7*2, hidden_dim*7*2),\n","                                 nn.BatchNorm1d(hidden_dim*7*2),\n","                                 nn.ReLU()) \n","        self.fc2 = nn.Linear(hidden_dim*7*2, num_classes)\n","\n","    \n","  def forward(self, x, x_len):\n","        x = self.embedding(x)\n","        x = self.dropout(x)\n","        \n","        x = nn.utils.rnn.pack_padded_sequence(x, x_len, batch_first=True, enforce_sorted=False)\n","        out1, h_n = self.gru1(x)\n","\n","        x, lengths = nn.utils.rnn.pad_packed_sequence(out1, batch_first=True)\n","        lengths_tensor = torch.autograd.Variable(torch.FloatTensor(lengths.float())).view(-1,1)\n","\n","        average_pooling = torch.sum(x,dim=1)/lengths_tensor.to(device)\n","        max_pooling =  torch.nn.functional.adaptive_max_pool1d(x.permute(0,2,1), (1,)).view(x.size()[0],-1)\n","\n","        # print(pooled_output_1.size())\n","\n","        x, _ = self.atten1(x, lengths) # skip connect\n","        if len(x.shape)==1:\n","          x = x.reshape(1,-1)\n","        pooled_output_1 = torch.cat([x,h_n[-1],average_pooling,max_pooling],dim=1)\n","\n","\n","        # print(pooled_output_1.size())\n","\n","        out2, h_n = self.gru2(out1)\n","        y, lengths = nn.utils.rnn.pad_packed_sequence(out2, batch_first=True)\n","\n","        lengths_tensor = torch.autograd.Variable(torch.FloatTensor(lengths.float())).view(-1,1)\n","\n","        average_pooling = torch.sum(y,dim=1)/lengths_tensor.to(device)\n","        max_pooling =  torch.nn.functional.adaptive_max_pool1d(y.permute(0,2,1), (1,)).view(y.size()[0],-1)\n","        y, _ = self.atten2(y, lengths)\n","        if len(y.shape)==1:\n","          y = y.reshape(1,-1)\n","        pooled_output_2 = torch.cat([y,h_n[-1],average_pooling,max_pooling],dim=1)\n","\n","        z = torch.cat([pooled_output_1, pooled_output_2], dim=1)\n","\n","        z = self.fc1(self.dropout(z))\n","        z = self.fc2(self.dropout(z))\n","        return z\n"],"execution_count":59,"outputs":[]},{"cell_type":"code","metadata":{"id":"VeuaTKv7b8SY","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e6158517-f92a-4982-e9b1-782bf99ac990","executionInfo":{"status":"ok","timestamp":1643567151188,"user_tz":-330,"elapsed":69914,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["import numpy as np\n","model_gru = MultiClassClassifierGRU(text.vocab.vectors, hidden_dim=400, lstm_layer=2, dropout=0.3).cuda()\n","model_gru.load_state_dict(torch.load(\"model_save_gru_difficulty_name/model_weights\"))"],"execution_count":60,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","metadata":{"id":"P0Qbs-C7kD0K","executionInfo":{"status":"ok","timestamp":1643567151722,"user_tz":-330,"elapsed":539,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["from torch import nn\n","class MultiClassClassifierLstm(nn.Module):\n","  def __init__(self, pretrained_lm, hidden_dim=128, lstm_layer=2, dropout=0.2):\n","        super(MultiClassClassifierLstm, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","        self.embedding = nn.Embedding.from_pretrained(pretrained_lm)\n","        self.embedding.weight.requires_grad = False\n","        self.lstm1 = nn.LSTM(input_size=self.embedding.embedding_dim,\n","                            hidden_size=hidden_dim,\n","                            num_layers=1, \n","                            bidirectional=True)\n","        self.atten1 = Attention(hidden_dim*2, batch_first=True) # 2 is bidrectional\n","        self.lstm2 = nn.LSTM(input_size=hidden_dim*2,\n","                            hidden_size=hidden_dim,\n","                            num_layers=1, \n","                            bidirectional=True)\n","        self.atten2 = Attention(hidden_dim*2, batch_first=True)\n","        self.fc1 = nn.Sequential(nn.Linear(hidden_dim*lstm_layer*2, hidden_dim*lstm_layer*2),\n","                                 nn.BatchNorm1d(hidden_dim*lstm_layer*2),\n","                                 nn.ReLU()) \n","        self.fc2 = nn.Linear(hidden_dim*lstm_layer*2, 3)\n","\n","    \n","  def forward(self, x, x_len):\n","        x = self.embedding(x)\n","        x = self.dropout(x)\n","        \n","        x = nn.utils.rnn.pack_padded_sequence(x, x_len, batch_first=True, enforce_sorted=False)\n","        out1, (h_n, c_n) = self.lstm1(x)\n","        x, lengths = nn.utils.rnn.pad_packed_sequence(out1, batch_first=True)\n","        x, _ = self.atten1(x, lengths) # skip connect\n","\n","        out2, (h_n, c_n) = self.lstm2(out1)\n","        y, lengths = nn.utils.rnn.pad_packed_sequence(out2, batch_first=True)\n","        y, _ = self.atten2(y, lengths)\n","        \n","        if len(x.shape)==1:\n","          x = x.reshape(1,-1)\n","          y = y.reshape(1,-1)\n","\n","        z = torch.cat([x, y], dim=1)\n","        z = self.fc1(self.dropout(z))\n","        z = self.fc2(self.dropout(z))\n","        return z\n"],"execution_count":61,"outputs":[]},{"cell_type":"code","metadata":{"id":"r-lFAuxXXXbk","executionInfo":{"status":"ok","timestamp":1643567153010,"user_tz":-330,"elapsed":1293,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["!cp -r \"/content/drive/MyDrive/research_skill_name_prediction/model_save_BLOOM_skill_Lstm\" /content/"],"execution_count":62,"outputs":[]},{"cell_type":"code","metadata":{"id":"lpqEAkGCkt7W","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6e7fa512-2153-4892-9892-41d18fc69236","executionInfo":{"status":"ok","timestamp":1643567153013,"user_tz":-330,"elapsed":23,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["model_lstm = MultiClassClassifierLstm(text.vocab.vectors, hidden_dim=128, lstm_layer=2, dropout=0.3).cuda()\n","model_lstm.load_state_dict(torch.load(\"model_save_BLOOM_difficulty_Lstm/model_weights\"))"],"execution_count":63,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":63}]},{"cell_type":"code","metadata":{"id":"nAdyYUrfRBzQ","executionInfo":{"status":"ok","timestamp":1643567205280,"user_tz":-330,"elapsed":4,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["from torch import nn\n","class MultiClassClassifier(nn.Module):\n","    def __init__(self, bert_model_path, labels_count, hidden_dim=768, mlp_dim=500, extras_dim=100, dropout=0.1, freeze_bert=False):\n","        super().__init__()\n","\n","        self.bert = BertModel.from_pretrained(bert_model_path,output_hidden_states=False,output_attentions=False)\n","        self.dropout = nn.Dropout(dropout)\n","        self.mlp = nn.Sequential(\n","            nn.Linear(hidden_dim, mlp_dim),\n","            nn.ReLU(),\n","            # nn.Linear(mlp_dim, mlp_dim),\n","            # # nn.ReLU(),\n","            # # nn.Linear(mlp_dim, mlp_dim),\n","            # nn.ReLU(),            \n","            nn.Linear(mlp_dim, labels_count)\n","        )\n","        # self.softmax = nn.LogSoftmax(dim=1)\n","        if freeze_bert:\n","            print(\"Freezing layers\")\n","            for param in self.bert.parameters():\n","                param.requires_grad = False\n","\n","    def forward(self, tokens, masks):\n","        _,pooled_output = self.bert(tokens, attention_mask=masks)\n","        dropout_output = self.dropout(pooled_output)\n","        # concat_output = torch.cat((dropout_output, topic_emb), dim=1)\n","        # concat_output = self.dropout(concat_output)\n","        mlp_output = self.mlp(dropout_output)\n","        # proba = self.sigmoid(mlp_output)\n","        # proba = self.softmax(mlp_output)\n","\n","        return mlp_output"],"execution_count":69,"outputs":[]},{"cell_type":"code","metadata":{"id":"H0TDkaA56dFJ","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a1282cb64c6f4d8c827734e9890a1b32","e3e7e59682854c2880aaf7dc49ebdf20","c1d9a51a16fa4028b14a69170d592df1","22ccf0234532411d92f5a46233162407","90c9c928619242b2adf95df7872a18d4","11ba5c504e304b2f9ceefa258e79ee7e","61ed2402da334adf8dd644bd7da14f1a","19aeac66ae9b470fa171be5b0f09e94b","af5d7ac69e3c44aaa0d783fcb3c8538b","38eeac47c86a4496b5b26323ed4d68b6","274dd46a471945bba696ae3a397f618f","1295c91918b845a88a2ce70e4fceff2f","f950b3eed3a34da4bf605b2435a0bb04","05f2e725fe1d47429421976390a0c7e7","13d3566026bf49d9a0995a9002d32ada","29520efc30524df78ffd449fe943ec4a","2deb4f10f927424ea334890c7872f204","9eb1a756ac4e4ceda13db1cab4e04a48","8896a7b161cd417d8d3db99228b6bba4","ea758d7070cc4a7881c0e74fce39ba38","9e36610fe72142f6b9ece0e1fc53a85c","3eb02f086a0e46cd8aeb215f3ce8f9d3"]},"outputId":"155d3d61-49fd-4420-cce4-527e30ff5870","executionInfo":{"status":"ok","timestamp":1643567197612,"user_tz":-330,"elapsed":44617,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","# Loads BertForSequenceClassification, the pretrained BERT model with a single \n","model = MultiClassClassifier('bert-base-uncased',num_classes, 768,500,140,dropout=0.1,freeze_bert=False)\n","\n","model.load_state_dict(torch.load(\"model_bert_difficulty_prediction/model_weights\"))\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()\n"],"execution_count":65,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a1282cb64c6f4d8c827734e9890a1b32","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1295c91918b845a88a2ce70e4fceff2f","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["MultiClassClassifier(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (mlp): Sequential(\n","    (0): Linear(in_features=768, out_features=500, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=500, out_features=3, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":65}]},{"cell_type":"code","metadata":{"id":"_g8cFpXrpo9Q","executionInfo":{"status":"ok","timestamp":1643567197613,"user_tz":-330,"elapsed":19,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["from torch import nn\n","class MultiClassClassifier(nn.Module):\n","    def __init__(self, bert_model_path, labels_count,skill_label_count, hidden_dim=768, mlp_dim=500, extras_dim=140, dropout=0.1, freeze_bert=False):\n","        super().__init__()\n","\n","        self.bert = BertModel.from_pretrained(bert_model_path,output_hidden_states=False,output_attentions=False)\n","        self.dropout = nn.Dropout(dropout)\n","        self.mlp = nn.Sequential(\n","            nn.Linear(hidden_dim , mlp_dim),\n","            nn.ReLU(),\n","            # nn.Linear(mlp_dim, mlp_dim),\n","            # nn.ReLU(),\n","            # nn.Linear(mlp_dim, mlp_dim),\n","            # nn.ReLU(),            \n","            nn.Linear(mlp_dim, labels_count)\n","        )\n","        self.mlp2 = nn.Sequential(\n","            nn.Linear(hidden_dim , mlp_dim),\n","            nn.ReLU(),         \n","            nn.Linear(mlp_dim, skill_label_count)\n","        )\n","        # self.softmax = nn.LogSoftmax(dim=1)\n","        if freeze_bert:\n","            print(\"Freezing layers\")\n","            for param in self.bert.parameters():\n","                param.requires_grad = False\n","\n","    def forward(self, tokens, masks):\n","        _,pooled_output = self.bert(tokens, attention_mask=masks)\n","\n","        dropout_output = self.dropout(pooled_output)\n","        concat_output = dropout_output\n","        mlp_output = self.mlp(concat_output)\n","        skill_output = self.mlp2(concat_output)\n","        # proba = self.sigmoid(mlp_output)\n","        # proba = self.softmax(mlp_output)\n","\n","        return mlp_output,skill_output"],"execution_count":66,"outputs":[]},{"cell_type":"code","metadata":{"id":"PzdVd6lUEfv8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4f713332-f11e-475e-8dbf-4f25405d37c0","executionInfo":{"status":"ok","timestamp":1643567197614,"user_tz":-330,"elapsed":19,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["num_classes"],"execution_count":67,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","metadata":{"id":"kctN7UA1bhCx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0fccc4ca-337d-426d-a277-77a9e31cb454","executionInfo":{"status":"ok","timestamp":1643567203298,"user_tz":-330,"elapsed":5700,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["model_multi_task = MultiClassClassifier('bert-base-uncased',3, 5,768,500,140,dropout=0.1,freeze_bert=False)\n","model_multi_task.load_state_dict(torch.load('model_bert_multi_task_prediction/model_weights'))\n","model_multi_task.cuda()"],"execution_count":68,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MultiClassClassifier(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (mlp): Sequential(\n","    (0): Linear(in_features=768, out_features=500, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=500, out_features=3, bias=True)\n","  )\n","  (mlp2): Sequential(\n","    (0): Linear(in_features=768, out_features=500, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=500, out_features=5, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":68}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6RuioUjMvcHi","outputId":"195cdbc7-bf31-41db-f3ce-47b3b03b08b0","executionInfo":{"status":"ok","timestamp":1643567216018,"user_tz":-330,"elapsed":5149,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["model_cascade = MultiClassClassifier('bert-base-uncased',num_classes, 768,500,140,dropout=0.1,freeze_bert=False)\n","\n","model_cascade.load_state_dict(torch.load(\"model_bert_difficulty_cascade/model_weights\"))"],"execution_count":70,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":70}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sj4KoYVkNJm-","outputId":"a8495419-971a-4d0e-8656-a8bc6ae6f79a","executionInfo":{"status":"ok","timestamp":1643567216019,"user_tz":-330,"elapsed":35,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["model_cascade.cuda()"],"execution_count":71,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MultiClassClassifier(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (mlp): Sequential(\n","    (0): Linear(in_features=768, out_features=500, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=500, out_features=3, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","metadata":{"id":"rYLxYivOFpKo","executionInfo":{"status":"ok","timestamp":1643567223036,"user_tz":-330,"elapsed":628,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["from torch import nn\n","\n","\n","class AttentionBlock(nn.Module):\n","  def __init__(self,vector_1_dim,vector_2_dim):\n","    super(AttentionBlock, self).__init__()\n","    self.Weights = nn.Parameter(torch.rand(vector_2_dim,vector_1_dim))\n","    self.bias = nn.Parameter(torch.zeros(1))\n","\n","  def forward(self,vector_1,vector_2):\n","    #(batch_size,vector_2_dim,vector_1_dim)\n","    weights = self.Weights.repeat(vector_2.size(0),1,1)\n","    vector_1 = vector_1.unsqueeze(-1)  # (batch_size,vector_2_dim,vector_1_dim)\n","    weights = weights.matmul(vector_1) # results in (batch_size,vector_2_dim,1)\n","    weights = weights.repeat(vector_2.size(1),1,1,1).transpose(0,1)\n","    vector_2 = vector_2.unsqueeze(-2)\n","    attention_weights = torch.tanh(vector_2.matmul(weights).squeeze() + self.bias) # batch_size, vector_2_dim.size(0)\n","    if len(attention_weights.shape) ==1:\n","      attention_weights = attention_weights.squeeze()\n","      attention_weights = attention_weights.reshape(1,-1)\n","    attention_weights = attention_weights.squeeze()\n","    # print(\"torch.exp(attention_weights)\",torch.exp(attention_weights).shape,attention_weights.shape,torch.exp(attention_weights).sum(dim=1).shape)\n","    attention_weights = torch.exp(attention_weights)/ torch.exp(attention_weights).sum(dim=1,keepdim=True)\n","\n","    return attention_weights\n","\n","# bloom interactive attention\n","class MultiClassClassifier(nn.Module):\n","    def __init__(self, bert_model_path, labels_count,skill_label_count, hidden_dim=768, mlp_dim=500, extras_dim=140, dropout=0.1, freeze_bert=False):\n","        super().__init__()\n","\n","        self.bert = BertModel.from_pretrained(bert_model_path,output_hidden_states=True,output_attentions=True)\n","        self.dropout = nn.Dropout(dropout)\n","        self.bloom_attention = AttentionBlock(768, 768)\n","\n","        self.mlp = nn.Sequential(\n","            nn.Linear(hidden_dim , mlp_dim),\n","            nn.ReLU(),\n","            # nn.Linear(mlp_dim, mlp_dim),\n","            # nn.ReLU(),\n","            # nn.Linear(mlp_dim, mlp_dim),\n","            # nn.ReLU(),            \n","            nn.Linear(mlp_dim, labels_count)\n","        )\n","        self.mlp2 = nn.Sequential(  \n","            nn.Linear(hidden_dim , mlp_dim),\n","            nn.ReLU(),         \n","            nn.Linear(mlp_dim, skill_label_count)\n","        )\n","        # self.softmax = nn.LogSoftmax(dim=1)\n","        if freeze_bert:\n","            print(\"Freezing layers\")\n","            for param in self.bert.parameters():\n","                param.requires_grad = False\n","\n","    def forward(self, tokens, masks):\n","        _, pooled_output,hidden_states,attentions = self.bert(tokens, attention_mask=masks)\n","        dropout_output = self.dropout(pooled_output)\n","        concat_output = dropout_output\n","\n","        # mlp_output = self.mlp(concat_output)\n","        skill_output_probas = self.mlp2(concat_output)\n","        skill_output = torch.argmax(skill_output_probas,axis=1).cpu().numpy()\n","        skill_output = LE_skill.inverse_transform(skill_output)\n","        skill_input_ids = []\n","        skill_attention_masks = []\n","        for skill_text in skill_output:\n","          encoded_skill_output = tokenizer.encode_plus(\n","                          skill_text,                      # Sentence to encode.\n","                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                          max_length = 128,           # Pad & truncate all sentences.\n","                          pad_to_max_length = True,\n","                          truncation=True,\n","                          return_attention_mask = True,   # Construct attn. masks.\n","                          return_tensors = 'pt',     # Return pytorch tensors.\n","                    )\n","          skill_input_ids.append(encoded_skill_output['input_ids'])\n","          skill_attention_masks.append(encoded_skill_output['attention_mask'])\n","        skill_input_ids = torch.cat(skill_input_ids,dim=0).cuda()\n","        skill_attention_masks = torch.cat(skill_attention_masks,dim=0).cuda()\n","        _,_,hidden_states_skill,_ = self.bert(skill_input_ids,skill_attention_masks)\n","\n","        skill_hidden_averaged =  torch.sum(hidden_states_skill[12],dim=1)/hidden_states_skill[12].shape[1]\n","\n","        bloom_attention_weights = self.bloom_attention(skill_hidden_averaged, hidden_states[12])\n","\n","        bloom_attention_weights = bloom_attention_weights.unsqueeze(-2)\n","        # print(\"context_attention_weights\",context_attention_weights.shape,context_out.shape)\n","        input_attended_vector = bloom_attention_weights.matmul(hidden_states[12]).squeeze()\n","\n","        mlp_output = self.mlp(input_attended_vector)\n","\n","        # print(\"bloom attention weights\", bloom_attention_weights.shape)\n","        # print(\"_hidden_states\",hidden_states_skill[12].shape, hidden_states[12].shape,skill_hidden_averaged.shape)\n","\n","        # proba = self.sigmoid(mlp_output)\n","        # proba = self.softmax(mlp_output)\n","\n","        return mlp_output,skill_output_probas"],"execution_count":72,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xy6FOcfNRp0P","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f4145bc0-4974-4044-db89-b8b79be7692f","executionInfo":{"status":"ok","timestamp":1643567223038,"user_tz":-330,"elapsed":10,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["skill_label_count = len(list(set(new_data[\"skill_label\"].values)))\n","skill_label_count"],"execution_count":73,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{},"execution_count":73}]},{"cell_type":"code","metadata":{"id":"qIbXoNcuUukV","executionInfo":{"status":"ok","timestamp":1643567237600,"user_tz":-330,"elapsed":12382,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["!cp -r \"/content/drive/MyDrive/research_skill_name_prediction/model_bert_multi_task_interactive_final\" /content/"],"execution_count":74,"outputs":[]},{"cell_type":"code","metadata":{"id":"wDaXrwL5Fut_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"47e56000-f5aa-4dd7-823c-a017075a320c","executionInfo":{"status":"ok","timestamp":1643567241633,"user_tz":-330,"elapsed":4043,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["model_interactive = MultiClassClassifier('bert-base-uncased',num_classes, skill_label_count,768,500,140,dropout=0.1,freeze_bert=False)\n","model_interactive.load_state_dict(torch.load(\"model_bert_multi_task_interactive_final/model_weights\"))\n","model_interactive.cuda()"],"execution_count":75,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MultiClassClassifier(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (bloom_attention): AttentionBlock()\n","  (mlp): Sequential(\n","    (0): Linear(in_features=768, out_features=500, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=500, out_features=3, bias=True)\n","  )\n","  (mlp2): Sequential(\n","    (0): Linear(in_features=768, out_features=500, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=500, out_features=5, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":75}]},{"cell_type":"code","metadata":{"id":"VP9As7pNfeVC","executionInfo":{"status":"ok","timestamp":1643567250197,"user_tz":-330,"elapsed":8576,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["!cp -r \"/content/drive/MyDrive/research_skill_name_prediction/model_bert_multi_task_interactive_skill_given_final\" /content"],"execution_count":76,"outputs":[]},{"cell_type":"code","metadata":{"id":"yjCpYGCyfZlf","executionInfo":{"status":"ok","timestamp":1643567250207,"user_tz":-330,"elapsed":52,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["from torch import nn\n","\n","\n","class Attention(nn.Module):\n","  def __init__(self,vector_1_dim,vector_2_dim):\n","    super(Attention, self).__init__()\n","    self.Weights = nn.Parameter(torch.rand(vector_2_dim,vector_1_dim))\n","    self.bias = nn.Parameter(torch.zeros(1))\n","\n","  def forward(self,vector_1,vector_2):\n","    #(batch_size,vector_2_dim,vector_1_dim)\n","    weights = self.Weights.repeat(vector_2.size(0),1,1)\n","    vector_1 = vector_1.unsqueeze(-1)  # (batch_size,vector_2_dim,vector_1_dim)\n","    weights = weights.matmul(vector_1) # results in (batch_size,vector_2_dim,1)\n","    weights = weights.repeat(vector_2.size(1),1,1,1).transpose(0,1)\n","    vector_2 = vector_2.unsqueeze(-2)\n","    attention_weights = torch.tanh(vector_2.matmul(weights).squeeze() + self.bias) # batch_size, vector_2_dim.size(0)\n","    if len(attention_weights.shape) ==1:\n","      attention_weights = attention_weights.squeeze()\n","      attention_weights = attention_weights.reshape(1,-1)\n","    attention_weights = attention_weights.squeeze()\n","    # print(\"torch.exp(attention_weights)\",torch.exp(attention_weights).shape,attention_weights.shape,torch.exp(attention_weights).sum(dim=1).shape)\n","    attention_weights = torch.exp(attention_weights)/ torch.exp(attention_weights).sum(dim=1,keepdim=True)\n","\n","    return attention_weights\n","\n","# bloom interactive attention\n","class MultiClassClassifier(nn.Module):\n","    def __init__(self, bert_model_path, labels_count,skill_label_count, hidden_dim=768, mlp_dim=500, extras_dim=140, dropout=0.1, freeze_bert=False):\n","        super().__init__()\n","\n","        self.bert = BertModel.from_pretrained(bert_model_path,output_hidden_states=True,output_attentions=True)\n","        self.dropout = nn.Dropout(dropout)\n","        self.bloom_attention = Attention(768, 768)\n","\n","        self.mlp = nn.Sequential(\n","            nn.Linear(hidden_dim , mlp_dim),\n","            nn.ReLU(),\n","            # nn.Linear(mlp_dim, mlp_dim),\n","            # nn.ReLU(),\n","            # nn.Linear(mlp_dim, mlp_dim),\n","            # nn.ReLU(),            \n","            nn.Linear(mlp_dim, labels_count)\n","        )\n","        self.mlp2 = nn.Sequential(  \n","            nn.Linear(hidden_dim , mlp_dim),\n","            nn.ReLU(),         \n","            nn.Linear(mlp_dim, skill_label_count)\n","        )\n","        # self.softmax = nn.LogSoftmax(dim=1)\n","        if freeze_bert:\n","            print(\"Freezing layers\")\n","            for param in self.bert.parameters():\n","                param.requires_grad = False\n","\n","    def forward(self, tokens, masks,skill_label):\n","        _, pooled_output,hidden_states,attentions = self.bert(tokens, attention_mask=masks)\n","        # dropout_output = self.dropout(pooled_output)\n","        # concat_output = dropout_output\n","\n","        # # mlp_output = self.mlp(concat_output)\n","        # skill_output_probas = self.mlp2(concat_output)\n","        # skill_output = torch.argmax(skill_output_probas,axis=1).cpu().numpy()\n","        # skill_output = LE_skill.inverse_transform(skill_output)\n","        skill_input_ids = []\n","        skill_attention_masks = []\n","        skill_label = skill_label.cpu().numpy()\n","        skill_label = LE_skill.inverse_transform(skill_label)\n","\n","        for skill_text in skill_label:\n","          encoded_skill_output = tokenizer.encode_plus(\n","                          skill_text,                      # Sentence to encode.\n","                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                          max_length = 128,           # Pad & truncate all sentences.\n","                          pad_to_max_length = True,\n","                          truncation=True,\n","                          return_attention_mask = True,   # Construct attn. masks.\n","                          return_tensors = 'pt',     # Return pytorch tensors.\n","                    )\n","          skill_input_ids.append(encoded_skill_output['input_ids'])\n","          skill_attention_masks.append(encoded_skill_output['attention_mask'])\n","        skill_input_ids = torch.cat(skill_input_ids,dim=0).cuda()\n","        skill_attention_masks = torch.cat(skill_attention_masks,dim=0).cuda()\n","        _,_,hidden_states_skill,_ = self.bert(skill_input_ids,skill_attention_masks)\n","\n","        skill_hidden_averaged =  torch.sum(hidden_states_skill[12],dim=1)/hidden_states_skill[12].shape[1]\n","\n","        bloom_attention_weights = self.bloom_attention(skill_hidden_averaged, hidden_states[12])\n","\n","        bloom_attention_weights = bloom_attention_weights.unsqueeze(-2)\n","        # print(\"context_attention_weights\",context_attention_weights.shape,context_out.shape)\n","        input_attended_vector = bloom_attention_weights.matmul(hidden_states[12]).squeeze()\n","        # print(\"input_attended_vector\",input_attended_vector.shape)\n","        mlp_output = self.mlp(input_attended_vector)\n","\n","        # print(\"bloom attention weights\", bloom_attention_weights.shape)\n","        # print(\"_hidden_states\",hidden_states_skill[12].shape, hidden_states[12].shape,skill_hidden_averaged.shape)\n","\n","        # proba = self.sigmoid(mlp_output)\n","        # proba = self.softmax(mlp_output)\n","\n","        return mlp_output"],"execution_count":77,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kNnbEpYvfb57","outputId":"fd90ebea-e45c-4709-e3d7-0b04d1bede37","executionInfo":{"status":"ok","timestamp":1643567254171,"user_tz":-330,"elapsed":4011,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["model_skill_given = MultiClassClassifier('bert-base-uncased',num_classes, skill_label_count,768,500,140,dropout=0.1,freeze_bert=False)\n","model_skill_given.load_state_dict(torch.load(\"model_bert_multi_task_interactive_skill_given_final/model_weights\"))\n","model_skill_given.cuda()"],"execution_count":78,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MultiClassClassifier(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (bloom_attention): Attention()\n","  (mlp): Sequential(\n","    (0): Linear(in_features=768, out_features=500, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=500, out_features=3, bias=True)\n","  )\n","  (mlp2): Sequential(\n","    (0): Linear(in_features=768, out_features=500, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=500, out_features=5, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":78}]},{"cell_type":"code","metadata":{"id":"nQ9_trOX96Tv","executionInfo":{"status":"ok","timestamp":1643567254172,"user_tz":-330,"elapsed":34,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["from torch import nn\n","class SkillClassifier(nn.Module):\n","    def __init__(self, bert_model_path, labels_count, hidden_dim=768, mlp_dim=500, extras_dim=140, dropout=0.1, freeze_bert=False):\n","        super().__init__()\n","\n","        self.bert = BertModel.from_pretrained(bert_model_path,output_hidden_states=True,output_attentions=True)\n","        self.dropout = nn.Dropout(dropout)\n","        self.mlp = nn.Sequential(\n","            nn.Linear(hidden_dim , mlp_dim),\n","            nn.ReLU(),\n","            # nn.Linear(mlp_dim, mlp_dim),\n","            # nn.ReLU(),\n","            # nn.Linear(mlp_dim, mlp_dim),\n","            # nn.ReLU(),            \n","            nn.Linear(mlp_dim, 5)\n","        )\n","        # self.softmax = nn.LogSoftmax(dim=1)\n","        if freeze_bert:\n","            print(\"Freezing layers\")\n","            for param in self.bert.parameters():\n","                param.requires_grad = False\n","\n","    def forward(self, tokens, masks):\n","        _, pooled_output,_,_ = self.bert(tokens, attention_mask=masks)\n","        dropout_output = self.dropout(pooled_output)\n","        concat_output = dropout_output\n","        mlp_output = self.mlp(concat_output)\n","        # proba = self.sigmoid(mlp_output)\n","        # proba = self.softmax(mlp_output)\n","\n","        return mlp_output"],"execution_count":79,"outputs":[]},{"cell_type":"code","metadata":{"id":"kucz3b5-Uq-A","executionInfo":{"status":"ok","timestamp":1643567266184,"user_tz":-330,"elapsed":12044,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["!cp -r \"/content/drive/MyDrive/research_skill_name_prediction/qdiff_skill_only_prediction_bert\" /content"],"execution_count":80,"outputs":[]},{"cell_type":"code","metadata":{"id":"7uqkkw379_WB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ec005dd0-2e5c-4e94-c7d7-a4fa158c2e1f","executionInfo":{"status":"ok","timestamp":1643567269997,"user_tz":-330,"elapsed":3817,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["skill_model = SkillClassifier('bert-base-uncased',num_classes, 768,500,140,dropout=0.1,freeze_bert=False)\n","skill_model.load_state_dict(torch.load(\"qdiff_skill_only_prediction_bert/model_weights\"))\n","skill_model.cuda()"],"execution_count":81,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SkillClassifier(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (mlp): Sequential(\n","    (0): Linear(in_features=768, out_features=500, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=500, out_features=5, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":81}]},{"cell_type":"code","metadata":{"id":"t19eboqPUFw9","executionInfo":{"status":"ok","timestamp":1643567269998,"user_tz":-330,"elapsed":21,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["from torch import nn\n","\n","\n","class Attention(nn.Module):\n","  def __init__(self,vector_1_dim,vector_2_dim):\n","    super(Attention, self).__init__()\n","    self.Weights = nn.Parameter(torch.rand(vector_2_dim,vector_1_dim))\n","    self.bias = nn.Parameter(torch.zeros(1))\n","\n","  def forward(self,vector_1,vector_2):\n","    #(batch_size,vector_2_dim,vector_1_dim)\n","    weights = self.Weights.repeat(vector_2.size(0),1,1)\n","    vector_1 = vector_1.unsqueeze(-1)  # (batch_size,vector_2_dim,vector_1_dim)\n","    weights = weights.matmul(vector_1) # results in (batch_size,vector_2_dim,1)\n","    weights = weights.repeat(vector_2.size(1),1,1,1).transpose(0,1)\n","    vector_2 = vector_2.unsqueeze(-2)\n","    attention_weights = torch.tanh(vector_2.matmul(weights).squeeze() + self.bias) # batch_size, vector_2_dim.size(0)\n","    if len(attention_weights.shape) ==1:\n","      attention_weights = attention_weights.squeeze()\n","      attention_weights = attention_weights.reshape(1,-1)\n","    attention_weights = attention_weights.squeeze()\n","    # print(\"torch.exp(attention_weights)\",torch.exp(attention_weights).shape,attention_weights.shape,torch.exp(attention_weights).sum(dim=1).shape)\n","    attention_weights = torch.exp(attention_weights)/ torch.exp(attention_weights).sum(dim=1,keepdim=True)\n","\n","    return attention_weights\n","\n","# bloom interactive attention\n","class MultiClassClassifier(nn.Module):\n","    def __init__(self, bert_model_path, labels_count,skill_label_count, hidden_dim=768, mlp_dim=500, extras_dim=140, dropout=0.1, freeze_bert=False):\n","        super().__init__()\n","\n","        self.bert = BertModel.from_pretrained(bert_model_path,output_hidden_states=True,output_attentions=True)\n","\n","        self.skill_bert = skill_model\n","        self.dropout = nn.Dropout(dropout)\n","        self.bloom_attention = Attention(768, 768)\n","\n","        self.mlp = nn.Sequential(\n","            nn.Linear(hidden_dim , mlp_dim),\n","            nn.ReLU(),\n","            # nn.Linear(mlp_dim, mlp_dim),\n","            # nn.ReLU(),\n","            # nn.Linear(mlp_dim, mlp_dim),\n","            # nn.ReLU(),            \n","            nn.Linear(mlp_dim, labels_count)\n","        )\n","        self.mlp2 = nn.Sequential(  \n","            nn.Linear(hidden_dim , mlp_dim),\n","            nn.ReLU(),         \n","            nn.Linear(mlp_dim, skill_label_count)\n","        )\n","        # self.softmax = nn.LogSoftmax(dim=1)\n","        if freeze_bert:\n","            print(\"Freezing layers\")\n","            for param in self.bert.parameters():\n","                param.requires_grad = False\n","\n","    def forward(self, tokens, masks):\n","        _, pooled_output,hidden_states,attentions = self.bert(tokens, attention_mask=masks)\n","        dropout_output = self.dropout(pooled_output)\n","        concat_output = dropout_output\n","\n","        # mlp_output = self.mlp(concat_output)\n","        skill_output_probas = self.skill_bert(tokens,masks)\n","        skill_output = torch.argmax(skill_output_probas,axis=1).cpu().numpy()\n","        skill_output = LE_skill.inverse_transform(skill_output)\n","        skill_input_ids = []\n","        skill_attention_masks = []\n","        for skill_text in skill_output:\n","          encoded_skill_output = tokenizer.encode_plus(\n","                          skill_text,                      # Sentence to encode.\n","                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                          max_length = 128,           # Pad & truncate all sentences.\n","                          pad_to_max_length = True,\n","                          truncation=True,\n","                          return_attention_mask = True,   # Construct attn. masks.\n","                          return_tensors = 'pt',     # Return pytorch tensors.\n","                    )\n","          skill_input_ids.append(encoded_skill_output['input_ids'])\n","          skill_attention_masks.append(encoded_skill_output['attention_mask'])\n","        skill_input_ids = torch.cat(skill_input_ids,dim=0).cuda()\n","        skill_attention_masks = torch.cat(skill_attention_masks,dim=0).cuda()\n","        _,_,hidden_states_skill,_ = self.skill_bert.bert(skill_input_ids,skill_attention_masks)\n","\n","        skill_hidden_averaged =  torch.sum(hidden_states_skill[12],dim=1)/hidden_states_skill[12].shape[1]\n","\n","        bloom_attention_weights = self.bloom_attention(skill_hidden_averaged, hidden_states[12])\n","\n","        bloom_attention_weights = bloom_attention_weights.unsqueeze(-2)\n","        # print(\"context_attention_weights\",context_attention_weights.shape,context_out.shape)\n","        input_attended_vector = bloom_attention_weights.matmul(hidden_states[12]).squeeze()\n","\n","        mlp_output = self.mlp(input_attended_vector)\n","\n","        # print(\"bloom attention weights\", bloom_attention_weights.shape)\n","        # print(\"_hidden_states\",hidden_states_skill[12].shape, hidden_states[12].shape,skill_hidden_averaged.shape)\n","\n","        # proba = self.sigmoid(mlp_output)\n","        # proba = self.softmax(mlp_output)\n","\n","\n","        return mlp_output,skill_output_probas"],"execution_count":82,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eBIZgO4OUF1O","outputId":"73203107-6630-4936-84f5-c14fdd83364b","executionInfo":{"status":"ok","timestamp":1643567276873,"user_tz":-330,"elapsed":6894,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["model_interactive_pre_trained = MultiClassClassifier('bert-base-uncased',num_classes, skill_label_count,768,500,140,dropout=0.1,freeze_bert=False)\n","model_interactive_pre_trained.load_state_dict(torch.load(\"model_bert_multi_task_interactive_pre_trained_skill_bert/model_weights\"))\n","model_interactive_pre_trained.cuda()\n"],"execution_count":83,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MultiClassClassifier(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (skill_bert): SkillClassifier(\n","    (bert): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (mlp): Sequential(\n","      (0): Linear(in_features=768, out_features=500, bias=True)\n","      (1): ReLU()\n","      (2): Linear(in_features=500, out_features=5, bias=True)\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (bloom_attention): Attention()\n","  (mlp): Sequential(\n","    (0): Linear(in_features=768, out_features=500, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=500, out_features=3, bias=True)\n","  )\n","  (mlp2): Sequential(\n","    (0): Linear(in_features=768, out_features=500, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=500, out_features=5, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":83}]},{"cell_type":"code","metadata":{"id":"6gtKYG0VeVwk","executionInfo":{"status":"ok","timestamp":1643567284271,"user_tz":-330,"elapsed":815,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["# for param in model.bert.encoder.layer[0:12].parameters():\n","#     param.requires_grad=False\n","# for param in model.bert.embeddings.parameters():\n","#     param.requires_grad=False\n"],"execution_count":84,"outputs":[]},{"cell_type":"code","metadata":{"id":"awQ2Y9Jb3kht","executionInfo":{"status":"ok","timestamp":1643567284909,"user_tz":-330,"elapsed":4,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )"],"execution_count":85,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Ys-M4-e3khv","executionInfo":{"status":"ok","timestamp":1643567286771,"user_tz":-330,"elapsed":2,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["\n","from transformers import get_linear_schedule_with_warmup\n","\n","\n","epochs = 30\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","total_steps = len(train_dataloader) * epochs\n","\n"],"execution_count":86,"outputs":[]},{"cell_type":"code","metadata":{"id":"QrYqErOD3khx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"19146f47-51f2-498b-ed8d-596296099ba0","executionInfo":{"status":"ok","timestamp":1643567287878,"user_tz":-330,"elapsed":623,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["len(train_dataloader) "],"execution_count":87,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1151"]},"metadata":{},"execution_count":87}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EWVSE9LM3kh0","outputId":"bdb557e1-df4c-4a5f-c874-f327d00fef51","executionInfo":{"status":"ok","timestamp":1643567287880,"user_tz":-330,"elapsed":10,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["1935 * 32"],"execution_count":88,"outputs":[{"output_type":"execute_result","data":{"text/plain":["61920"]},"metadata":{},"execution_count":88}]},{"cell_type":"code","metadata":{"id":"rcvxVVi63kh3","executionInfo":{"status":"ok","timestamp":1643567288481,"user_tz":-330,"elapsed":5,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":89,"outputs":[]},{"cell_type":"code","metadata":{"id":"GUw3zm6g3kh5","executionInfo":{"status":"ok","timestamp":1643567290200,"user_tz":-330,"elapsed":8,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":90,"outputs":[]},{"cell_type":"code","metadata":{"id":"ta6zfUTa3kh7","executionInfo":{"status":"ok","timestamp":1643567290202,"user_tz":-330,"elapsed":9,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":91,"outputs":[]},{"cell_type":"code","metadata":{"id":"GFq9gd5kQSHb","executionInfo":{"status":"ok","timestamp":1643567290203,"user_tz":-330,"elapsed":8,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"],"execution_count":92,"outputs":[]},{"cell_type":"code","metadata":{"id":"9AjZgn3fwTmX","executionInfo":{"status":"ok","timestamp":1643567290743,"user_tz":-330,"elapsed":3,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'checkpoint.pt'\n","            trace_func (function): trace print function.\n","                            Default: print            \n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","        self.trace_func = trace_func\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss"],"execution_count":93,"outputs":[]},{"cell_type":"code","metadata":{"id":"-qclnCpSZb2O","executionInfo":{"status":"ok","timestamp":1643567292513,"user_tz":-330,"elapsed":3,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["loss_func = nn.CrossEntropyLoss()"],"execution_count":94,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"FcSwwzAFyE7S","outputId":"e480e7c4-1345-4b2b-f994-a5259271615e","executionInfo":{"status":"ok","timestamp":1643567293002,"user_tz":-330,"elapsed":11,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["test"],"execution_count":95,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-19e0c4c6-419e-4bbf-a5a9-ede8385d0685\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>board_syllabus</th>\n","      <th>question_answer</th>\n","      <th>skill_label</th>\n","      <th>difficulty_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>CBSE&gt;&gt;Nursery&gt;&gt;Environmental Science&gt;&gt;Common V...</td>\n","      <td>Write down the names of some common vegetable...</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>CBSE&gt;&gt;XII&gt;&gt;Physics&gt;&gt;Physics : Part - II&gt;&gt;Atoms</td>\n","      <td>Name the series of hydrogen atom which lies i...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ICSE OLD&gt;&gt;XI&gt;&gt;Political Science&gt;&gt;State, Govern...</td>\n","      <td>Which of the following is not the element of ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Maharashtra New&gt;&gt;VII&gt;&gt;General Science&gt;&gt;Static ...</td>\n","      <td>The process of electrically charging an objec...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Tamil Nadu&gt;&gt;IX&gt;&gt;Science&gt;&gt;Physics&gt;&gt;Measurement&gt;...</td>\n","      <td>The mass of an object is measured in kilogram...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4572</th>\n","      <td>ICSE OLD&gt;&gt;VIII&gt;&gt;Biology&gt;&gt;Nervous System And Se...</td>\n","      <td>Which of the following is the first cranial n...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4573</th>\n","      <td>CBSE&gt;&gt;VII&gt;&gt;Computer Science&gt;&gt;Advance features ...</td>\n","      <td>To ungroup the worksheets: Right-click on any...</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4574</th>\n","      <td>CBSE&gt;&gt;VIII&gt;&gt;Science&gt;&gt;Chemical Effects of Elect...</td>\n","      <td>After passing electricity through a solution ...</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4575</th>\n","      <td>CLSP&gt;&gt;Stage 9&gt;&gt;Science&gt;&gt;Chemistry&gt;&gt;Material pr...</td>\n","      <td>Identify the scientists who gave the “plum-pu...</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4576</th>\n","      <td>AP&gt;&gt;VIII&gt;&gt;Physical Science&gt;&gt;Physical Science (...</td>\n","      <td>What do you understand by the term static ele...</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4577 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19e0c4c6-419e-4bbf-a5a9-ede8385d0685')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-19e0c4c6-419e-4bbf-a5a9-ede8385d0685 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-19e0c4c6-419e-4bbf-a5a9-ede8385d0685');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                         board_syllabus  ... difficulty_label\n","0     CBSE>>Nursery>>Environmental Science>>Common V...  ...                2\n","1        CBSE>>XII>>Physics>>Physics : Part - II>>Atoms  ...                1\n","2     ICSE OLD>>XI>>Political Science>>State, Govern...  ...                0\n","3     Maharashtra New>>VII>>General Science>>Static ...  ...                1\n","4     Tamil Nadu>>IX>>Science>>Physics>>Measurement>...  ...                1\n","...                                                 ...  ...              ...\n","4572  ICSE OLD>>VIII>>Biology>>Nervous System And Se...  ...                1\n","4573  CBSE>>VII>>Computer Science>>Advance features ...  ...                0\n","4574  CBSE>>VIII>>Science>>Chemical Effects of Elect...  ...                2\n","4575  CLSP>>Stage 9>>Science>>Chemistry>>Material pr...  ...                0\n","4576  AP>>VIII>>Physical Science>>Physical Science (...  ...                1\n","\n","[4577 rows x 4 columns]"]},"metadata":{},"execution_count":95}]},{"cell_type":"code","metadata":{"id":"4178_yLFMWmx","executionInfo":{"status":"ok","timestamp":1643567306408,"user_tz":-330,"elapsed":609,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["test_features = test[\"question_answer\"].values\n","test_labels = test[\"difficulty_label\"].values\n","test_skill_labels = test[\"skill_label\"].values"],"execution_count":96,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DggP9Sxdv_-l","outputId":"80135f81-983b-4bb9-d103-606ec00eca1d","executionInfo":{"status":"ok","timestamp":1643567307058,"user_tz":-330,"elapsed":3,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["\n","\n","\n","\n","test_labels"],"execution_count":97,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2, 1, 0, ..., 2, 0, 1])"]},"metadata":{},"execution_count":97}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ZpmBJuIC2nM","outputId":"405099ae-7573-4814-f9aa-520d48d54c40","executionInfo":{"status":"ok","timestamp":1643567307736,"user_tz":-330,"elapsed":3,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["test_features"],"execution_count":98,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([' Write down the names of some common vegetables. Answer may vary Probable answer – Names of some common vegetables are potato, onion, tomato and carrot. ',\n","       ' Name the series of hydrogen atom which lies in the U.V region. Lyman series lies in the U.V region. ',\n","       ' Which of the following is not the element of an association? Relationships are abstract Each association has elements 1) a group of people, 2) voluntary Membership, 3) shared and common interests or needs as the basis, 4) some set of objective goals which are to be achieved collectively by all the members, 5) a voluntary organisation, and 6) co-operation among the members objectives pooled resources for funds needed for action.',\n","       ...,\n","       ' After passing electricity through a solution the change that takes place is a chemical change Physical changes are those changes that do not result in the production of a new substance whereas a chemical change involves the production of a new substance. For example: When electricity is passed in a solution containing water, bubbles of hydrogen and oxygen are formed.',\n","       ' Identify the scientists who gave the “plum-pudding” model of the atom. J. J. Thomson The &ldquo;plum-pudding&rdquo; model of the atom was developed by the J. J Thomson. He compared his model used for describing the structure of atom with a plum pudding in which negatively charged electrons were surrounded by a positively charged &lsquo;pudding&rsquo;.',\n","       ' What do you understand by the term static electricity? It is the electricity developed due to stationary electric charges on the body. '],\n","      dtype=object)"]},"metadata":{},"execution_count":98}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"MlOvANUwprAw","outputId":"960e1ab8-e847-4dff-bd2f-836c8910456c","executionInfo":{"status":"ok","timestamp":1643567309936,"user_tz":-330,"elapsed":657,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["test_features[0]"],"execution_count":99,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["' Write down the names of some common vegetables. Answer may vary Probable answer – Names of some common vegetables are potato, onion, tomato and carrot. '"]},"metadata":{},"execution_count":99}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LmmWYcW2sNHe","outputId":"37d4cbe4-b8dd-4095-b88e-dd777d82fec9","executionInfo":{"status":"ok","timestamp":1643567315666,"user_tz":-330,"elapsed":5738,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["input_ids = []\n","attention_masks = []\n","for sent in test_features:\n","\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 128,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        truncation=True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","test_labels = torch.tensor(test_labels)\n","test_skill_labels = torch.tensor(test_skill_labels)\n","\n","# Set the batch size.  \n","batch_size = 34\n","\n","# test_poincare_tensor = torch.tensor(poincare_embeddings_final,dtype=torch.float)\n","# print(test_poincare_tensor.shape)\n","# difficulty_tensor = torch.tensor(difficulty_level_vectors,dtype=torch.float)\n","# print(\"difficulty_tensor\",difficulty_tensor.shape)\n","# Combine the training inputs into a TensorDataset.\n","prediction_data = TensorDataset(input_ids, attention_masks, test_labels,test_skill_labels)\n","# Create the DataLoader.\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"execution_count":100,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KkLhcFdI9doK","outputId":"32d5e885-ba29-404f-af00-bffc5b880582","executionInfo":{"status":"ok","timestamp":1643567331001,"user_tz":-330,"elapsed":15364,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["\n","\n","!pip install ax-platform==0.1.9"],"execution_count":101,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ax-platform==0.1.9\n","  Downloading ax_platform-0.1.9-py3-none-any.whl (499 kB)\n","\u001b[?25l\r\u001b[K     |▋                               | 10 kB 22.5 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 30 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 40 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████                            | 61 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 71 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 81 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████                          | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 276 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 286 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 296 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 307 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 317 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 327 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 337 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 348 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 358 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 368 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 378 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 389 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 399 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 409 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 419 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 430 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 440 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 450 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 460 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 471 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 481 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 491 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 499 kB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from ax-platform==0.1.9) (2.11.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from ax-platform==0.1.9) (1.0.2)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from ax-platform==0.1.9) (5.5.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ax-platform==0.1.9) (1.1.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from ax-platform==0.1.9) (1.4.1)\n","Collecting botorch==0.2.1\n","  Downloading botorch-0.2.1-py3-none-any.whl (221 kB)\n","\u001b[K     |████████████████████████████████| 221 kB 24.2 MB/s \n","\u001b[?25hCollecting gpytorch>=1.0.0\n","  Downloading gpytorch-1.6.0.tar.gz (310 kB)\n","\u001b[K     |████████████████████████████████| 310 kB 39.5 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from botorch==0.2.1->ax-platform==0.1.9) (1.10.0+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->botorch==0.2.1->ax-platform==0.1.9) (3.10.0.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->ax-platform==0.1.9) (2.0.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->ax-platform==0.1.9) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ax-platform==0.1.9) (2.8.2)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->ax-platform==0.1.9) (1.19.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->ax-platform==0.1.9) (1.15.0)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->ax-platform==0.1.9) (8.0.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->ax-platform==0.1.9) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->ax-platform==0.1.9) (3.0.0)\n","Building wheels for collected packages: gpytorch\n","  Building wheel for gpytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gpytorch: filename=gpytorch-1.6.0-py2.py3-none-any.whl size=509889 sha256=8a495060371c58d1655c4e9f9d8b68d082e9a0d2d60f9bd3a498a2792bb9d38f\n","  Stored in directory: /root/.cache/pip/wheels/66/b5/89/34c06ad393a6feb72b4cdde46d0f1c667f3e2632960f9df109\n","Successfully built gpytorch\n","Installing collected packages: gpytorch, botorch, ax-platform\n","Successfully installed ax-platform-0.1.9 botorch-0.2.1 gpytorch-1.6.0\n"]}]},{"cell_type":"code","metadata":{"id":"G0H4JBrl-FnZ","executionInfo":{"status":"ok","timestamp":1643567336991,"user_tz":-330,"elapsed":684,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["from ax import optimize"],"execution_count":102,"outputs":[]},{"cell_type":"code","metadata":{"id":"SX-RiYbQPDpx","executionInfo":{"status":"ok","timestamp":1643567337372,"user_tz":-330,"elapsed":2,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["from sklearn.metrics import precision_recall_fscore_support\n"],"execution_count":103,"outputs":[]},{"cell_type":"code","metadata":{"id":"zFediYEjlKjX","executionInfo":{"status":"ok","timestamp":1643567339384,"user_tz":-330,"elapsed":4,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["def get_confusion_matrix(predicted,actual):\n","    conf_matrix = np.zeros((3, 3))\n","    for pred,act in zip(predicted,actual):\n","        conf_matrix[act,pred]+=1\n","    return conf_matrix\n","        \n","def get_TP(confusion_matrix,label):\n","    tp = confusion_matrix[label][label]\n","    return tp\n","\n","def get_FN(confusion_matrix,label):\n","    row = confusion_matrix[label,]\n","    row_truepositives = row[label]\n","    fn = row.sum() - row_truepositives\n","    return fn\n","\n","def get_FP(confusion_matrix,tag):\n","    col = confusion_matrix[:,tag]\n","    col_tp = col[tag]\n","    #  sum of all values in column except tp\n","    fp = col.sum() - col_tp\n","    return fp\n","def Precision(conf_matrix):\n","    precision = 0.0\n","    for label in [0,1,2]:\n","        dividor= get_TP(conf_matrix,label)+get_FP(conf_matrix,label)\n","        if dividor != 0.0:\n","            precision += (get_TP(conf_matrix,label))/dividor\n","    return (precision / 3)\n","\n","def Recall(conf_matrix):\n","    recall = 0.0\n","    for label in [0,1,2]:\n","        dividor=get_TP(conf_matrix,label)+get_FN(conf_matrix,label)\n","        if dividor != 0.0:\n","            recall += (get_TP(conf_matrix,label))/dividor\n","    return (recall / 3)\n","\n","def F1(precision,recall):\n","    return (2*precision*recall)/(precision+recall)\n","def accuracy_per_class(preds_flat, labels_flat):\n","\n","    for label in np.unique(labels_flat):\n","        y_preds = preds_flat[labels_flat==label]\n","        y_true = labels_flat[labels_flat==label]\n","        print(f'Class: {label}')\n","        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n","def print_metrics(predictions,test_labels):\n","    conf_matrix = get_confusion_matrix(predictions,test_labels)\n","    precision = Precision(conf_matrix)\n","    recall = Recall(conf_matrix)\n","    f1_score = F1(precision,recall)\n","    return (precision,recall,f1_score)"],"execution_count":104,"outputs":[]},{"cell_type":"code","metadata":{"id":"aFEi23ejPfOm","executionInfo":{"status":"ok","timestamp":1643567339781,"user_tz":-330,"elapsed":2,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["\n","def Precision_macro_weighted(conf_matrix,test_samples):\n","    accum =0\n","    label_wise_precision = dict()\n","    for label in [0,1,2]:\n","        true_sample = [sample for sample in test_samples if sample==label ]\n","        if (get_TP(conf_matrix,label)+get_FP(conf_matrix,label))!=0:\n","            accum+= float(len(true_sample)) *(get_TP(conf_matrix,label)/(get_TP(conf_matrix,label)+get_FP(conf_matrix,label)))\n","            label_wise_precision[label] = get_TP(conf_matrix,label)/(get_TP(conf_matrix,label)+get_FP(conf_matrix,label))\n","\n","    \n","    precision =  accum/len(test_samples)\n","            \n","    return precision\n","\n","\n","def Recall_macro_weighted(conf_matrix,test_samples):\n","    accum =0\n","    label_wise_recall = dict()\n","    for label in [0,1,2]:\n","        true_sample = [sample for sample in test_samples if sample==label ]\n","\n","        if (get_TP(conf_matrix,label)+get_FN(conf_matrix,label))!=0:\n","            accum+= float(len(true_sample)) * (get_TP(conf_matrix,label)/(get_TP(conf_matrix,label)+get_FN(conf_matrix,label)))\n","            label_wise_recall[label] = get_TP(conf_matrix,label)/(get_TP(conf_matrix,label)+get_FN(conf_matrix,label))\n","\n","    \n","    recall =  accum/len(test_samples)\n","    return recall\n","def print_weighted_metrics(predictions,test_labels):\n","    conf_matrix = get_confusion_matrix(predictions,test_labels)\n","    precision = Precision_macro_weighted(conf_matrix,test_labels)\n","    recall = Recall_macro_weighted(conf_matrix,test_labels)\n","    f1_score = F1(precision,recall)\n","    return (precision,recall,f1_score)"],"execution_count":105,"outputs":[]},{"cell_type":"code","metadata":{"id":"9F7JWv8uFrL-","executionInfo":{"status":"ok","timestamp":1643567345947,"user_tz":-330,"elapsed":622,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["def make_lstm_and_gru_predictions(index, params):\n","  model_lstm.eval()\n","  model_gru.eval()\n","  for i,batch in enumerate(test_iter):\n","    outputs = []\n","    if i == index:\n","      # print(\"i\",i,index)\n","      with torch.no_grad():\n","          question, x_len = batch.text\n","          x = question.cuda()\n","          # outs = sigmoid(outs.cpu().data.numpy()).tolist()\n","          y = batch.label.type(torch.long).cuda()\n","          if params['lstm']>=0.5:\n","            lstm_outputs = model_lstm(x,x_len)\n","            outputs.append(lstm_outputs)\n","          if params[\"gru\"]>=0.5:\n","            gru_outputs = model_gru(x,x_len)\n","            outputs.append(gru_outputs)\n","          \n","          return outputs\n","\n"],"execution_count":106,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZqKPe4ZN6vPY","executionInfo":{"status":"ok","timestamp":1643567346673,"user_tz":-330,"elapsed":3,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["def make_predictions(params):\n","  # Prediction on test set\n","    print(params)\n","    print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n","\n","    # Put model in evaluation mode\n","    model.eval()\n","    model_multi_task.eval()\n","    model_cascade.eval()\n","    model_interactive.eval()\n","\n","    # Tracking variables \n","    predictions , true_labels,ids = [], [], []\n","\n","\n","    # Predict \n","    for index,batch in enumerate(prediction_dataloader):\n","      final_outputs = []\n","      # Add batch to GPU\n","      batch = tuple(t.to(device) for t in batch)\n","      \n","      # Unpack the inputs from our dataloader\n","      b_input_ids, b_input_mask, b_labels, skill_labels = batch\n","      # print(\"skill_labels\",skill_labels)\n","      # Telling the model not to compute or store gradients, saving memory and \n","      # speeding up prediction\n","      with torch.no_grad():\n","          # Forward pass, calculate logit predictions\n","          if params['multi_task']>=0.5:\n","            # print(\"multi\")\n","            outputs,_ = model_multi_task(b_input_ids,b_input_mask)\n","            # print(\"outputs\",outputs.shape,b_input_ids.shape,batch[0].shape,index)\n","            final_outputs.append(outputs)\n","          if params['cascade']>=0.5:\n","            # print(\"cascade\")\n","            output_cascade = model_cascade(b_input_ids,b_input_mask)\n","            final_outputs.append(output_cascade)\n","\n","          if params['interactive']>=0.5:\n","            output_interactive, skill_probs  = model_interactive(b_input_ids,b_input_mask)\n","            final_outputs.append(output_interactive)\n","          if params['interactive_given']>0:\n","            outputs,_ = model_interactive_pre_trained(b_input_ids,b_input_mask)\n","            final_outputs.append(outputs)\n","          if params['skill_given']>0:\n","            output_skill_given = model_skill_given(b_input_ids,b_input_mask,skill_labels)\n","            final_outputs.append(output_skill_given)\n","          if params['difficulty'] >=0:\n","            # print(\"normal\")\n","            output_difficulty = model(b_input_ids,b_input_mask)\n","            final_outputs.append(output_difficulty)\n","\n","          out = make_lstm_and_gru_predictions(index,params)\n","          # print(\"out\",out[0].shape,output_difficulty.shape)\n","          if len(out)>0:\n","            final_outputs.append(out[0])\n","          if len(out) >1:\n","            final_outputs.append(out[1])\n","      # logits_2 = outputs\n","      # logist_1 = output_bert[0]\n","      predictions_1 = final_outputs\n","      logits = torch.mean(torch.stack(predictions_1), dim=0)\n","      # else:\n","        # logits = predictions_1[0]\n","      # Move logits and labels to CPU\n","      logits = logits.detach().cpu().numpy()\n","      label_ids = b_labels.to('cpu').numpy()\n","\n","      \n","      # Store predictions and true labels\n","      predictions.append(logits)\n","      true_labels.append(label_ids)\n","    flat_predictions = np.concatenate(predictions, axis=0)\n","\n","    flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","\n","    # Combine the correct labels for each batch into a single list.\n","    flat_true_labels = np.concatenate(true_labels, axis=0)\n","    # metrics = precision_recall_fscore_support(flat_true_labels, flat_predictions, average='micro')\n","    metrics = print_weighted_metrics(flat_predictions,flat_true_labels)\n","    print(metrics)\n","    print('    DONE.')\n","    return metrics[2]"],"execution_count":107,"outputs":[]},{"cell_type":"code","metadata":{"id":"QkC2S9bkuVA1","executionInfo":{"status":"ok","timestamp":1643567349069,"user_tz":-330,"elapsed":527,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["for i,batch in enumerate(test_iter):\n","  if len(batch)==1:\n","    print(i,len(batch))"],"execution_count":108,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dmZeexRZhF6U","outputId":"382d8c04-0ae2-4756-91ca-e43859e9f3dd","executionInfo":{"status":"ok","timestamp":1643579934796,"user_tz":-330,"elapsed":12585737,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["import torch.nn.functional as F\n","from ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n","from ax.modelbridge.registry import Models\n","\n","best_parameters, best_values, experiment, model_100 = optimize(\n","        parameters=[\n","          {\n","              \n","            \"name\": \"multi_task\",\n","            \"type\": \"range\",\n","            \"bounds\": [1,2],\n","          },\n","           {\n","              \n","            \"name\": \"interactive\",\n","            \"type\": \"range\",\n","            \"bounds\": [1,2],\n","          },\n","          {\n","\n","              \n","            \"name\": \"interactive_given\",\n","            \"type\": \"range\",\n","            \"bounds\": [1,2],\n","          },\n","              {\n","\n","              \n","            \"name\": \"skill_given\",\n","            \"type\": \"range\",\n","            \"bounds\": [0,1],\n","          },\n","          {\n","            \"name\": \"cascade\",\n","            \"type\": \"range\",\n","            \"bounds\": [0,1],\n","          },\n","               {\n","            \"name\": \"lstm\",\n","            \"type\": \"range\",\n","            \"bounds\": [0,1],\n","          },\n","          {\n","            \"name\": \"gru\",\n","            \"type\": \"range\",\n","            \"bounds\": [0,1],\n","          },\n","           {\n","            \"name\": \"difficulty\",\n","            \"type\": \"range\",\n","            \"bounds\": [0,1],\n","          },\n","        ],\n","        # Booth function\n","        evaluation_function=make_predictions,\n","        generation_strategy = GenerationStrategy(name=\"Sobol+GPEI\", steps=[GenerationStep(model=Models.SOBOL, num_arms=10),\n","                GenerationStep(model=Models.GPEI, num_arms=12)]),\n","        minimize=False,\n","    )"],"execution_count":109,"outputs":[{"output_type":"stream","name":"stderr","text":["[INFO 01-30 18:29:08] ax.service.managed_loop: Started full optimization with 20 steps.\n","[INFO 01-30 18:29:08] ax.service.managed_loop: Running optimization trial 1...\n"]},{"output_type":"stream","name":"stdout","text":["{'multi_task': 2, 'interactive': 2, 'interactive_given': 2, 'skill_given': 1, 'cascade': 0, 'lstm': 1, 'gru': 0, 'difficulty': 0}\n","Predicting labels for 4,577 test sentences...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning:\n","\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","\n","[INFO 01-30 18:40:09] ax.service.managed_loop: Running optimization trial 2...\n"]},{"output_type":"stream","name":"stdout","text":["(0.5578566038914472, 0.5676207122569369, 0.5626963036833905)\n","    DONE.\n","{'multi_task': 1, 'interactive': 1, 'interactive_given': 1, 'skill_given': 0, 'cascade': 1, 'lstm': 1, 'gru': 0, 'difficulty': 1}\n","Predicting labels for 4,577 test sentences...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning:\n","\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","\n","[INFO 01-30 18:49:57] ax.service.managed_loop: Running optimization trial 3...\n"]},{"output_type":"stream","name":"stdout","text":["(0.5571353610877984, 0.5658728424732358, 0.5614701111201109)\n","    DONE.\n","{'multi_task': 1, 'interactive': 1, 'interactive_given': 2, 'skill_given': 1, 'cascade': 0, 'lstm': 0, 'gru': 0, 'difficulty': 1}\n","Predicting labels for 4,577 test sentences...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning:\n","\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","\n","[INFO 01-30 19:00:47] ax.service.managed_loop: Running optimization trial 4...\n"]},{"output_type":"stream","name":"stdout","text":["(0.5612124380838159, 0.5715534192702644, 0.56633572744335)\n","    DONE.\n","{'multi_task': 2, 'interactive': 2, 'interactive_given': 2, 'skill_given': 1, 'cascade': 1, 'lstm': 0, 'gru': 1, 'difficulty': 1}\n","Predicting labels for 4,577 test sentences...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning:\n","\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","\n","[INFO 01-30 19:13:07] ax.service.managed_loop: Running optimization trial 5...\n"]},{"output_type":"stream","name":"stdout","text":["(0.5575039667488247, 0.5700240332095259, 0.5636944885948966)\n","    DONE.\n","{'multi_task': 1, 'interactive': 2, 'interactive_given': 1, 'skill_given': 1, 'cascade': 0, 'lstm': 0, 'gru': 1, 'difficulty': 1}\n","Predicting labels for 4,577 test sentences...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning:\n","\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","\n","[INFO 01-30 19:24:16] ax.service.managed_loop: Running optimization trial 6...\n"]},{"output_type":"stream","name":"stdout","text":["(0.5602909857033871, 0.5706794843784138, 0.5654375234040471)\n","    DONE.\n","{'multi_task': 1, 'interactive': 1, 'interactive_given': 2, 'skill_given': 0, 'cascade': 0, 'lstm': 1, 'gru': 0, 'difficulty': 1}\n","Predicting labels for 4,577 test sentences...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning:\n","\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","\n","[INFO 01-30 19:32:54] ax.service.managed_loop: Running optimization trial 7...\n"]},{"output_type":"stream","name":"stdout","text":["(0.5510678920330868, 0.5636880052436094, 0.5573065127043308)\n","    DONE.\n","{'multi_task': 2, 'interactive': 2, 'interactive_given': 1, 'skill_given': 1, 'cascade': 0, 'lstm': 1, 'gru': 0, 'difficulty': 1}\n","Predicting labels for 4,577 test sentences...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning:\n","\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","\n","[INFO 01-30 19:43:53] ax.service.managed_loop: Running optimization trial 8...\n"]},{"output_type":"stream","name":"stdout","text":["(0.5576815035002949, 0.5700240332095259, 0.5637852249959996)\n","    DONE.\n","{'multi_task': 2, 'interactive': 2, 'interactive_given': 2, 'skill_given': 0, 'cascade': 0, 'lstm': 0, 'gru': 1, 'difficulty': 1}\n","Predicting labels for 4,577 test sentences...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning:\n","\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","\n","[INFO 01-30 19:52:42] ax.service.managed_loop: Running optimization trial 9...\n"]},{"output_type":"stream","name":"stdout","text":["(0.5560368670776934, 0.5669652610880489, 0.561447889742124)\n","    DONE.\n","{'multi_task': 1, 'interactive': 1, 'interactive_given': 1, 'skill_given': 0, 'cascade': 0, 'lstm': 1, 'gru': 0, 'difficulty': 0}\n","Predicting labels for 4,577 test sentences...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning:\n","\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","\n","[INFO 01-30 20:01:21] ax.service.managed_loop: Running optimization trial 10...\n"]},{"output_type":"stream","name":"stdout","text":["(0.5493078967027535, 0.5593183307843566, 0.5542679187138788)\n","    DONE.\n","{'multi_task': 2, 'interactive': 1, 'interactive_given': 1, 'skill_given': 0, 'cascade': 0, 'lstm': 0, 'gru': 1, 'difficulty': 0}\n","Predicting labels for 4,577 test sentences...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning:\n","\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","\n","[INFO 01-30 20:10:09] ax.service.managed_loop: Running optimization trial 11...\n"]},{"output_type":"stream","name":"stdout","text":["(0.5567003401207168, 0.5674022285339743, 0.5620003412822875)\n","    DONE.\n","{'multi_task': 1, 'interactive': 1, 'interactive_given': 2, 'skill_given': 1, 'cascade': 0, 'lstm': 0, 'gru': 0, 'difficulty': 1}\n","Predicting labels for 4,577 test sentences...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning:\n","\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","\n","[INFO 01-30 20:21:02] ax.service.managed_loop: Running optimization trial 12...\n"]},{"output_type":"stream","name":"stdout","text":["(0.5614571157128792, 0.571771902993227, 0.5665675661337733)\n","    DONE.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gpytorch/utils/cholesky.py:40: NumericalWarning:\n","\n","A not p.d., added jitter of 1.0e-08 to the diagonal\n","\n"]},{"output_type":"stream","name":"stdout","text":["{'multi_task': 1, 'interactive': 1, 'interactive_given': 2, 'skill_given': 1, 'cascade': 0, 'lstm': 0, 'gru': 0, 'difficulty': 1}\n","Predicting labels for 4,577 test sentences...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning:\n","\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","\n","[INFO 01-30 20:31:55] ax.service.managed_loop: Running optimization trial 13...\n"]},{"output_type":"stream","name":"stdout","text":["(0.561000367729743, 0.5713349355473017, 0.5661204910087749)\n","    DONE.\n","{'multi_task': 1, 'interactive': 1, 'interactive_given': 2, 'skill_given': 1, 'cascade': 0, 'lstm': 0, 'gru': 0, 'difficulty': 1}\n","Predicting labels for 4,577 test sentences...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning:\n","\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","\n","[INFO 01-30 20:42:50] ax.service.managed_loop: Running optimization trial 14...\n"]},{"output_type":"stream","name":"stdout","text":["(0.5610846376209254, 0.5713349355473017, 0.5661633953833303)\n","    DONE.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gpytorch/utils/cholesky.py:40: NumericalWarning:\n","\n","A not p.d., added jitter of 1.0e-08 to the diagonal\n","\n"]},{"output_type":"stream","name":"stdout","text":["{'multi_task': 1, 'interactive': 1, 'interactive_given': 2, 'skill_given': 1, 'cascade': 0, 'lstm': 0, 'gru': 0, 'difficulty': 1}\n","Predicting labels for 4,577 test sentences...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning:\n","\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","\n","[INFO 01-30 20:53:43] ax.service.managed_loop: Running optimization trial 15...\n"]},{"output_type":"stream","name":"stdout","text":["(0.561552586727285, 0.571771902993227, 0.5666161704897246)\n","    DONE.\n","{'multi_task': 1, 'interactive': 1, 'interactive_given': 2, 'skill_given': 1, 'cascade': 0, 'lstm': 0, 'gru': 0, 'difficulty': 1}\n","Predicting labels for 4,577 test sentences...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning:\n","\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","\n","[INFO 01-30 21:04:35] ax.service.managed_loop: Running optimization trial 16...\n"]},{"output_type":"stream","name":"stdout","text":["(0.5617130504798903, 0.5719903867161896, 0.56680513514568)\n","    DONE.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gpytorch/utils/cholesky.py:40: NumericalWarning:\n","\n","A not p.d., added jitter of 1.0e-08 to the diagonal\n","\n"]},{"output_type":"stream","name":"stdout","text":["{'multi_task': 1, 'interactive': 1, 'interactive_given': 2, 'skill_given': 1, 'cascade': 0, 'lstm': 0, 'gru': 0, 'difficulty': 1}\n","Predicting labels for 4,577 test sentences...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning:\n","\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","\n","[INFO 01-30 21:15:27] ax.service.managed_loop: Running optimization trial 17...\n"]},{"output_type":"stream","name":"stdout","text":["(0.5606216110051114, 0.5711164518243391, 0.5658203710014025)\n","    DONE.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gpytorch/utils/cholesky.py:40: NumericalWarning:\n","\n","A not p.d., added jitter of 1.0e-08 to the diagonal\n","\n"]},{"output_type":"stream","name":"stdout","text":["{'multi_task': 1, 'interactive': 1, 'interactive_given': 2, 'skill_given': 1, 'cascade': 0, 'lstm': 0, 'gru': 0, 'difficulty': 1}\n","Predicting labels for 4,577 test sentences...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning:\n","\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","\n","[INFO 01-30 21:26:19] ax.service.managed_loop: Running optimization trial 18...\n"]},{"output_type":"stream","name":"stdout","text":["(0.5600942766708807, 0.5706794843784138, 0.5653373362983523)\n","    DONE.\n","{'multi_task': 1, 'interactive': 1, 'interactive_given': 2, 'skill_given': 1, 'cascade': 0, 'lstm': 0, 'gru': 0, 'difficulty': 1}\n","Predicting labels for 4,577 test sentences...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning:\n","\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","\n","[INFO 01-30 21:37:11] ax.service.managed_loop: Running optimization trial 19...\n"]},{"output_type":"stream","name":"stdout","text":["(0.5615010445279935, 0.571771902993227, 0.5665899313394559)\n","    DONE.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gpytorch/utils/cholesky.py:40: NumericalWarning:\n","\n","A not p.d., added jitter of 1.0e-08 to the diagonal\n","\n"]},{"output_type":"stream","name":"stdout","text":["{'multi_task': 1, 'interactive': 1, 'interactive_given': 2, 'skill_given': 1, 'cascade': 0, 'lstm': 0, 'gru': 0, 'difficulty': 1}\n","Predicting labels for 4,577 test sentences...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning:\n","\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","\n","[INFO 01-30 21:48:02] ax.service.managed_loop: Running optimization trial 20...\n"]},{"output_type":"stream","name":"stdout","text":["(0.5612451013735307, 0.5715534192702644, 0.5663523581517748)\n","    DONE.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gpytorch/utils/cholesky.py:40: NumericalWarning:\n","\n","A not p.d., added jitter of 1.0e-08 to the diagonal\n","\n"]},{"output_type":"stream","name":"stdout","text":["{'multi_task': 1, 'interactive': 1, 'interactive_given': 2, 'skill_given': 1, 'cascade': 0, 'lstm': 0, 'gru': 0, 'difficulty': 1}\n","Predicting labels for 4,577 test sentences...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning:\n","\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","\n"]},{"output_type":"stream","name":"stdout","text":["(0.5607383740213367, 0.5711164518243391, 0.5658798341625474)\n","    DONE.\n"]}]},{"cell_type":"code","metadata":{"id":"bD8aNLwc6sgM"},"source":["import torch.nn.functional as F\n","from ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n","from ax.modelbridge.registry import Models\n","\n","best_parameters, best_values, experiment, model_100 = optimize(\n","        parameters=[\n","          {\n","            \"name\": \"multi_task\",\n","            \"type\": \"range\",\n","            \"bounds\": [1,2],\n","          },\n","          {\n","            \"name\": \"cascade\",\n","            \"type\": \"range\",\n","            \"bounds\": [0,1],\n","          },\n","               {\n","            \"name\": \"lstm\",\n","            \"type\": \"range\",\n","            \"bounds\": [0,1],\n","          },\n","          {\n","            \"name\": \"gru\",\n","            \"type\": \"range\",\n","            \"bounds\": [0,1],\n","          },\n","           {\n","            \"name\": \"difficulty\",\n","            \"type\": \"range\",\n","            \"bounds\": [0,1],\n","          },\n","        ],\n","        # Booth function\n","        evaluation_function=make_predictions,\n","        generation_strategy = GenerationStrategy(name=\"Sobol+GPEI\", steps=[GenerationStep(model=Models.SOBOL, num_arms=10),\n","                GenerationStep(model=Models.GPEI, num_arms=12)]),\n","        minimize=False,\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uw569V5iQT0i"},"source":["# output_difficulty = model(b_input_ids,b_input_mask)\n","#weighted\n","best_parameters,best_values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EOBMqL72_6-e","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f006eb79-95c7-4864-daf0-6853b93ab52e"},"source":["    print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n","\n","    # Put model in evaluation mode\n","    model.eval()\n","    model_multi_task.eval()\n","    model_cascade.eval()\n","    model_interactive.eval()\n","\n","    # Tracking variables \n","    predictions , true_labels,ids = [], [], []\n","\n","\n","    # Predict \n","    for index,batch in enumerate(prediction_dataloader):\n","      final_outputs = []\n","      # Add batch to GPU\n","      batch = tuple(t.to(device) for t in batch)\n","      \n","      # Unpack the inputs from our dataloader\n","      b_input_ids, b_input_mask, b_labels, skill_labels = batch\n","      # Telling the model not to compute or store gradients, saving memory and \n","      # speeding up prediction\n","      with torch.no_grad():\n","          # Forward pass, calculate logit predictions\n","            # print(\"multi\")\n","          outputs,_ = model_multi_task(b_input_ids,b_input_mask)\n","            # print(\"outputs\",outputs.shape,b_input_ids.shape,batch[0].shape,index)\n","          final_outputs.append(outputs)\n","            # print(\"cascade\")\n","          output_skill_given = model_skill_given(b_input_ids,b_input_mask,skill_labels)\n","          final_outputs.append(output_skill_given)\n","          output_cascade = model_cascade(b_input_ids,b_input_mask)\n","          final_outputs.append(output_cascade)\n","          outputs,_ = model_interactive_pre_trained(b_input_ids,b_input_mask)\n","          final_outputs.append(outputs)\n","\n","            # print(\"normal\")\n","          # output_difficulty = model(b_input_ids,b_input_mask)\n","          # final_outputs.append(output_difficulty)\n","          interactive_output,_ = model_interactive(b_input_ids,b_input_mask)\n","          final_outputs.append(interactive_output)\n","      # logits_2 = outputs\n","      # logist_1 = output_bert[0]\n","      predictions_1 = final_outputs\n","      logits = torch.mean(torch.stack(predictions_1), dim=0)\n","      # else:\n","        # logits = predictions_1[0]\n","      # Move logits and labels to CPU\n","      logits = logits.detach().cpu().numpy()\n","      label_ids = b_labels.to('cpu').numpy()\n","\n","      \n","      # Store predictions and true labels\n","      predictions.append(logits)\n","      true_labels.append(label_ids)\n","    flat_predictions = np.concatenate(predictions, axis=0)\n","\n","    flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","\n","    # Combine the correct labels for each batch into a single list.\n","    flat_true_labels = np.concatenate(true_labels, axis=0)\n","    # metrics = precision_recall_fscore_support(flat_true_labels, flat_predictions, average='micro')\n","    metrics = print_weighted_metrics(flat_predictions,flat_true_labels)\n","    macro_metrics = print_metrics(flat_predictions,flat_true_labels)\n","    print(\"macro_metrics\",macro_metrics)\n","\n","    print(\"weighted\",metrics)\n","    print('    DONE.')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting labels for 4,577 test sentences...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning:\n","\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","\n"]},{"output_type":"stream","name":"stdout","text":["macro_metrics (0.539084717991494, 0.480744537519493, 0.5082459284908306)\n","weighted (0.5649431976290253, 0.5743937076687787, 0.5696292578595487)\n","    DONE.\n"]}]},{"cell_type":"markdown","metadata":{"id":"dBS6OmWO1DJ6"},"source":["Now for comapring statistical significance between ensemble mlp and bo ensemble\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TBqbaDo11IZc","outputId":"9cabe691-12be-4864-d016-f91ff82c3aca"},"source":["from sklearn.model_selection import KFold\n","kf = KFold(n_splits=5, shuffle=True)\n","kf.split(test_features)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<generator object _BaseKFold.split at 0x7f8cc19c5d50>"]},"metadata":{},"execution_count":96}]},{"cell_type":"code","metadata":{"id":"k6Fk2gObC8iw"},"source":["def get_bo_predictions(prediction_dataloader):\n","  predictions=[]\n","  true_labels=[]\n","  for index,batch in enumerate(prediction_dataloader):\n","      final_outputs = []\n","      # Add batch to GPU\n","      batch = tuple(t.to(device) for t in batch)\n","      \n","      # Unpack the inputs from our dataloader\n","      b_input_ids, b_input_mask, b_labels, id = batch\n","      # Telling the model not to compute or store gradients, saving memory and \n","      # speeding up prediction\n","      with torch.no_grad():\n","          # Forward pass, calculate logit predictions\n","            # print(\"multi\")\n","          outputs,_ = model_multi_task(b_input_ids,b_input_mask)\n","            # print(\"outputs\",outputs.shape,b_input_ids.shape,batch[0].shape,index)\n","          final_outputs.append(outputs)\n","            # print(\"cascade\")\n","          # output_skill_given = model_skill_given(b_input_ids,b_input_mask,skill_labels)\n","          # final_outputs.append(output_skill_given)\n","          output_cascade = model_cascade(b_input_ids,b_input_mask)\n","          final_outputs.append(output_cascade)\n","          outputs,_ = model_interactive_pre_trained(b_input_ids,b_input_mask)\n","          final_outputs.append(outputs)\n","\n","            # print(\"normal\")\n","          # output_difficulty = model(b_input_ids,b_input_mask)\n","          # final_outputs.append(output_difficulty)\n","          interactive_output,_ = model_interactive(b_input_ids,b_input_mask)\n","          final_outputs.append(interactive_output)\n","      # logits_2 = outputs\n","      # logist_1 = output_bert[0]\n","      predictions_1 = final_outputs\n","      logits = torch.mean(torch.stack(predictions_1), dim=0)\n","      # else:\n","        # logits = predictions_1[0]\n","      # Move logits and labels to CPU\n","      logits = logits.detach().cpu().numpy()\n","      label_ids = b_labels.to('cpu').numpy()\n","\n","      \n","      # Store predictions and true labels\n","      predictions.append(logits)\n","      true_labels.append(label_ids)\n","  flat_predictions = np.concatenate(predictions, axis=0)\n","\n","  flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","\n","    # Combine the correct labels for each batch into a single list.\n","  flat_true_labels = np.concatenate(true_labels, axis=0)\n","  # metrics = precision_recall_fscore_support(flat_true_labels, flat_predictions, average='micro')\n","  metrics = print_weighted_metrics(flat_predictions,flat_true_labels)\n","  macro_metrics = print_metrics(flat_predictions,flat_true_labels)\n","  return metrics[2],macro_metrics[2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YX2oGxtlEwDb"},"source":["!cp -r \"/content/drive/MyDrive/research_skill_name_prediction/model_MLP_difficulty_ensemble_2\" /content/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MpxaFiZIFWnx"},"source":["class MLPStackedEnsemble(nn.Module):\n","  def __init__(self,hidden_dim=5,dropout=0.2):\n","    super(MLPStackedEnsemble, self).__init__()\n","\n","    # self.dropout = nn.Dropout(p=dropout)\n","    # self.linear1 = nn.Linear(hidden_dim, hidden_dim)\n","    # self.linear2 = nn.Linear(hidden_dim,hidden_dim)\n","    self.mlp = nn.Sequential(\n","        nn.Linear(hidden_dim, hidden_dim),\n","\n","        nn.ReLU(),\n","        nn.Dropout(p=dropout),\n","\n","        nn.Linear(hidden_dim,hidden_dim),\n","        nn.ReLU()\n","    )\n","    self.output = nn.Linear(hidden_dim,3)\n","  def forward(self,input):\n","    # intermediate_out = self.linear1(input)\n","    # intermediate_out = nn.ReLU(intermediate_out)\n","    # intermediate_out = self.dropout(intermediate_out)\n","    # final_out = self.linear2(intermediate_out)\n","    # final_out = nn.ReLU(final_out)\n","    output = self.mlp(input)\n","    final_out = self.output(output)\n","    return final_out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qL6Ivc9zFdhO","outputId":"09b8d65f-23f1-4a6d-a49f-e561755863c1"},"source":["stacking_model = MLPStackedEnsemble()\n","stacking_model.load_state_dict(torch.load(\"model_MLP_difficulty_ensemble_2/model_weights\"))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":99}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K4OYjlXrG4PB","outputId":"f6dd2bbe-2433-4277-952e-490709b19590"},"source":["stacking_model.cuda()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MLPStackedEnsemble(\n","  (mlp): Sequential(\n","    (0): Linear(in_features=5, out_features=5, bias=True)\n","    (1): ReLU()\n","    (2): Dropout(p=0.2, inplace=False)\n","    (3): Linear(in_features=5, out_features=5, bias=True)\n","    (4): ReLU()\n","  )\n","  (output): Linear(in_features=5, out_features=3, bias=True)\n",")"]},"metadata":{},"execution_count":100}]},{"cell_type":"code","metadata":{"id":"vPqqc9JXGG7j"},"source":["def make_lstm_and_gru_predictions_mlp(index,iterator):\n","  model_lstm.eval()\n","  model_gru.eval()\n","  for i,batch in enumerate(iterator):\n","    outputs = []\n","    if i == index:\n","      with torch.no_grad():\n","          question, x_len = batch.text\n","          x = question.cuda()\n","          # outs = sigmoid(outs.cpu().data.numpy()).tolist()\n","          y = batch.label.type(torch.long).cuda()\n","\n","          lstm_outputs = model_lstm(x,x_len)\n","          outputs.append(lstm_outputs)\n","          gru_outputs = model_gru(x,x_len)\n","          outputs.append(gru_outputs)\n","\n","          return outputs\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1h94v1ElFyOY"},"source":["def make_mlp_predictions(prediction_dataloader):\n","  # Prediction on test set\n","    predictions = []\n","    true_labels = []\n","    for index,batch in enumerate(prediction_dataloader):\n","\n","        # Progress update every 40 batches.\n","        stacking_model.eval()\n","        model.eval()\n","        model_multi_task.eval()\n","        model_cascade.eval()\n","        final_outputs = []\n","        # Add batch to GPU\n","        batch = tuple(t.to(device) for t in batch)\n","        # print(\"index\",index)\n","        # Unpack the inputs from our dataloader\n","        b_input_ids, b_input_mask, b_labels,_ = batch\n","\n","        # Telling the model not to compute or store gradients, saving memory and \n","        # speeding up prediction\n","        with torch.no_grad():\n","            # Forward pass, calculate logit predictions\n","            # if params['multi_task']>=0.5:\n","              # print(\"multi\")\n","            outputs,_ = model_multi_task(b_input_ids,b_input_mask)\n","            # print(np.concatenate(outputs,axis=0).shape)\n","            final_outputs.append(np.argmax(outputs.detach().cpu().numpy(), axis=1).flatten())\n","          # if params['cascade']>=0.5:\n","            # print(\"cascade\")\n","            output_cascade = model_cascade(b_input_ids,b_input_mask)\n","            final_outputs.append(np.argmax(output_cascade.detach().cpu().numpy(),axis=1).flatten())\n","          # if params['difficulty'] >=0:\n","            # print(\"normal\")\n","            output_difficulty = model(b_input_ids,b_input_mask)\n","            final_outputs.append(np.argmax(output_difficulty.detach().cpu().numpy(),axis=1).flatten())\n","\n","            out = make_lstm_and_gru_predictions_mlp(index,test_iter)\n","            final_outputs.append(np.argmax(out[0].detach().cpu().numpy(),axis=1).flatten())\n","            final_outputs.append(np.argmax(out[1].detach().cpu().numpy(),axis=1).flatten())\n","\n","\n","\n","\n","            inputs_ensemble = np.vstack(final_outputs).transpose()\n","            inputs_ensemble = torch.tensor(inputs_ensemble,dtype=float).float().cuda()  \n","            probas = stacking_model(inputs_ensemble)\n","      # else:\n","        # logits = predictions_1[0]\n","      # Move logits and labels to CPU\n","        logits = probas.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","      \n","      # Store predictions and true labels\n","        predictions.append(logits)\n","        true_labels.append(label_ids)\n","    flat_predictions = np.concatenate(predictions, axis=0)\n","\n","    flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","\n","    # Combine the correct labels for each batch into a single list.\n","    flat_true_labels = np.concatenate(true_labels, axis=0)\n","    # metrics = precision_recall_fscore_support(flat_true_labels, flat_predictions, average='micro')\n","    metrics = print_weighted_metrics(flat_predictions,flat_true_labels)\n","    macro_metrics = print_metrics(flat_predictions, flat_true_labels)\n","    print(\"weighted_metrics\",metrics)\n","    print(\"macro_metrics\",macro_metrics)\n","\n","    print('    DONE.')\n","    return metrics[2],macro_metrics[2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0_k-mOsuSKYR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4647d68c-f141-4c3f-b043-2ba114548766"},"source":["import torch.nn.functional as F\n","make_mlp_predictions(prediction_dataloader)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["weighted_metrics (0.5343434295308657, 0.550578981865851, 0.5423397255091517)\n","macro_metrics (0.49384635878376376, 0.4591804763525, 0.4758829403557214)\n","    DONE.\n"]},{"output_type":"execute_result","data":{"text/plain":["(0.5423397255091517, 0.4758829403557214)"]},"metadata":{},"execution_count":155}]},{"cell_type":"code","metadata":{"id":"19sDbZXQF0k7"},"source":["import torch.nn.functional as F\n","make_mlp_predictions(prediction_dataloader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3QFUh7sqKv9n"},"source":["test_labels = test[\"difficulty_label\"].values\n","test_skill_labels = test[\"skill_label\"].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YlXpc52FUTp1","colab":{"base_uri":"https://localhost:8080/","height":108},"outputId":"53faaf4f-838d-483c-db5a-760ac92ea077"},"source":["test.iloc[[2,3],:]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>board_syllabus</th>\n","      <th>question_answer</th>\n","      <th>skill_label</th>\n","      <th>difficulty_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>ICSE OLD&gt;&gt;XI&gt;&gt;Political Science&gt;&gt;State, Govern...</td>\n","      <td>Which of the following is not the element of ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Maharashtra New&gt;&gt;VII&gt;&gt;General Science&gt;&gt;Static ...</td>\n","      <td>The process of electrically charging an objec...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                      board_syllabus  ... difficulty_label\n","2  ICSE OLD>>XI>>Political Science>>State, Govern...  ...                0\n","3  Maharashtra New>>VII>>General Science>>Static ...  ...                1\n","\n","[2 rows x 4 columns]"]},"metadata":{},"execution_count":104}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OaozdK_RDJ0I","outputId":"e2b6a8b8-0fa6-4fc8-f59c-ecc6da742a55"},"source":["for indices in kf.split(test_features):\n","  print(len(indices[0]),len(indices[1]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3661 916\n","3661 916\n","3662 915\n","3662 915\n","3662 915\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K3gCmcJN2lJH","outputId":"63dac758-4952-419d-e8c2-ccd8af44c112"},"source":["import torch.nn.functional as F\n","f1_bo_ensemble = []\n","f1_mlp_ensemble =[]\n","macro_f1_bo_ensemble = []\n","macro_f1_mlp_ensemble = []\n","for indices in kf.split(test_features):\n","  input_ids = []\n","  attention_masks = []\n","  for sent in test_features[indices[1]]:\n","\n","\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 256,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        truncation=True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","  input_ids = torch.cat(input_ids, dim=0)\n","  attention_masks = torch.cat(attention_masks, dim=0)\n","  test_labels_tensor = torch.tensor(test_labels[indices[1]])\n","  test_skill_labels_tensor = torch.tensor(test_skill_labels[indices[1]])\n","  text = torchtext.data.Field(lower=True, batch_first=True, tokenize='spacy', include_lengths=True)\n","  target_diff = torchtext.data.Field(sequential=False, use_vocab=False, is_target=True)\n","  test.iloc[indices[1],:].to_csv(\"interim_test.csv\",index=False)\n","  text.build_vocab(train, val, test_text,vectors=\"glove.6B.100d\", min_freq=3)\n","\n","  test_text = torchtext.data.TabularDataset(path=\"interim_test.csv\",format='csv',\n","                                     fields={'difficulty_label': ('label', target_diff),\n","                                             'question_answer': ('text',text)})\n","  # test_text = torchtext.data.TabularDataset(examples=test.iloc[indices[1],:],\n","  #                                    fields={'difficulty_label': ('label', target_diff),\n","  #                                            'question_answer': ('text',text)})\n","  test_iter = torchtext.data.Iterator(dataset=test_text, batch_size=34,train=False, sort=False, sort_within_batch=False,shuffle=False)\n","# Set the batch size.  /\n","  batch_size = 34  \n","\n","  prediction_data = TensorDataset(input_ids, attention_masks, test_labels_tensor,test_skill_labels_tensor)\n","  # Create the DataLoader.\n","  prediction_sampler = SequentialSampler(prediction_data)\n","  prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n","  f1_bo,macro_f1_bo = get_bo_predictions(prediction_dataloader)\n","  f1_mlp,macro_f1_mlp = make_mlp_predictions(prediction_dataloader)\n","  f1_bo_ensemble.append(f1_bo)\n","  f1_mlp_ensemble.append(f1_mlp)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning:\n","\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","\n"]},{"output_type":"stream","name":"stdout","text":["weighted_metrics (0.5530553491571512, 0.5611353711790393, 0.5570660623312516)\n","macro_metrics (0.5340482288338629, 0.4704674115286114, 0.5002456462703636)\n","    DONE.\n","weighted_metrics (0.5435361186556741, 0.5491266375545851, 0.5463170763906339)\n","macro_metrics (0.5201339746462621, 0.46855746855746855, 0.4930004404230845)\n","    DONE.\n","weighted_metrics (0.5266728911297947, 0.5431693989071038, 0.5347939604925704)\n","macro_metrics (0.4709670700827882, 0.4308966336805981, 0.4500416730959399)\n","    DONE.\n","weighted_metrics (0.5268283645587903, 0.5453551912568306, 0.5359317104894857)\n","macro_metrics (0.4634247493330299, 0.4305399174071221, 0.4463774928148343)\n","    DONE.\n","weighted_metrics (0.5566972312117943, 0.5639344262295082, 0.5602924593149341)\n","macro_metrics (0.5175346597946382, 0.4710140895110264, 0.4931797581956103)\n","    DONE.\n"]}]},{"cell_type":"code","metadata":{"id":"eLO3BUOEKMpm","colab":{"base_uri":"https://localhost:8080/"},"outputId":"edbc3ec9-7f15-4c18-f5e5-4b5385600a7c"},"source":["print(f1_bo_ensemble)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.5564373545209147, 0.5697848472451442, 0.5572211622117446, 0.5481181546492473, 0.5782687476285892]\n"]}]},{"cell_type":"code","metadata":{"id":"71jVD2AAcMPe","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b3eba157-f803-4d4a-ce2c-fea8c6a27dbe"},"source":["f1_mlp_ensemble"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.5570660623312516,\n"," 0.5463170763906339,\n"," 0.5347939604925704,\n"," 0.5359317104894857,\n"," 0.5602924593149341]"]},"metadata":{},"execution_count":111}]},{"cell_type":"code","metadata":{"id":"87jSlrNZJsfZ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"05393754-2732-4d1d-bc86-a0ff8f1a4633"},"source":["from scipy import stats\n","stats.ttest_rel(f1_bo_ensemble,f1_mlp_ensemble)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Ttest_relResult(statistic=3.425669958264614, pvalue=0.026641198016335244)"]},"metadata":{},"execution_count":112}]},{"cell_type":"markdown","metadata":{"id":"UDxKTJqNSnFp"},"source":["Now for macro f1"]},{"cell_type":"code","metadata":{"id":"t9YL5hHaSmd9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f5c892e9-cfa2-4b7a-98c7-7570cc51b6a6"},"source":["\n","macro_f1_bo_ensemble = []\n","macro_f1_mlp_ensemble = []\n","for indices in kf.split(test_features):\n","  input_ids = []\n","  attention_masks = []\n","  for sent in test_features[indices[1]]:\n","\n","\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 256,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        truncation=True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","  input_ids = torch.cat(input_ids, dim=0)\n","  attention_masks = torch.cat(attention_masks, dim=0)\n","  test_labels_tensor = torch.tensor(test_labels[indices[1]])\n","  test_skill_labels_tensor = torch.tensor(test_skill_labels[indices[1]])\n","  text = torchtext.data.Field(lower=True, batch_first=True, tokenize='spacy', include_lengths=True)\n","  target_diff = torchtext.data.Field(sequential=False, use_vocab=False, is_target=True)\n","  test.iloc[indices[1],:].to_csv(\"interim_test.csv\",index=False)\n","  text.build_vocab(train, val, test_text,vectors=\"glove.6B.100d\", min_freq=3)\n","\n","  test_text = torchtext.data.TabularDataset(path=\"interim_test.csv\",format='csv',\n","                                     fields={'difficulty_label': ('label', target_diff),\n","                                             'question_answer': ('text',text)})\n","  # test_text = torchtext.data.TabularDataset(examples=test.iloc[indices[1],:],\n","  #                                    fields={'difficulty_label': ('label', target_diff),\n","  #                                            'question_answer': ('text',text)})\n","  test_iter = torchtext.data.Iterator(dataset=test_text, batch_size=34,train=False, sort=False, sort_within_batch=False,shuffle=False)\n","# Set the batch size.  \n","  batch_size = 34  \n","\n","  prediction_data = TensorDataset(input_ids, attention_masks, test_labels_tensor,test_skill_labels_tensor)\n","  # Create the DataLoader.\n","  prediction_sampler = SequentialSampler(prediction_data)\n","  prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n","  f1_bo,macro_f1_bo = get_bo_predictions(prediction_dataloader)\n","  f1_mlp,macro_f1_mlp = make_mlp_predictions(prediction_dataloader)\n","  macro_f1_bo_ensemble.append(macro_f1_bo)\n","  macro_f1_mlp_ensemble.append(macro_f1_mlp)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning:\n","\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","\n"]},{"output_type":"stream","name":"stdout","text":["weighted_metrics (0.5315880250037801, 0.5425764192139738, 0.5370260180481446)\n","macro_metrics (0.48680668919881276, 0.4496357070266303, 0.46748346885077546)\n","    DONE.\n","weighted_metrics (0.5343098684358575, 0.5414847161572053, 0.5378733665208482)\n","macro_metrics (0.5044394549345044, 0.45359740729020076, 0.4776693630803235)\n","    DONE.\n","weighted_metrics (0.5421212111005197, 0.5606557377049181, 0.5512327182106705)\n","macro_metrics (0.510186679972996, 0.4581613347093223, 0.482776453719545)\n","    DONE.\n","weighted_metrics (0.5333977057019141, 0.5420765027322404, 0.5377020864001445)\n","macro_metrics (0.49329852860404294, 0.45144149831649827, 0.4714427684327664)\n","    DONE.\n","weighted_metrics (0.5657431935093302, 0.5759562841530055, 0.5708040581496328)\n","macro_metrics (0.517350213868192, 0.4627010703232452, 0.48850198260035854)\n","    DONE.\n"]}]},{"cell_type":"code","metadata":{"id":"31_jaZqASy6P","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b7af9536-93b2-40a2-8519-158dc5466f25"},"source":["print(macro_f1_bo_ensemble)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.5039015738748421, 0.4861594069076786, 0.49643838071424107, 0.4841041446822403, 0.5162985261075795]\n"]}]},{"cell_type":"code","metadata":{"id":"IoqkoAbaSy6Q","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fcc64a09-f14f-4997-dbaa-be282050603a"},"source":["macro_f1_mlp_ensemble"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.46748346885077546,\n"," 0.4776693630803235,\n"," 0.482776453719545,\n"," 0.4714427684327664,\n"," 0.48850198260035854]"]},"metadata":{},"execution_count":115}]},{"cell_type":"code","metadata":{"id":"ManKEa4kSy6R","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a02d692e-1215-4848-b660-dc6f033c1294"},"source":["from scipy import stats\n","stats.ttest_rel(macro_f1_bo_ensemble,macro_f1_mlp_ensemble)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Ttest_relResult(statistic=3.7541287158233967, pvalue=0.01987576901257517)"]},"metadata":{},"execution_count":116}]},{"cell_type":"code","metadata":{"id":"qPPkoifkKLxK"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dhb1vToRNmkx"},"source":["def accuracy_per_class(preds_flat, labels_flat):\n","\n","    for label in np.unique(labels_flat):\n","        y_preds = preds_flat[labels_flat==label]\n","        y_true = labels_flat[labels_flat==label]\n","        print(f'Class: {get_labels(label)}')\n","        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n","accuracy_per_class(flat_predictions,flat_true_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BjdqIPm96UYJ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Majority Voting"],"metadata":{"id":"W10P9rK82085"}},{"cell_type":"code","source":["    print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n","\n","    # Put model in evaluation mode\n","    model.eval()\n","    model_multi_task.eval()\n","    model_cascade.eval()\n","    model_interactive.eval()\n","\n","    # Tracking variables \n","    predictions , true_labels,ids = [], [], []\n","\n","# 8 models in total\n","    # Predict \n","    for index,batch in enumerate(prediction_dataloader):\n","      final_outputs = []\n","      # Add batch to GPU\n","      batch = tuple(t.to(device) for t in batch)\n","      \n","      # Unpack the inputs from our dataloader\n","      b_input_ids, b_input_mask, b_labels, skill_labels = batch\n","      # Telling the model not to compute or store gradients, saving memory and \n","      # speeding up prediction\n","      with torch.no_grad():\n","          # Forward pass, calculate logit predictions\n","            # print(\"multi\")\n","\n","          # multi task model\n","          outputs,_ = model_multi_task(b_input_ids,b_input_mask)\n","            # print(\"outputs\",outputs.shape,b_input_ids.shape,batch[0].shape,index)\n","          final_outputs.append(outputs)\n","            # print(\"cascade\")\n","\n","          # assuming skill is given interactive attention\n","          output_skill_given = model_skill_given(b_input_ids,b_input_mask,skill_labels)\n","          final_outputs.append(output_skill_given)\n","\n","          #bert cascade\n","          output_cascade = model_cascade(b_input_ids,b_input_mask)\n","          final_outputs.append(output_cascade)\n","\n","          # interactive bert with pretrained model for skilled prediction\n","          outputs,_ = model_interactive_pre_trained(b_input_ids,b_input_mask)\n","          final_outputs.append(outputs)\n","\n","            # print(\"normal\")\n","          # output_difficulty = model(b_input_ids,b_input_mask)\n","          # final_outputs.append(output_difficulty)\n","\n","          # interactive attention model (ours)\n","          interactive_output,_ = model_interactive(b_input_ids,b_input_mask)\n","          final_outputs.append(interactive_output)\n","          params =dict()\n","          params['lstm'] =1\n","          params['gru'] = 1\n","\n","          # lstm plus GRU\n","          out = make_lstm_and_gru_predictions(index,params)\n","          final_outputs.append(out[0])\n","          final_outputs.append(out[1])\n","\n","          # base difficulty bert model\n","          output_difficulty = model(b_input_ids,b_input_mask)\n","          final_outputs.append(output_difficulty)\n","      # logits_2 = outputs\n","      # logist_1 = output_bert[0]\n","      predictions_1 = final_outputs\n","      logits,_ = torch.max(torch.stack(predictions_1), dim=0)\n","      # else:\n","        # logits = predictions_1[0]\n","      # Move logits and labels to CPU\n","      logits = logits.detach().cpu().numpy()\n","      label_ids = b_labels.to('cpu').numpy()\n","\n","      \n","      # Store predictions and true labels\n","      predictions.append(logits)\n","      true_labels.append(label_ids)\n","    flat_predictions = np.concatenate(predictions, axis=0)\n","\n","    flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","\n","    # Combine the correct labels for each batch into a single list.\n","    flat_true_labels = np.concatenate(true_labels, axis=0)\n","    # metrics = precision_recall_fscore_support(flat_true_labels, flat_predictions, average='micro')\n","    metrics = print_weighted_metrics(flat_predictions,flat_true_labels)\n","    macro_metrics = print_metrics(flat_predictions,flat_true_labels)\n","    print(\"macro_metrics\",macro_metrics)\n","\n","    print(\"weighted\",metrics)\n","    print('    DONE.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pHb5ELUF23GR","executionInfo":{"status":"ok","timestamp":1643580775989,"user_tz":-330,"elapsed":747741,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}},"outputId":"1207969c-f969-4561-f9bc-2ab80dd16a1f"},"execution_count":111,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting labels for 4,577 test sentences...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning:\n","\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","\n"]},{"output_type":"stream","name":"stdout","text":["macro_metrics (0.5252243597242369, 0.4660716619455976, 0.49388312851016175)\n","weighted (0.5499026145685715, 0.560847716845095, 0.5553212403284401)\n","    DONE.\n"]}]},{"cell_type":"markdown","source":["# Mean voting"],"metadata":{"id":"6PgvQmCYEsoy"}},{"cell_type":"code","source":["    print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n","\n","    # Put model in evaluation mode\n","    model.eval()\n","    model_multi_task.eval()\n","    model_cascade.eval()\n","    model_interactive.eval()\n","\n","    # Tracking variables \n","    predictions , true_labels,ids = [], [], []\n","\n","\n","    # Predict \n","    for index,batch in enumerate(prediction_dataloader):\n","      final_outputs = []\n","      # Add batch to GPU\n","      batch = tuple(t.to(device) for t in batch)\n","      \n","      # Unpack the inputs from our dataloader\n","      b_input_ids, b_input_mask, b_labels, skill_labels = batch\n","      # Telling the model not to compute or store gradients, saving memory and \n","      # speeding up prediction\n","      with torch.no_grad():\n","          # Forward pass, calculate logit predictions\n","            # print(\"multi\")\n","          outputs,_ = model_multi_task(b_input_ids,b_input_mask)\n","            # print(\"outputs\",outputs.shape,b_input_ids.shape,batch[0].shape,index)\n","          final_outputs.append(outputs)\n","            # print(\"cascade\")\n","          output_skill_given = model_skill_given(b_input_ids,b_input_mask,skill_labels)\n","          final_outputs.append(output_skill_given)\n","          output_cascade = model_cascade(b_input_ids,b_input_mask)\n","          final_outputs.append(output_cascade)\n","          outputs,_ = model_interactive_pre_trained(b_input_ids,b_input_mask)\n","          final_outputs.append(outputs)\n","\n","            # print(\"normal\")\n","          # output_difficulty = model(b_input_ids,b_input_mask)\n","          # final_outputs.append(output_difficulty)\n","          interactive_output,_ = model_interactive(b_input_ids,b_input_mask)\n","          final_outputs.append(interactive_output)\n","          params =dict()\n","          params['lstm'] =1\n","          params['gru'] = 1\n","          out = make_lstm_and_gru_predictions(index,params)\n","          final_outputs.append(out[0])\n","          final_outputs.append(out[1])\n","          output_difficulty = model(b_input_ids,b_input_mask)\n","          final_outputs.append(output_difficulty)\n","      # logits_2 = outputs\n","      # logist_1 = output_bert[0]\n","      predictions_1 = final_outputs\n","      logits = torch.mean(torch.stack(predictions_1), dim=0)\n","      # else:\n","        # logits = predictions_1[0]\n","      # Move logits and labels to CPU\n","      logits = logits.detach().cpu().numpy()\n","      label_ids = b_labels.to('cpu').numpy()\n","\n","      \n","      # Store predictions and true labels\n","      predictions.append(logits)\n","      true_labels.append(label_ids)\n","    flat_predictions = np.concatenate(predictions, axis=0)\n","\n","    flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","\n","    # Combine the correct labels for each batch into a single list.\n","    flat_true_labels = np.concatenate(true_labels, axis=0)\n","    # metrics = precision_recall_fscore_support(flat_true_labels, flat_predictions, average='micro')\n","    metrics = print_weighted_metrics(flat_predictions,flat_true_labels)\n","    macro_metrics = print_metrics(flat_predictions,flat_true_labels)\n","    print(\"macro_metrics\",macro_metrics)\n","\n","    print(\"weighted\",metrics)\n","    print('    DONE.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jW217ax166ZA","executionInfo":{"status":"ok","timestamp":1643581929657,"user_tz":-330,"elapsed":736639,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}},"outputId":"0a307faf-53e2-4a9c-eaa2-8f5041ed8e14"},"execution_count":112,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting labels for 4,577 test sentences...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning:\n","\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","\n"]},{"output_type":"stream","name":"stdout","text":["macro_metrics (0.5471735665240417, 0.4572675311906578, 0.49819687081004643)\n","weighted (0.5652408564340834, 0.5724273541621149, 0.5688114072262386)\n","    DONE.\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"r3y0fTWuErkO"},"execution_count":null,"outputs":[]}]}