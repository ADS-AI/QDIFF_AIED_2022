{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "difficulty_prediction_interactive_attention_vs_multi_task_stat_significance.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7cd72753a7ae4627a3cbae08d5a03888": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_86684b9c88da422e910a3423396aa537",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1896bc72003e4035a66f7b2ef9af0e4d",
              "IPY_MODEL_4ba04fee022e4fa69f6eafcab22e1674",
              "IPY_MODEL_c9ab0115145541558786c7292db930fb"
            ]
          }
        },
        "86684b9c88da422e910a3423396aa537": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1896bc72003e4035a66f7b2ef9af0e4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fa9e91fd8477425087d2045ffb9aeae2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ada269048a0346af98ea426d8bf87ac1"
          }
        },
        "4ba04fee022e4fa69f6eafcab22e1674": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_759f187f102e4218bb0602684a81b88a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_41eb0bf506a4463bb53d79360a91f0e2"
          }
        },
        "c9ab0115145541558786c7292db930fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1ac5f96821b647a6a817ded6c9fb0e66",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 904kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac72d343d2544fbba9b26434797cb3c1"
          }
        },
        "fa9e91fd8477425087d2045ffb9aeae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ada269048a0346af98ea426d8bf87ac1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "759f187f102e4218bb0602684a81b88a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "41eb0bf506a4463bb53d79360a91f0e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ac5f96821b647a6a817ded6c9fb0e66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac72d343d2544fbba9b26434797cb3c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc81f56bf9064e5182644521b3e915e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_de4aa0f5f93e4465b08857fae5789ee6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_37e7949b87914659bf87debd59771599",
              "IPY_MODEL_d649384285d14364af56da1e238090a2",
              "IPY_MODEL_a3e428e4ec324189a938287049c1feb9"
            ]
          }
        },
        "de4aa0f5f93e4465b08857fae5789ee6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "37e7949b87914659bf87debd59771599": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_abd274069b30471f955464d3a95e08dd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1c1b4f99f1a54b1b9771e5528043d4e1"
          }
        },
        "d649384285d14364af56da1e238090a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_10028f73076f4cd3b3fc6ffc32f22970",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dd06240d1097419e9849c9106431a6ec"
          }
        },
        "a3e428e4ec324189a938287049c1feb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4f45ce89b5e142c18322fe4e560ae6d6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 11.9kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_45fe2949a10c49b6ad7a2928d625a506"
          }
        },
        "abd274069b30471f955464d3a95e08dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1c1b4f99f1a54b1b9771e5528043d4e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10028f73076f4cd3b3fc6ffc32f22970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dd06240d1097419e9849c9106431a6ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4f45ce89b5e142c18322fe4e560ae6d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "45fe2949a10c49b6ad7a2928d625a506": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dd4bf0d060ff4a478d7ff183ea934120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_877803b21323407280c6c664cbda3da9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ac2fe627cd0a44efa343c1507ad6284f",
              "IPY_MODEL_4abee27fac4b4a2a8fca82dd60a42f8b",
              "IPY_MODEL_9a0099799bbe47489d548ac39de8d5ad"
            ]
          }
        },
        "877803b21323407280c6c664cbda3da9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ac2fe627cd0a44efa343c1507ad6284f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0b248779ad7c41a7bd16b03f7f62c475",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f505dddb32054a90b8fcb706fb389093"
          }
        },
        "4abee27fac4b4a2a8fca82dd60a42f8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4ab9c8bca00540279d56f4495b3e8a75",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2831ecaa630444a5a48934fd10ddfc5e"
          }
        },
        "9a0099799bbe47489d548ac39de8d5ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4b1354aa66f14ab3971b2c13bbb0a483",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:32&lt;00:00, 19.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6d81e1196c404328a4cc985a78047c8e"
          }
        },
        "0b248779ad7c41a7bd16b03f7f62c475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f505dddb32054a90b8fcb706fb389093": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ab9c8bca00540279d56f4495b3e8a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2831ecaa630444a5a48934fd10ddfc5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b1354aa66f14ab3971b2c13bbb0a483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6d81e1196c404328a4cc985a78047c8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR9av2JU3kf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b565002a-01ab-4675-e269-3b3f6fbcaf7d"
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "import torch\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXHEZXXXIrDD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8230e84b-ea45-4be4-ccd9-061f5b055cf1"
      },
      "source": [
        "!pip install torchtext==0.3.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.3.1\n",
            "  Downloading torchtext-0.3.1-py3-none-any.whl (62 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▎                          | 10 kB 33.0 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 20 kB 22.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 30 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 40 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 51 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 61 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 62 kB 927 kB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.3.1) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.3.1) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.3.1) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.3.1) (4.62.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.3.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.3.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.3.1) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.3.1) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.3.1) (3.10.0.2)\n",
            "Installing collected packages: torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.11.0\n",
            "    Uninstalling torchtext-0.11.0:\n",
            "      Successfully uninstalled torchtext-0.11.0\n",
            "Successfully installed torchtext-0.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATfPIQGkqp_u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54a5fadd-106a-483d-f0b3-77d07f239c1a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzKeqoCs3kgA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7853826c-79a1-47ec-a5d2-d53434338f78"
      },
      "source": [
        "\n",
        "!pip install transformers==3.2.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==3.2.0\n",
            "  Downloading transformers-3.2.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 17.0 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |█                               | 30 kB 18.5 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40 kB 21.7 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██                              | 61 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 92 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 133 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 143 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 153 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 163 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 174 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 184 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 194 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 204 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 215 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 225 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 235 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 245 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 256 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 266 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 276 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 286 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 296 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 307 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 317 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 327 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 337 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 348 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 358 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 368 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 378 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 389 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 399 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 409 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 419 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 430 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 440 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 450 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 460 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 471 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 481 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 491 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 501 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 512 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 522 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 532 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 542 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 552 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 563 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 573 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 583 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 593 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 604 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 614 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 624 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 634 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 645 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 655 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 665 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 675 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 686 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 696 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 706 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 716 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 727 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 737 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 747 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 757 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 768 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 778 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 788 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 798 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 808 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 819 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 829 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 839 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 849 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 860 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 870 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 880 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 890 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 901 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 911 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 921 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 931 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 942 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 952 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 962 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 972 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 983 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 993 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.0 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0 MB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (4.62.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (21.3)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "  Downloading tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 56.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (3.4.2)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 58.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 67.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.2.0) (3.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2.0) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.2.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.2.0) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.2.0) (1.15.0)\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.47 sentencepiece-0.1.96 tokenizers-0.8.1rc2 transformers-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsADhaO93kgD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "9a9bc070-4b14-4d34-a0f0-b8fe749dd597"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "final_data = pd.read_csv(\"train_skill_name_difficulty.csv\")\n",
        "final_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1413e56f-d29c-4db0-a406-baffab7854d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>board_syllabus</th>\n",
              "      <th>question_answer</th>\n",
              "      <th>skill_label</th>\n",
              "      <th>difficulty_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Raj English&gt;&gt;XII&gt;&gt;Biology&gt;&gt;Domestication, Cult...</td>\n",
              "      <td>Among the following, freshwater fish is rohu ...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Maharashtra New&gt;&gt;VI&gt;&gt;General Science&gt;&gt;Sound&gt;&gt;P...</td>\n",
              "      <td>Which of the following statement is true? Sou...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ICSE OLD&gt;&gt;XI&gt;&gt;Computer Science&gt;&gt;Functions&gt;&gt;Con...</td>\n",
              "      <td>The process of using multiple constructors wi...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CBSE&gt;&gt;VI&gt;&gt;Science&gt;&gt;Separation of Substances&gt;&gt;S...</td>\n",
              "      <td>Sieving is based on the difference in the siz...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AP&gt;&gt;X&gt;&gt;Biology&gt;&gt;Excretion - The Wastage Dispos...</td>\n",
              "      <td>The removal of toxic and unwanted waste subst...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39124</th>\n",
              "      <td>CAPS(South Africa)&gt;&gt;Grade 7&gt;&gt;Natural Sciences&gt;...</td>\n",
              "      <td>How heat loss problems are prevented by birds...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39125</th>\n",
              "      <td>CBSE&gt;&gt;X&gt;&gt;Science&gt;&gt;Metals and Non-Metal</td>\n",
              "      <td>Give reasons why copper is used to make hot w...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39126</th>\n",
              "      <td>CBSE&gt;&gt;VII&gt;&gt;Science&gt;&gt;Motion and Time</td>\n",
              "      <td>The horizontal line in the graph is denoted as...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39127</th>\n",
              "      <td>Tamil Nadu&gt;&gt;VI&gt;&gt;Science&gt;&gt;Term 1&gt;&gt;Physics&gt;&gt;Forc...</td>\n",
              "      <td>SI unit of force is newton The SI unit of for...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39128</th>\n",
              "      <td>Tamil Nadu&gt;&gt;VIII&gt;&gt;Science&gt;&gt;Term 1&gt;&gt;Physics&gt;&gt;Fo...</td>\n",
              "      <td>In machines sliding frictions is replaced to ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39129 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1413e56f-d29c-4db0-a406-baffab7854d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1413e56f-d29c-4db0-a406-baffab7854d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1413e56f-d29c-4db0-a406-baffab7854d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                          board_syllabus  ... difficulty_label\n",
              "0      Raj English>>XII>>Biology>>Domestication, Cult...  ...                0\n",
              "1      Maharashtra New>>VI>>General Science>>Sound>>P...  ...                2\n",
              "2      ICSE OLD>>XI>>Computer Science>>Functions>>Con...  ...                0\n",
              "3      CBSE>>VI>>Science>>Separation of Substances>>S...  ...                1\n",
              "4      AP>>X>>Biology>>Excretion - The Wastage Dispos...  ...                1\n",
              "...                                                  ...  ...              ...\n",
              "39124  CAPS(South Africa)>>Grade 7>>Natural Sciences>...  ...                1\n",
              "39125             CBSE>>X>>Science>>Metals and Non-Metal  ...                2\n",
              "39126                CBSE>>VII>>Science>>Motion and Time  ...                1\n",
              "39127  Tamil Nadu>>VI>>Science>>Term 1>>Physics>>Forc...  ...                2\n",
              "39128  Tamil Nadu>>VIII>>Science>>Term 1>>Physics>>Fo...  ...                1\n",
              "\n",
              "[39129 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0Ja4jiFhmdg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80faaac4-5883-4eb0-d994-b8d14b92490e"
      },
      "source": [
        "final_data[\"question_answer\"].values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' Among the following, freshwater fish is rohu Rohu is a fresh water fish. Other common freshwater fish are catla, common carp.',\n",
              "       ' Which of the following statement is true? Sound requires a medium for propagation. Sound travels through a medium (solid, liquid or gas). It cannot travel through vacuum.',\n",
              "       ' The process of using multiple constructors with the same name but with different parameters is known as: Constructor overloading Constructor overloading is a technique in Java in which a class can have any number of constructors that differ in parameter lists.',\n",
              "       ...,\n",
              "       'The horizontal line in the graph is denoted as the X-axis. The horizontal line points in the horizontal direction and is denoted as the X-axis in the graph.',\n",
              "       ' SI unit of force is newton The SI unit of force is Newton (N), named after famous scientist Isaac Newton who discovered force of gravitation.',\n",
              "       ' In machines sliding frictions is replaced to rolling by use of ball bearings Ball bearing roll to produce rolling;friction.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQhO6qqt6lge",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5c0f7b6-cae2-46b1-8828-f9c4b3d68ae8"
      },
      "source": [
        "final_data['skill_label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    11376\n",
              "4    10707\n",
              "2     8619\n",
              "1     4997\n",
              "0     3430\n",
              "Name: skill_label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMBf0kH7TOyd"
      },
      "source": [
        "!cp \"/content/drive/My Drive/research_skill_name_prediction/label_encoder_skill_lstm\"  /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/My Drive/research_skill_name_prediction/label_encoder_difficulty_Lstm\"  /content"
      ],
      "metadata": {
        "id": "5DvYyS_vTZ3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlpZo0VvTSMb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d31599ea-7aeb-448d-d111-5e653af59d29"
      },
      "source": [
        "import joblib\n",
        "LE_skill = joblib.load(\"label_encoder_skill_lstm\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OBarOLBz2nO"
      },
      "source": [
        "def get_labels(prediction):\n",
        "    predicted_label =  LE.inverse_transform([prediction])\n",
        "    return predicted_label[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqWem79lbn1J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "51a250fb-c3a6-49b3-fca4-f970667373a9"
      },
      "source": [
        "final_data['difficulty_label'].value_counts().sort_values(ascending=False).plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe65076fb10>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD2CAYAAAA0/OvUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAS5UlEQVR4nO3df4xd5X3n8fenpkRRE4QpU8vxj9pNTVeQ3XXCCFh1U7HLBgyparKqWPuP2KEoThRoG+1KG6f7B1GyrNzdplGRsnSdxsKsUggbksVqnLiulTSqug4eJ5bBEOqBmGUsY08xG5pNRWv47h/3mc3pMGOP547nmvj9kq7uud/znHOeqwF/5jzPc+emqpAkXdh+atAdkCQNnmEgSTIMJEmGgSQJw0CShGEgSWIGYZBkWZJvJHkyyaEkv93qlyXZneRwe17Y6klyb5LRJAeTvKtzro2t/eEkGzv1q5M83o65N0nOxZuVJE0tZ/qcQZLFwOKq+k6StwL7gVuBDwAnq2pLks3Awqr6WJJbgN8EbgGuBf6gqq5NchkwAgwD1c5zdVW9lOQx4LeAbwM7gXur6mun69fll19eK1asmO37lqQL0v79+/+6qoYm1y8604FVdQw41rb/JslTwBJgLXB9a7Yd+CbwsVZ/oHopszfJpS1Qrgd2V9VJgCS7gTVJvglcUlV7W/0BemFz2jBYsWIFIyMjZ+q+JKkjyXNT1c9qziDJCuCd9H6DX9SCAuAFYFHbXgI83zlsrNVOVx+boi5JmiczDoMkbwEeAT5aVS9397W7gHP+dy2SbEoykmRkfHz8XF9Oki4YMwqDJD9NLwi+UFVfbuXjbfhnYl7hRKsfBZZ1Dl/aaqerL52i/jpVtbWqhqtqeGjodUNekqRZmslqogCfB56qqt/v7NoBTKwI2gg82qlvaKuKrgN+0IaTdgE3JlnYVh7dCOxq+15Ocl271obOuSRJ8+CME8jALwPvBx5PcqDVfgfYAjyc5A7gOeC2tm8nvZVEo8CPgNsBqupkkk8B+1q7T05MJgMfAe4H3kxv4vi0k8eSpLl1xqWl56vh4eFyNZEknZ0k+6tqeHLdTyBLkgwDSdLM5gwErNj81UF34Zw6suW9g+6CpAHyzkCSZBhIkgwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkMYMwSLItyYkkT3RqX0xyoD2OTHw3cpIVSf62s+8PO8dcneTxJKNJ7k2SVr8sye4kh9vzwnPxRiVJ05vJncH9wJpuoar+TVWtrqrVwCPAlzu7n5nYV1Uf7tTvAz4IrGqPiXNuBvZU1SpgT3stSZpHZwyDqvoWcHKqfe23+9uAB093jiSLgUuqam9VFfAAcGvbvRbY3ra3d+qSpHnS75zBu4HjVXW4U1uZ5LtJ/jzJu1ttCTDWaTPWagCLqupY234BWNRnnyRJZ6nf70Bezz+8KzgGLK+qF5NcDfzPJFfN9GRVVUlquv1JNgGbAJYvXz7LLkuSJpv1nUGSi4B/DXxxolZVr1TVi217P/AMcAVwFFjaOXxpqwEcb8NIE8NJJ6a7ZlVtrarhqhoeGhqabdclSZP0M0z0r4DvVdX/H/5JMpRkQdv+BXoTxc+2YaCXk1zX5hk2AI+2w3YAG9v2xk5dkjRPZrK09EHgfwG/lGQsyR1t1zpeP3H8K8DBttT0S8CHq2pi8vkjwB8Bo/TuGL7W6luA9yQ5TC9gtvTxfiRJs3DGOYOqWj9N/QNT1B6ht9R0qvYjwDumqL8I3HCmfkiSzh0/gSxJMgwkSYaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kSM/sO5G1JTiR5olP7RJKjSQ60xy2dfR9PMprk6SQ3deprWm00yeZOfWWSb7f6F5NcPJdvUJJ0ZjO5M7gfWDNF/TNVtbo9dgIkuRJYB1zVjvmvSRYkWQB8FrgZuBJY39oC/G471y8CLwF39POGJEln74xhUFXfAk7O8HxrgYeq6pWq+j4wClzTHqNV9WxV/R3wELA2SYB/CXypHb8duPUs34MkqU/9zBncleRgG0Za2GpLgOc7bcZabbr6zwL/p6pOTapLkubRbMPgPuDtwGrgGPDpOevRaSTZlGQkycj4+Ph8XFKSLgizCoOqOl5Vr1bVa8Dn6A0DARwFlnWaLm216eovApcmuWhSfbrrbq2q4aoaHhoamk3XJUlTmFUYJFncefk+YGKl0Q5gXZI3JVkJrAIeA/YBq9rKoYvpTTLvqKoCvgH8ejt+I/DobPokSZq9i87UIMmDwPXA5UnGgLuB65OsBgo4AnwIoKoOJXkYeBI4BdxZVa+289wF7AIWANuq6lC7xMeAh5L8R+C7wOfn7N1JkmbkjGFQVeunKE/7D3ZV3QPcM0V9J7Bzivqz/HiYSZI0AH4CWZJkGEiSDANJEoaBJIkZTCBLb3QrNn910F04p45see+gu6CfAN4ZSJIMA0mSYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSmEEYJNmW5ESSJzq1/5Lke0kOJvlKkktbfUWSv01yoD3+sHPM1UkeTzKa5N4kafXLkuxOcrg9LzwXb1SSNL2Z3BncD6yZVNsNvKOq/gnwV8DHO/ueqarV7fHhTv0+4IPAqvaYOOdmYE9VrQL2tNeSpHl0xjCoqm8BJyfV/rSqTrWXe4GlpztHksXAJVW1t6oKeAC4te1eC2xv29s7dUnSPJmLOYPfAL7Web0yyXeT/HmSd7faEmCs02as1QAWVdWxtv0CsGi6CyXZlGQkycj4+PgcdF2SBH2GQZL/AJwCvtBKx4DlVfVO4N8Cf5zkkpmer9011Gn2b62q4aoaHhoa6qPnkqSuWX/tZZIPAL8K3ND+EaeqXgFeadv7kzwDXAEc5R8OJS1tNYDjSRZX1bE2nHRitn2SJM3OrO4MkqwB/j3wa1X1o059KMmCtv0L9CaKn23DQC8nua6tItoAPNoO2wFsbNsbO3VJ0jw5451BkgeB64HLk4wBd9NbPfQmYHdbIbq3rRz6FeCTSf4eeA34cFVNTD5/hN7KpDfTm2OYmGfYAjyc5A7gOeC2OXlnkqQZO2MYVNX6Kcqfn6btI8Aj0+wbAd4xRf1F4IYz9UOSdO74CWRJkmEgSTIMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCQxwzBIsi3JiSRPdGqXJdmd5HB7XtjqSXJvktEkB5O8q3PMxtb+cJKNnfrVSR5vx9zbvidZkjRPZnpncD+wZlJtM7CnqlYBe9prgJuBVe2xCbgPeuFB7/uTrwWuAe6eCJDW5oOd4yZfS5J0Ds0oDKrqW8DJSeW1wPa2vR24tVN/oHr2ApcmWQzcBOyuqpNV9RKwG1jT9l1SVXurqoAHOueSJM2DfuYMFlXVsbb9ArCobS8Bnu+0G2u109XHpqhLkubJnEwgt9/oay7OdTpJNiUZSTIyPj5+ri8nSReMfsLgeBvioT2faPWjwLJOu6Wtdrr60inqr1NVW6tquKqGh4aG+ui6JKmrnzDYAUysCNoIPNqpb2iriq4DftCGk3YBNyZZ2CaObwR2tX0vJ7murSLa0DmXJGkeXDSTRkkeBK4HLk8yRm9V0Bbg4SR3AM8Bt7XmO4FbgFHgR8DtAFV1MsmngH2t3SeramJS+iP0Viy9Gfhae0iS5smMwqCq1k+z64Yp2hZw5zTn2QZsm6I+ArxjJn2RJM09P4EsSTIMJEmGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEn2EQZJfSnKg83g5yUeTfCLJ0U79ls4xH08ymuTpJDd16mtabTTJ5n7flCTp7MzoO5CnUlVPA6sBkiwAjgJfAW4HPlNVv9dtn+RKYB1wFfA24M+SXNF2fxZ4DzAG7Euyo6qenG3fJElnZ9ZhMMkNwDNV9VyS6dqsBR6qqleA7ycZBa5p+0ar6lmAJA+1toaBJM2TuZozWAc82Hl9V5KDSbYlWdhqS4DnO23GWm26uiRpnvQdBkkuBn4N+B+tdB/wdnpDSMeAT/d7jc61NiUZSTIyPj4+V6eVpAveXNwZ3Ax8p6qOA1TV8ap6tapeAz7Hj4eCjgLLOsctbbXp6q9TVVurariqhoeGhuag65IkmJswWE9niCjJ4s6+9wFPtO0dwLokb0qyElgFPAbsA1YlWdnuMta1tpKkedLXBHKSn6G3CuhDnfJ/TrIaKODIxL6qOpTkYXoTw6eAO6vq1Xaeu4BdwAJgW1Ud6qdfkqSz01cYVNX/BX52Uu39p2l/D3DPFPWdwM5++iJJmj0/gSxJMgwkSYaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiS6PP7DCTpXFux+auD7sI5dWTLewfdBcA7A0kShoEkiTkIgyRHkjye5ECSkVa7LMnuJIfb88JWT5J7k4wmOZjkXZ3zbGztDyfZ2G+/JEkzN1d3Bv+iqlZX1XB7vRnYU1WrgD3tNcDNwKr22ATcB73wAO4GrgWuAe6eCBBJ0rl3roaJ1gLb2/Z24NZO/YHq2QtcmmQxcBOwu6pOVtVLwG5gzTnqmyRpkrkIgwL+NMn+JJtabVFVHWvbLwCL2vYS4PnOsWOtNl1dkjQP5mJp6T+vqqNJfg7YneR73Z1VVUlqDq5DC5tNAMuXL5+LU0qSmIM7g6o62p5PAF+hN+Z/vA3/0J5PtOZHgWWdw5e22nT1ydfaWlXDVTU8NDTUb9clSU1fYZDkZ5K8dWIbuBF4AtgBTKwI2gg82rZ3ABvaqqLrgB+04aRdwI1JFraJ4xtbTZI0D/odJloEfCXJxLn+uKq+nmQf8HCSO4DngNta+53ALcAo8CPgdoCqOpnkU8C+1u6TVXWyz75JkmaorzCoqmeBfzpF/UXghinqBdw5zbm2Adv66Y8kaXb8BLIkyTCQJBkGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJ9BEGSZYl+UaSJ5McSvLbrf6JJEeTHGiPWzrHfDzJaJKnk9zUqa9ptdEkm/t7S5Kks9XPdyCfAv5dVX0nyVuB/Ul2t32fqarf6zZOciWwDrgKeBvwZ0muaLs/C7wHGAP2JdlRVU/20TdJ0lmYdRhU1THgWNv+myRPAUtOc8ha4KGqegX4fpJR4Jq2b7SqngVI8lBraxhI0jyZkzmDJCuAdwLfbqW7khxMsi3JwlZbAjzfOWys1aarS5LmSd9hkOQtwCPAR6vqZeA+4O3Aanp3Dp/u9xqda21KMpJkZHx8fK5OK0kXvL7CIMlP0wuCL1TVlwGq6nhVvVpVrwGf48dDQUeBZZ3Dl7badPXXqaqtVTVcVcNDQ0P9dF2S1NHPaqIAnweeqqrf79QXd5q9D3iibe8A1iV5U5KVwCrgMWAfsCrJyiQX05tk3jHbfkmSzl4/q4l+GXg/8HiSA632O8D6JKuBAo4AHwKoqkNJHqY3MXwKuLOqXgVIchewC1gAbKuqQ330S5J0lvpZTfQXQKbYtfM0x9wD3DNFfefpjpMknVt+AlmSZBhIkgwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkzqMwSLImydNJRpNsHnR/JOlCcl6EQZIFwGeBm4ErgfVJrhxsryTpwnFehAFwDTBaVc9W1d8BDwFrB9wnSbpgXDToDjRLgOc7r8eAayc3SrIJ2NRe/jDJ0/PQt0G5HPjr+bpYfne+rnRB8Gf3xvaT/vP7+amK50sYzEhVbQW2Drof8yHJSFUND7ofOnv+7N7YLtSf3/kyTHQUWNZ5vbTVJEnz4HwJg33AqiQrk1wMrAN2DLhPknTBOC+GiarqVJK7gF3AAmBbVR0acLcG7YIYDvsJ5c/uje2C/PmlqgbdB0nSgJ0vw0SSpAEyDCRJhoEk6TyZQJbeyJL8I3qfmF/SSkeBHVX11OB6pZlqP78lwLer6oed+pqq+vrgeja/vDM4zyW5fdB90PSSfIzen08J8Fh7BHjQP7h4/kvyW8CjwG8CTyTp/hmc/zSYXg2Gq4nOc0n+d1UtH3Q/NLUkfwVcVVV/P6l+MXCoqlYNpmeaiSSPA/+sqn6YZAXwJeC/V9UfJPluVb1zoB2cRw4TnQeSHJxuF7BoPvuis/Ya8DbguUn1xW2fzm8/NTE0VFVHklwPfCnJz9P7/++CYRicHxYBNwEvTaoH+Mv5747OwkeBPUkO8+M/trgc+EXgroH1SjN1PMnqqjoA0O4QfhXYBvzjwXZtfhkG54c/Ad4y8R9kV5Jvzn93NFNV9fUkV9D7M+zdCeR9VfXq4HqmGdoAnOoWquoUsCHJfxtMlwbDOQNJkquJJEmGgSQJw0CShGEgScIwkCQB/w+x5LFsGMEOWgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxliBQEJ9eTG"
      },
      "source": [
        "val = pd.read_csv(\"val_skill_name_difficulty.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07eBaI9wA2hL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "f95681a7-cc90-4be1-b14b-71526abb0787"
      },
      "source": [
        "val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-04ff2535-b38a-4c14-ba45-5ebf44fd9ba6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>board_syllabus</th>\n",
              "      <th>question_answer</th>\n",
              "      <th>skill_label</th>\n",
              "      <th>difficulty_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AP&gt;&gt;VII&gt;&gt;Science&gt;&gt;Animal Fibre&gt;&gt;Silk</td>\n",
              "      <td>Name the two types of protein from which silk...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Maharashtra New&gt;&gt;VIII&gt;&gt;General Science&gt;&gt;Man Ma...</td>\n",
              "      <td>Give reasons: (i) Thermocol is used for the p...</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CBSE&gt;&gt;VI&gt;&gt;Science&gt;&gt;Fun with Magnets&gt;&gt;Demagneti...</td>\n",
              "      <td>Identify the odd option. Rubbing a magnetic m...</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tamil Nadu&gt;&gt;VIII&gt;&gt;Science&gt;&gt;Term 1&gt;&gt;Physics&gt;&gt;Li...</td>\n",
              "      <td>Find the speed of light in glass of refractiv...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Raj English&gt;&gt;XII&gt;&gt;Biology&gt;&gt;Integumentary Syste...</td>\n",
              "      <td>Which of the following function is associated...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2055</th>\n",
              "      <td>CBSE&gt;&gt;XI&gt;&gt;Chemistry&gt;&gt;Chemistry : Part I&gt;&gt;Equil...</td>\n",
              "      <td>The solubility of A 2 X 3 is y mol.dm -3 . So...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2056</th>\n",
              "      <td>CBSE&gt;&gt;VI&gt;&gt;Computer Science&gt;&gt;Using Mail Merge&gt;&gt;...</td>\n",
              "      <td>To create an invitation letter, click on Mail...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2057</th>\n",
              "      <td>CBSE&gt;&gt;XII&gt;&gt;Physics&gt;&gt;Physics : Part - II&gt;&gt;Ray O...</td>\n",
              "      <td>Choose the correct option about the intensity...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2058</th>\n",
              "      <td>ICSE OLD&gt;&gt;VII&gt;&gt;Biology&gt;&gt;Organ System of Human ...</td>\n",
              "      <td>Which of the following instrument is used to ...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2059</th>\n",
              "      <td>CBSE&gt;&gt;X&gt;&gt;Science&gt;&gt;Carbon and its Compounds&gt;&gt;Al...</td>\n",
              "      <td>Identify the correct statement about allotrop...</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2060 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04ff2535-b38a-4c14-ba45-5ebf44fd9ba6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-04ff2535-b38a-4c14-ba45-5ebf44fd9ba6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-04ff2535-b38a-4c14-ba45-5ebf44fd9ba6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                         board_syllabus  ... difficulty_label\n",
              "0                  AP>>VII>>Science>>Animal Fibre>>Silk  ...                0\n",
              "1     Maharashtra New>>VIII>>General Science>>Man Ma...  ...                2\n",
              "2     CBSE>>VI>>Science>>Fun with Magnets>>Demagneti...  ...                2\n",
              "3     Tamil Nadu>>VIII>>Science>>Term 1>>Physics>>Li...  ...                0\n",
              "4     Raj English>>XII>>Biology>>Integumentary Syste...  ...                0\n",
              "...                                                 ...  ...              ...\n",
              "2055  CBSE>>XI>>Chemistry>>Chemistry : Part I>>Equil...  ...                0\n",
              "2056  CBSE>>VI>>Computer Science>>Using Mail Merge>>...  ...                1\n",
              "2057  CBSE>>XII>>Physics>>Physics : Part - II>>Ray O...  ...                0\n",
              "2058  ICSE OLD>>VII>>Biology>>Organ System of Human ...  ...                1\n",
              "2059  CBSE>>X>>Science>>Carbon and its Compounds>>Al...  ...                0\n",
              "\n",
              "[2060 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8tVsjiWj-cF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "77c08629-28b3-49b7-f019-389d79c7bdaa"
      },
      "source": [
        "test = pd.read_csv(\"test_skill_name_difficulty.csv\")\n",
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ec0bcf68-c7b6-4b01-a5f9-69e2011b9304\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>board_syllabus</th>\n",
              "      <th>question_answer</th>\n",
              "      <th>skill_label</th>\n",
              "      <th>difficulty_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CBSE&gt;&gt;Nursery&gt;&gt;Environmental Science&gt;&gt;Common V...</td>\n",
              "      <td>Write down the names of some common vegetable...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CBSE&gt;&gt;XII&gt;&gt;Physics&gt;&gt;Physics : Part - II&gt;&gt;Atoms</td>\n",
              "      <td>Name the series of hydrogen atom which lies i...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ICSE OLD&gt;&gt;XI&gt;&gt;Political Science&gt;&gt;State, Govern...</td>\n",
              "      <td>Which of the following is not the element of ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Maharashtra New&gt;&gt;VII&gt;&gt;General Science&gt;&gt;Static ...</td>\n",
              "      <td>The process of electrically charging an objec...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tamil Nadu&gt;&gt;IX&gt;&gt;Science&gt;&gt;Physics&gt;&gt;Measurement&gt;...</td>\n",
              "      <td>The mass of an object is measured in kilogram...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4572</th>\n",
              "      <td>ICSE OLD&gt;&gt;VIII&gt;&gt;Biology&gt;&gt;Nervous System And Se...</td>\n",
              "      <td>Which of the following is the first cranial n...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4573</th>\n",
              "      <td>CBSE&gt;&gt;VII&gt;&gt;Computer Science&gt;&gt;Advance features ...</td>\n",
              "      <td>To ungroup the worksheets: Right-click on any...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4574</th>\n",
              "      <td>CBSE&gt;&gt;VIII&gt;&gt;Science&gt;&gt;Chemical Effects of Elect...</td>\n",
              "      <td>After passing electricity through a solution ...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4575</th>\n",
              "      <td>CLSP&gt;&gt;Stage 9&gt;&gt;Science&gt;&gt;Chemistry&gt;&gt;Material pr...</td>\n",
              "      <td>Identify the scientists who gave the “plum-pu...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4576</th>\n",
              "      <td>AP&gt;&gt;VIII&gt;&gt;Physical Science&gt;&gt;Physical Science (...</td>\n",
              "      <td>What do you understand by the term static ele...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4577 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec0bcf68-c7b6-4b01-a5f9-69e2011b9304')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ec0bcf68-c7b6-4b01-a5f9-69e2011b9304 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ec0bcf68-c7b6-4b01-a5f9-69e2011b9304');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                         board_syllabus  ... difficulty_label\n",
              "0     CBSE>>Nursery>>Environmental Science>>Common V...  ...                2\n",
              "1        CBSE>>XII>>Physics>>Physics : Part - II>>Atoms  ...                1\n",
              "2     ICSE OLD>>XI>>Political Science>>State, Govern...  ...                0\n",
              "3     Maharashtra New>>VII>>General Science>>Static ...  ...                1\n",
              "4     Tamil Nadu>>IX>>Science>>Physics>>Measurement>...  ...                1\n",
              "...                                                 ...  ...              ...\n",
              "4572  ICSE OLD>>VIII>>Biology>>Nervous System And Se...  ...                1\n",
              "4573  CBSE>>VII>>Computer Science>>Advance features ...  ...                0\n",
              "4574  CBSE>>VIII>>Science>>Chemical Effects of Elect...  ...                2\n",
              "4575  CLSP>>Stage 9>>Science>>Chemistry>>Material pr...  ...                0\n",
              "4576  AP>>VIII>>Physical Science>>Physical Science (...  ...                1\n",
              "\n",
              "[4577 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIrS5sxE3kgk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "7cd72753a7ae4627a3cbae08d5a03888",
            "86684b9c88da422e910a3423396aa537",
            "1896bc72003e4035a66f7b2ef9af0e4d",
            "4ba04fee022e4fa69f6eafcab22e1674",
            "c9ab0115145541558786c7292db930fb",
            "fa9e91fd8477425087d2045ffb9aeae2",
            "ada269048a0346af98ea426d8bf87ac1",
            "759f187f102e4218bb0602684a81b88a",
            "41eb0bf506a4463bb53d79360a91f0e2",
            "1ac5f96821b647a6a817ded6c9fb0e66",
            "ac72d343d2544fbba9b26434797cb3c1"
          ]
        },
        "outputId": "5784eb05-5d6d-48fe-a94d-95e9f0c8f5c3"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7cd72753a7ae4627a3cbae08d5a03888",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp64MkNB3kg1"
      },
      "source": [
        "\n",
        "def get_labels(prediction):\n",
        "    predicted_label =  LE.inverse_transform([prediction])\n",
        "    return predicted_label[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPgTmJPS3kg4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "8de16679-8585-491f-9479-c490300fedc0"
      },
      "source": [
        "import joblib\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "LE = LabelEncoder()\n",
        "LE = joblib.load('label_encoder_difficulty_Lstm')\n",
        "\n",
        "get_labels(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Difficult'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_UpqLMG3kg9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "433eef56-eab3-4efa-e96e-ef034f386d94"
      },
      "source": [
        "final_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c0227b0c-4c1b-420b-95ad-74ef701511e8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>board_syllabus</th>\n",
              "      <th>question_answer</th>\n",
              "      <th>skill_label</th>\n",
              "      <th>difficulty_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Raj English&gt;&gt;XII&gt;&gt;Biology&gt;&gt;Domestication, Cult...</td>\n",
              "      <td>Among the following, freshwater fish is rohu ...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Maharashtra New&gt;&gt;VI&gt;&gt;General Science&gt;&gt;Sound&gt;&gt;P...</td>\n",
              "      <td>Which of the following statement is true? Sou...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ICSE OLD&gt;&gt;XI&gt;&gt;Computer Science&gt;&gt;Functions&gt;&gt;Con...</td>\n",
              "      <td>The process of using multiple constructors wi...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CBSE&gt;&gt;VI&gt;&gt;Science&gt;&gt;Separation of Substances&gt;&gt;S...</td>\n",
              "      <td>Sieving is based on the difference in the siz...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AP&gt;&gt;X&gt;&gt;Biology&gt;&gt;Excretion - The Wastage Dispos...</td>\n",
              "      <td>The removal of toxic and unwanted waste subst...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39124</th>\n",
              "      <td>CAPS(South Africa)&gt;&gt;Grade 7&gt;&gt;Natural Sciences&gt;...</td>\n",
              "      <td>How heat loss problems are prevented by birds...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39125</th>\n",
              "      <td>CBSE&gt;&gt;X&gt;&gt;Science&gt;&gt;Metals and Non-Metal</td>\n",
              "      <td>Give reasons why copper is used to make hot w...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39126</th>\n",
              "      <td>CBSE&gt;&gt;VII&gt;&gt;Science&gt;&gt;Motion and Time</td>\n",
              "      <td>The horizontal line in the graph is denoted as...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39127</th>\n",
              "      <td>Tamil Nadu&gt;&gt;VI&gt;&gt;Science&gt;&gt;Term 1&gt;&gt;Physics&gt;&gt;Forc...</td>\n",
              "      <td>SI unit of force is newton The SI unit of for...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39128</th>\n",
              "      <td>Tamil Nadu&gt;&gt;VIII&gt;&gt;Science&gt;&gt;Term 1&gt;&gt;Physics&gt;&gt;Fo...</td>\n",
              "      <td>In machines sliding frictions is replaced to ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39129 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0227b0c-4c1b-420b-95ad-74ef701511e8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c0227b0c-4c1b-420b-95ad-74ef701511e8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c0227b0c-4c1b-420b-95ad-74ef701511e8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                          board_syllabus  ... difficulty_label\n",
              "0      Raj English>>XII>>Biology>>Domestication, Cult...  ...                0\n",
              "1      Maharashtra New>>VI>>General Science>>Sound>>P...  ...                2\n",
              "2      ICSE OLD>>XI>>Computer Science>>Functions>>Con...  ...                0\n",
              "3      CBSE>>VI>>Science>>Separation of Substances>>S...  ...                1\n",
              "4      AP>>X>>Biology>>Excretion - The Wastage Dispos...  ...                1\n",
              "...                                                  ...  ...              ...\n",
              "39124  CAPS(South Africa)>>Grade 7>>Natural Sciences>...  ...                1\n",
              "39125             CBSE>>X>>Science>>Metals and Non-Metal  ...                2\n",
              "39126                CBSE>>VII>>Science>>Motion and Time  ...                1\n",
              "39127  Tamil Nadu>>VI>>Science>>Term 1>>Physics>>Forc...  ...                2\n",
              "39128  Tamil Nadu>>VIII>>Science>>Term 1>>Physics>>Fo...  ...                1\n",
              "\n",
              "[39129 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHdVe13Fr3vt"
      },
      "source": [
        "new_data = final_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkyM7gqv3khI"
      },
      "source": [
        "question_answer = new_data[\"question_answer\"].values\n",
        "categories = new_data[\"difficulty_label\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ndpw0p1SBUoZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87ef356d-9060-4bb3-8c33-5140bf74fbbe"
      },
      "source": [
        "question_answer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' Among the following, freshwater fish is rohu Rohu is a fresh water fish. Other common freshwater fish are catla, common carp.',\n",
              "       ' Which of the following statement is true? Sound requires a medium for propagation. Sound travels through a medium (solid, liquid or gas). It cannot travel through vacuum.',\n",
              "       ' The process of using multiple constructors with the same name but with different parameters is known as: Constructor overloading Constructor overloading is a technique in Java in which a class can have any number of constructors that differ in parameter lists.',\n",
              "       ...,\n",
              "       'The horizontal line in the graph is denoted as the X-axis. The horizontal line points in the horizontal direction and is denoted as the X-axis in the graph.',\n",
              "       ' SI unit of force is newton The SI unit of force is Newton (N), named after famous scientist Isaac Newton who discovered force of gravitation.',\n",
              "       ' In machines sliding frictions is replaced to rolling by use of ball bearings Ball bearing roll to produce rolling;friction.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFkS_H_83khL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ddc10190-f19a-477a-efe6-717840699baa"
      },
      "source": [
        "question_answer[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' Among the following, freshwater fish is rohu Rohu is a fresh water fish. Other common freshwater fish are catla, common carp.'"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ian7gSDE3khR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b141c426-b63f-47b9-dae3-38857f24311e"
      },
      "source": [
        "len(categories)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39129"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_ZeuHc63khU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a99cb9eb-9c7b-477b-a4e5-780f9a14214a"
      },
      "source": [
        "import torch\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in question_answer:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', question_answer[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:   Among the following, freshwater fish is rohu Rohu is a fresh water fish. Other common freshwater fish are catla, common carp.\n",
            "Token IDs: tensor([  101,  2426,  1996,  2206,  1010, 12573,  3869,  2003, 20996,  6979,\n",
            "        20996,  6979,  2003,  1037,  4840,  2300,  3869,  1012,  2060,  2691,\n",
            "        12573,  3869,  2024,  4937,  2721,  1010,  2691, 29267,  1012,   102,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVGvVZb13kha",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f115704e-11aa-4ca3-83f2-fb4688b41935"
      },
      "source": [
        "print('Original: ', len(question_answer[1]))\n",
        "print('Token IDs:', len(input_ids[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  171\n",
            "Token IDs: 128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nmRiaBbA9OH"
      },
      "source": [
        "val_text = val[\"question_answer\"].values\n",
        "val_labels = val[\"difficulty_label\"].values\n",
        "test_text = test[\"question_answer\"].values\n",
        "test_labels = test[\"difficulty_label\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-s_H1WdyvCw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b329fd6-4d72-4622-b020-6fd1a63d0fe2"
      },
      "source": [
        "test_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 0, ..., 2, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF-mKCC1CUjD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b739c1b-cccd-4e34-e539-3039f52f64e4"
      },
      "source": [
        "val_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 2, ..., 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOQuDahhAzOO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3f5a287-c923-46c4-e64b-fb48742aa000"
      },
      "source": [
        "val_input_ids = []\n",
        "val_attention_masks = []\n",
        "\n",
        "for sent in val_text:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    val_input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    val_attention_masks.append(encoded_dict['attention_mask'])\n",
        "# Convert the lists into tensors.\n",
        "val_input_ids = torch.cat(val_input_ids, dim=0)\n",
        "val_attention_masks = torch.cat(val_attention_masks, dim=0)\n",
        "\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', val_text[0])\n",
        "print('Token IDs:', val_attention_masks[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:   Name the two types of protein from which silk is made. Sericin and fibroin \n",
            "Token IDs: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Siskea7qDLUG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20b0a970-e661-440f-c4d8-18df38733161"
      },
      "source": [
        "print('Original: ', val_text[1])\n",
        "print('Token IDs:', val_input_ids[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:   Give reasons: (i) Thermocol is used for the packing of delicate items. (ii) Name two diseases that may develop in people working in thermocol industries. (i) Thermocol is a good shock-absorber, therefore, it is used for packing of delicate items. (ii) People working in thermocol industries may suffer from blood cancer such as leukemia and lymphoma or have problems in eyes and respiratory system. \n",
            "Token IDs: tensor([  101,  2507,  4436,  1024,  1006,  1045,  1007,  1996, 10867, 24163,\n",
            "         2140,  2003,  2109,  2005,  1996, 14743,  1997, 10059,  5167,  1012,\n",
            "         1006,  2462,  1007,  2171,  2048,  7870,  2008,  2089,  4503,  1999,\n",
            "         2111,  2551,  1999,  1996, 10867, 24163,  2140,  6088,  1012,  1006,\n",
            "         1045,  1007,  1996, 10867, 24163,  2140,  2003,  1037,  2204,  5213,\n",
            "         1011, 16888,  2121,  1010,  3568,  1010,  2009,  2003,  2109,  2005,\n",
            "        14743,  1997, 10059,  5167,  1012,  1006,  2462,  1007,  2111,  2551,\n",
            "         1999,  1996, 10867, 24163,  2140,  6088,  2089,  9015,  2013,  2668,\n",
            "         4456,  2107,  2004, 25468,  1998,  1048, 24335,  8458,  9626,  2030,\n",
            "         2031,  3471,  1999,  2159,  1998, 16464,  2291,  1012,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irMTimjf3khd"
      },
      "source": [
        "labels = torch.tensor(categories)\n",
        "val_labels = torch.tensor(val_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdOgWP_LKTHi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92d1e8cb-e431-4f6a-d1b9-0f450e2a39f8"
      },
      "source": [
        "val_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 2, 2,  ..., 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJJ0I8Ud3khf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8b7e57aa-cd81-4c2e-8b87-a583c57982d9"
      },
      "source": [
        "get_labels(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Easy'"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1ZAbQRfiG63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b37b9ec6-f1cb-4311-be81-ad2cd00dd931"
      },
      "source": [
        "len(set(final_data[\"question_answer\"].values).intersection(val[\"question_answer\"].values))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNDW74Ny3khj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9e90c75-b81f-4642-da6e-6f05a93a9428"
      },
      "source": [
        "num_classes = len(list(set(categories)))\n",
        "list(set(categories))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmaLk5Ab3khl"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "# train_poincare_tensor = torch.tensor(poincare_embeddings_final,dtype=torch.float)\n",
        "# difficulty_tensor = torch.tensor(difficulty_level_vectors,dtype=torch.float)\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "val_dataset = TensorDataset(val_input_ids, val_attention_masks,val_labels) \n",
        "# Create a 90-10train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "# train_size = int(0.90 * len(dataset))\n",
        "# val_size = len(dataset) - train_size\n",
        "\n",
        "# # Divide the dataset by randomly selecting samples.\n",
        "# train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# print('{:>5,} training samples'.format(train_size))\n",
        "# # print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_lTinod3kho"
      },
      "source": [
        "\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size = 34\n",
        "train_dataloader = DataLoader(\n",
        "            dataset,  # The training samples.\n",
        "            sampler = RandomSampler(dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), \n",
        "            batch_size = batch_size \n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2tmAMlw3khr"
      },
      "source": [
        "from transformers import BertModel, AdamW, BertConfig\n",
        "\n",
        "# # Loads BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# model = BertModel.from_pretrained(\n",
        "#     \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "# )\n",
        "\n",
        "# # Tell pytorch to run this model on the GPU.\n",
        "# model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkDmTZhVChN6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6bb46a8-3efd-4d19-a220-878cfb5bfc39"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "set(test[\"question_answer\"].values).intersection(set(final_data[\"question_answer\"].values))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJ9iUjJiHI7k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17b0d9c5-2f09-40b0-fbd3-0a7b10ec309e"
      },
      "source": [
        "!unzip \"/content/drive/MyDrive/research_skill_name_prediction/model_bert_multi_task_interactive_final.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/research_skill_name_prediction/model_bert_multi_task_interactive_final.zip\n",
            "   creating: model_bert_multi_task_interactive_final/\n",
            "  inflating: model_bert_multi_task_interactive_final/special_tokens_map.json  \n",
            " extracting: model_bert_multi_task_interactive_final/tokenizer_config.json  \n",
            "  inflating: model_bert_multi_task_interactive_final/vocab.txt  \n",
            "  inflating: model_bert_multi_task_interactive_final/model_weights  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip \"/content/drive/MyDrive/research_skill_name_prediction/model_bert_multi_task_prediction.zip\"\n",
        "!cp -r \"/content/drive/MyDrive/research_skill_name_prediction/model_bert_multi_task_prediction_final\" /content"
      ],
      "metadata": {
        "id": "V1d0rl8rINpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n"
      ],
      "metadata": {
        "id": "BzAqI9j7T7fE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g8cFpXrpo9Q"
      },
      "source": [
        "from torch import nn\n",
        "class MultiClassClassifier(nn.Module):\n",
        "    def __init__(self, bert_model_path, labels_count,skill_label_count, hidden_dim=768, mlp_dim=500, extras_dim=140, dropout=0.1, freeze_bert=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(bert_model_path,output_hidden_states=False,output_attentions=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim , mlp_dim),\n",
        "            nn.ReLU(),\n",
        "            # nn.Linear(mlp_dim, mlp_dim),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(mlp_dim, mlp_dim),\n",
        "            # nn.ReLU(),            \n",
        "            nn.Linear(mlp_dim, labels_count)\n",
        "        )\n",
        "        self.mlp2 = nn.Sequential(\n",
        "            nn.Linear(hidden_dim , mlp_dim),\n",
        "            nn.ReLU(),         \n",
        "            nn.Linear(mlp_dim, skill_label_count)\n",
        "        )\n",
        "        # self.softmax = nn.LogSoftmax(dim=1)\n",
        "        if freeze_bert:\n",
        "            print(\"Freezing layers\")\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, tokens, masks):\n",
        "        _,pooled_output = self.bert(tokens, attention_mask=masks)\n",
        "\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        concat_output = dropout_output\n",
        "        mlp_output = self.mlp(concat_output)\n",
        "        skill_output = self.mlp2(concat_output)\n",
        "        # proba = self.sigmoid(mlp_output)\n",
        "        # proba = self.softmax(mlp_output)\n",
        "\n",
        "        return mlp_output,skill_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzdVd6lUEfv8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "342f3369-b679-4321-df01-74acd44a9cd0"
      },
      "source": [
        "num_classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kctN7UA1bhCx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "fc81f56bf9064e5182644521b3e915e0",
            "de4aa0f5f93e4465b08857fae5789ee6",
            "37e7949b87914659bf87debd59771599",
            "d649384285d14364af56da1e238090a2",
            "a3e428e4ec324189a938287049c1feb9",
            "abd274069b30471f955464d3a95e08dd",
            "1c1b4f99f1a54b1b9771e5528043d4e1",
            "10028f73076f4cd3b3fc6ffc32f22970",
            "dd06240d1097419e9849c9106431a6ec",
            "4f45ce89b5e142c18322fe4e560ae6d6",
            "45fe2949a10c49b6ad7a2928d625a506",
            "dd4bf0d060ff4a478d7ff183ea934120",
            "877803b21323407280c6c664cbda3da9",
            "ac2fe627cd0a44efa343c1507ad6284f",
            "4abee27fac4b4a2a8fca82dd60a42f8b",
            "9a0099799bbe47489d548ac39de8d5ad",
            "0b248779ad7c41a7bd16b03f7f62c475",
            "f505dddb32054a90b8fcb706fb389093",
            "4ab9c8bca00540279d56f4495b3e8a75",
            "2831ecaa630444a5a48934fd10ddfc5e",
            "4b1354aa66f14ab3971b2c13bbb0a483",
            "6d81e1196c404328a4cc985a78047c8e"
          ]
        },
        "outputId": "9b9ec3fd-bdbc-4dd7-ee45-59e70e587cc1"
      },
      "source": [
        "model_multi_task = MultiClassClassifier('bert-base-uncased',3, 5,768,500,140,dropout=0.1,freeze_bert=False)\n",
        "model_multi_task.load_state_dict(torch.load('model_bert_multi_task_prediction_final/model_weights'))\n",
        "model_multi_task.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc81f56bf9064e5182644521b3e915e0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd4bf0d060ff4a478d7ff183ea934120",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiClassClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (mlp): Sequential(\n",
              "    (0): Linear(in_features=768, out_features=500, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=500, out_features=3, bias=True)\n",
              "  )\n",
              "  (mlp2): Sequential(\n",
              "    (0): Linear(in_features=768, out_features=500, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=500, out_features=5, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYLxYivOFpKo"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "\n",
        "class AttentionBlock(nn.Module):\n",
        "  def __init__(self,vector_1_dim,vector_2_dim):\n",
        "    super(AttentionBlock, self).__init__()\n",
        "    self.Weights = nn.Parameter(torch.rand(vector_2_dim,vector_1_dim))\n",
        "    self.bias = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "  def forward(self,vector_1,vector_2):\n",
        "    #(batch_size,vector_2_dim,vector_1_dim)\n",
        "    weights = self.Weights.repeat(vector_2.size(0),1,1)\n",
        "    vector_1 = vector_1.unsqueeze(-1)  # (batch_size,vector_2_dim,vector_1_dim)\n",
        "    weights = weights.matmul(vector_1) # results in (batch_size,vector_2_dim,1)\n",
        "    weights = weights.repeat(vector_2.size(1),1,1,1).transpose(0,1)\n",
        "    vector_2 = vector_2.unsqueeze(-2)\n",
        "    attention_weights = torch.tanh(vector_2.matmul(weights).squeeze() + self.bias) # batch_size, vector_2_dim.size(0)\n",
        "    if len(attention_weights.shape) ==1:\n",
        "      attention_weights = attention_weights.squeeze()\n",
        "      attention_weights = attention_weights.reshape(1,-1)\n",
        "    attention_weights = attention_weights.squeeze()\n",
        "    # print(\"torch.exp(attention_weights)\",torch.exp(attention_weights).shape,attention_weights.shape,torch.exp(attention_weights).sum(dim=1).shape)\n",
        "    attention_weights = torch.exp(attention_weights)/ torch.exp(attention_weights).sum(dim=1,keepdim=True)\n",
        "\n",
        "    return attention_weights\n",
        "\n",
        "# bloom interactive attention\n",
        "class MultiClassClassifier(nn.Module):\n",
        "    def __init__(self, bert_model_path, labels_count,skill_label_count, hidden_dim=768, mlp_dim=500, extras_dim=140, dropout=0.1, freeze_bert=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(bert_model_path,output_hidden_states=True,output_attentions=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.bloom_attention = AttentionBlock(768, 768)\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim , mlp_dim),\n",
        "            nn.ReLU(),\n",
        "            # nn.Linear(mlp_dim, mlp_dim),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(mlp_dim, mlp_dim),\n",
        "            # nn.ReLU(),            \n",
        "            nn.Linear(mlp_dim, labels_count)\n",
        "        )\n",
        "        self.mlp2 = nn.Sequential(  \n",
        "            nn.Linear(hidden_dim , mlp_dim),\n",
        "            nn.ReLU(),         \n",
        "            nn.Linear(mlp_dim, skill_label_count)\n",
        "        )\n",
        "        # self.softmax = nn.LogSoftmax(dim=1)\n",
        "        if freeze_bert:\n",
        "            print(\"Freezing layers\")\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, tokens, masks):\n",
        "        _, pooled_output,hidden_states,attentions = self.bert(tokens, attention_mask=masks)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        concat_output = dropout_output\n",
        "\n",
        "        # mlp_output = self.mlp(concat_output)\n",
        "        skill_output_probas = self.mlp2(concat_output)\n",
        "        skill_output = torch.argmax(skill_output_probas,axis=1).cpu().numpy()\n",
        "        skill_output = LE_skill.inverse_transform(skill_output)\n",
        "        skill_input_ids = []\n",
        "        skill_attention_masks = []\n",
        "        for skill_text in skill_output:\n",
        "          encoded_skill_output = tokenizer.encode_plus(\n",
        "                          skill_text,                      # Sentence to encode.\n",
        "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                          max_length = 128,           # Pad & truncate all sentences.\n",
        "                          pad_to_max_length = True,\n",
        "                          truncation=True,\n",
        "                          return_attention_mask = True,   # Construct attn. masks.\n",
        "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                    )\n",
        "          skill_input_ids.append(encoded_skill_output['input_ids'])\n",
        "          skill_attention_masks.append(encoded_skill_output['attention_mask'])\n",
        "        skill_input_ids = torch.cat(skill_input_ids,dim=0).cuda()\n",
        "        skill_attention_masks = torch.cat(skill_attention_masks,dim=0).cuda()\n",
        "        _,_,hidden_states_skill,_ = self.bert(skill_input_ids,skill_attention_masks)\n",
        "\n",
        "        skill_hidden_averaged =  torch.sum(hidden_states_skill[12],dim=1)/hidden_states_skill[12].shape[1]\n",
        "\n",
        "        bloom_attention_weights = self.bloom_attention(skill_hidden_averaged, hidden_states[12])\n",
        "\n",
        "        bloom_attention_weights = bloom_attention_weights.unsqueeze(-2)\n",
        "        # print(\"context_attention_weights\",context_attention_weights.shape,context_out.shape)\n",
        "        input_attended_vector = bloom_attention_weights.matmul(hidden_states[12]).squeeze()\n",
        "\n",
        "        mlp_output = self.mlp(input_attended_vector)\n",
        "\n",
        "        # print(\"bloom attention weights\", bloom_attention_weights.shape)\n",
        "        # print(\"_hidden_states\",hidden_states_skill[12].shape, hidden_states[12].shape,skill_hidden_averaged.shape)\n",
        "\n",
        "        # proba = self.sigmoid(mlp_output)\n",
        "        # proba = self.softmax(mlp_output)\n",
        "\n",
        "        return mlp_output,skill_output_probas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xy6FOcfNRp0P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73bf74eb-0319-4868-a5dc-fc20e84047dd"
      },
      "source": [
        "skill_label_count = len(list(set(new_data[\"skill_label\"].values)))\n",
        "skill_label_count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIbXoNcuUukV"
      },
      "source": [
        "!cp -r \"/content/drive/MyDrive/research_skill_name_prediction/model_bert_multi_task_interactive_final\" /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDaXrwL5Fut_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1e32ab7-459b-40d3-e418-79f7fc1c1199"
      },
      "source": [
        "model_interactive = MultiClassClassifier('bert-base-uncased',num_classes, skill_label_count,768,500,140,dropout=0.1,freeze_bert=False)\n",
        "model_interactive.load_state_dict(torch.load(\"model_bert_multi_task_interactive_final/model_weights\"))\n",
        "model_interactive.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiClassClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (bloom_attention): AttentionBlock()\n",
              "  (mlp): Sequential(\n",
              "    (0): Linear(in_features=768, out_features=500, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=500, out_features=3, bias=True)\n",
              "  )\n",
              "  (mlp2): Sequential(\n",
              "    (0): Linear(in_features=768, out_features=500, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=500, out_features=5, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gtKYG0VeVwk"
      },
      "source": [
        "# for param in model.bert.encoder.layer[0:12].parameters():\n",
        "#     param.requires_grad=False\n",
        "# for param in model.bert.embeddings.parameters():\n",
        "#     param.requires_grad=False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4178_yLFMWmx"
      },
      "source": [
        "test_features = test[\"question_answer\"].values\n",
        "test_labels = test[\"difficulty_label\"].values\n",
        "test_skill_labels = test[\"skill_label\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DggP9Sxdv_-l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c5f7342-8c15-4a3c-9d8e-fcc26260e419"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "test_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 0, ..., 2, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZpmBJuIC2nM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe69ca41-ae2b-430a-e4cc-d907dd59a765"
      },
      "source": [
        "test_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' Write down the names of some common vegetables. Answer may vary Probable answer – Names of some common vegetables are potato, onion, tomato and carrot. ',\n",
              "       ' Name the series of hydrogen atom which lies in the U.V region. Lyman series lies in the U.V region. ',\n",
              "       ' Which of the following is not the element of an association? Relationships are abstract Each association has elements 1) a group of people, 2) voluntary Membership, 3) shared and common interests or needs as the basis, 4) some set of objective goals which are to be achieved collectively by all the members, 5) a voluntary organisation, and 6) co-operation among the members objectives pooled resources for funds needed for action.',\n",
              "       ...,\n",
              "       ' After passing electricity through a solution the change that takes place is a chemical change Physical changes are those changes that do not result in the production of a new substance whereas a chemical change involves the production of a new substance. For example: When electricity is passed in a solution containing water, bubbles of hydrogen and oxygen are formed.',\n",
              "       ' Identify the scientists who gave the “plum-pudding” model of the atom. J. J. Thomson The &ldquo;plum-pudding&rdquo; model of the atom was developed by the J. J Thomson. He compared his model used for describing the structure of atom with a plum pudding in which negatively charged electrons were surrounded by a positively charged &lsquo;pudding&rsquo;.',\n",
              "       ' What do you understand by the term static electricity? It is the electricity developed due to stationary electric charges on the body. '],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlOvANUwprAw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7218dccc-52da-41eb-ae0d-f1532f4c6d7f"
      },
      "source": [
        "test_features[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' Write down the names of some common vegetables. Answer may vary Probable answer – Names of some common vegetables are potato, onion, tomato and carrot. '"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmmWYcW2sNHe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6a8fc79-af01-4d80-84eb-28a9ee4ed7c4"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "for sent in test_features:\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "test_skill_labels = torch.tensor(test_skill_labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 34\n",
        "\n",
        "# test_poincare_tensor = torch.tensor(poincare_embeddings_final,dtype=torch.float)\n",
        "# print(test_poincare_tensor.shape)\n",
        "# difficulty_tensor = torch.tensor(difficulty_level_vectors,dtype=torch.float)\n",
        "# print(\"difficulty_tensor\",difficulty_tensor.shape)\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, test_labels,test_skill_labels)\n",
        "# Create the DataLoader.\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX-RiYbQPDpx"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFediYEjlKjX"
      },
      "source": [
        "def get_confusion_matrix(predicted,actual):\n",
        "    conf_matrix = np.zeros((3, 3))\n",
        "    for pred,act in zip(predicted,actual):\n",
        "        conf_matrix[act,pred]+=1\n",
        "    return conf_matrix\n",
        "        \n",
        "def get_TP(confusion_matrix,label):\n",
        "    tp = confusion_matrix[label][label]\n",
        "    return tp\n",
        "\n",
        "def get_FN(confusion_matrix,label):\n",
        "    row = confusion_matrix[label,]\n",
        "    row_truepositives = row[label]\n",
        "    fn = row.sum() - row_truepositives\n",
        "    return fn\n",
        "\n",
        "def get_FP(confusion_matrix,tag):\n",
        "    col = confusion_matrix[:,tag]\n",
        "    col_tp = col[tag]\n",
        "    #  sum of all values in column except tp\n",
        "    fp = col.sum() - col_tp\n",
        "    return fp\n",
        "def Precision(conf_matrix):\n",
        "    precision = 0.0\n",
        "    for label in [0,1,2]:\n",
        "        dividor= get_TP(conf_matrix,label)+get_FP(conf_matrix,label)\n",
        "        if dividor != 0.0:\n",
        "            precision += (get_TP(conf_matrix,label))/dividor\n",
        "    return (precision / 3)\n",
        "\n",
        "def Recall(conf_matrix):\n",
        "    recall = 0.0\n",
        "    for label in [0,1,2]:\n",
        "        dividor=get_TP(conf_matrix,label)+get_FN(conf_matrix,label)\n",
        "        if dividor != 0.0:\n",
        "            recall += (get_TP(conf_matrix,label))/dividor\n",
        "    return (recall / 3)\n",
        "\n",
        "def F1(precision,recall):\n",
        "    return (2*precision*recall)/(precision+recall)\n",
        "def accuracy_per_class(preds_flat, labels_flat):\n",
        "\n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label}')\n",
        "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n",
        "def print_metrics(predictions,test_labels):\n",
        "    conf_matrix = get_confusion_matrix(predictions,test_labels)\n",
        "    precision = Precision(conf_matrix)\n",
        "    recall = Recall(conf_matrix)\n",
        "    f1_score = F1(precision,recall)\n",
        "    return (precision,recall,f1_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFEi23ejPfOm"
      },
      "source": [
        "\n",
        "def Precision_macro_weighted(conf_matrix,test_samples):\n",
        "    accum =0\n",
        "    label_wise_precision = dict()\n",
        "    for label in [0,1,2]:\n",
        "        true_sample = [sample for sample in test_samples if sample==label ]\n",
        "        if (get_TP(conf_matrix,label)+get_FP(conf_matrix,label))!=0:\n",
        "            accum+= float(len(true_sample)) *(get_TP(conf_matrix,label)/(get_TP(conf_matrix,label)+get_FP(conf_matrix,label)))\n",
        "            label_wise_precision[label] = get_TP(conf_matrix,label)/(get_TP(conf_matrix,label)+get_FP(conf_matrix,label))\n",
        "\n",
        "    \n",
        "    precision =  accum/len(test_samples)\n",
        "            \n",
        "    return precision\n",
        "\n",
        "\n",
        "def Recall_macro_weighted(conf_matrix,test_samples):\n",
        "    accum =0\n",
        "    label_wise_recall = dict()\n",
        "    for label in [0,1,2]:\n",
        "        true_sample = [sample for sample in test_samples if sample==label ]\n",
        "\n",
        "        if (get_TP(conf_matrix,label)+get_FN(conf_matrix,label))!=0:\n",
        "            accum+= float(len(true_sample)) * (get_TP(conf_matrix,label)/(get_TP(conf_matrix,label)+get_FN(conf_matrix,label)))\n",
        "            label_wise_recall[label] = get_TP(conf_matrix,label)/(get_TP(conf_matrix,label)+get_FN(conf_matrix,label))\n",
        "\n",
        "    \n",
        "    recall =  accum/len(test_samples)\n",
        "    return recall\n",
        "def print_weighted_metrics(predictions,test_labels):\n",
        "    conf_matrix = get_confusion_matrix(predictions,test_labels)\n",
        "    precision = Precision_macro_weighted(conf_matrix,test_labels)\n",
        "    recall = Recall_macro_weighted(conf_matrix,test_labels)\n",
        "    f1_score = F1(precision,recall)\n",
        "    return (precision,recall,f1_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9F7JWv8uFrL-"
      },
      "source": [
        "def make_lstm_and_gru_predictions(index, params):\n",
        "  model_lstm.eval()\n",
        "  model_gru.eval()\n",
        "  for i,batch in enumerate(test_iter):\n",
        "    outputs = []\n",
        "    if i == index:\n",
        "      # print(\"i\",i,index)\n",
        "      with torch.no_grad():\n",
        "          question, x_len = batch.text\n",
        "          x = question.cuda()\n",
        "          # outs = sigmoid(outs.cpu().data.numpy()).tolist()\n",
        "          y = batch.label.type(torch.long).cuda()\n",
        "          if params['lstm']>=0.5:\n",
        "            lstm_outputs = model_lstm(x,x_len)\n",
        "            outputs.append(lstm_outputs)\n",
        "          if params[\"gru\"]>=0.5:\n",
        "            gru_outputs = model_gru(x,x_len)\n",
        "            outputs.append(gru_outputs)\n",
        "          \n",
        "          return outputs\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBS6OmWO1DJ6"
      },
      "source": [
        "Now for comapring statistical significance between ensemble mlp and bo ensemble\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBqbaDo11IZc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0831043f-8d05-4a4a-8c93-2486bc637052"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=5, shuffle=True)\n",
        "kf.split(test_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object _BaseKFold.split at 0x7fe5e619ae50>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6Fk2gObC8iw"
      },
      "source": [
        "def get_interactive_predictions(prediction_dataloader):\n",
        "  predictions=[]\n",
        "  true_labels=[]\n",
        "  for index,batch in enumerate(prediction_dataloader):\n",
        "      final_outputs = []\n",
        "      # Add batch to GPU\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      \n",
        "      # Unpack the inputs from our dataloader\n",
        "      b_input_ids, b_input_mask, b_labels, id = batch\n",
        "      # Telling the model not to compute or store gradients, saving memory and \n",
        "      # speeding up prediction\n",
        "      with torch.no_grad():\n",
        "          # Forward pass, calculate logit predictions\n",
        "            # print(\"multi\")\n",
        "          interactive_output,_ = model_interactive(b_input_ids,b_input_mask)\n",
        "          # final_outputs.append(interactive_output)\n",
        "      # logits_2 = outputs\n",
        "      # logist_1 = output_bert[0]\n",
        "      logits = interactive_output\n",
        "      # logits = torch.mean(torch.stack(predictions_1), dim=0)\n",
        "      # else:\n",
        "        # logits = predictions_1[0]\n",
        "      # Move logits and labels to CPU\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "      \n",
        "      # Store predictions and true labels\n",
        "      predictions.append(logits)\n",
        "      true_labels.append(label_ids)\n",
        "  flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "  flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "    # Combine the correct labels for each batch into a single list.\n",
        "  flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "  # metrics = precision_recall_fscore_support(flat_true_labels, flat_predictions, average='micro')\n",
        "  metrics = print_weighted_metrics(flat_predictions,flat_true_labels)\n",
        "  macro_metrics = print_metrics(flat_predictions,flat_true_labels)\n",
        "  return metrics[2],macro_metrics[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_multi_task_predictions(prediction_dataloader):\n",
        "  predictions=[]\n",
        "  true_labels=[]\n",
        "  for index,batch in enumerate(prediction_dataloader):\n",
        "      final_outputs = []\n",
        "      # Add batch to GPU\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      \n",
        "      # Unpack the inputs from our dataloader\n",
        "      b_input_ids, b_input_mask, b_labels, id = batch\n",
        "      # Telling the model not to compute or store gradients, saving memory and \n",
        "      # speeding up prediction\n",
        "      with torch.no_grad():\n",
        "          # Forward pass, calculate logit predictions\n",
        "            # print(\"multi\")\n",
        "          interactive_output,_ = model_multi_task(b_input_ids,b_input_mask)\n",
        "          # final_outputs.append(interactive_output)\n",
        "      # logits_2 = outputs\n",
        "      # logist_1 = output_bert[0]\n",
        "      logits = interactive_output\n",
        "      # logits = torch.mean(torch.stack(predictions_1), dim=0)\n",
        "      # else:\n",
        "        # logits = predictions_1[0]\n",
        "      # Move logits and labels to CPU\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "      \n",
        "      # Store predictions and true labels\n",
        "      predictions.append(logits)\n",
        "      true_labels.append(label_ids)\n",
        "  flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "  flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "    # Combine the correct labels for each batch into a single list.\n",
        "  flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "  # metrics = precision_recall_fscore_support(flat_true_labels, flat_predictions, average='micro')\n",
        "  metrics = print_weighted_metrics(flat_predictions,flat_true_labels)\n",
        "  macro_metrics = print_metrics(flat_predictions,flat_true_labels)\n",
        "  return metrics[2],macro_metrics[2]"
      ],
      "metadata": {
        "id": "NE_YHCjSKRqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QFUh7sqKv9n"
      },
      "source": [
        "test_labels = test[\"difficulty_label\"].values\n",
        "test_skill_labels = test[\"skill_label\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlXpc52FUTp1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "ea796459-9317-4268-d8fc-cafe65ee97cd"
      },
      "source": [
        "test.iloc[[2,3],:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-be3b2d68-e80b-40ba-8aa4-9887941202f8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>board_syllabus</th>\n",
              "      <th>question_answer</th>\n",
              "      <th>skill_label</th>\n",
              "      <th>difficulty_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ICSE OLD&gt;&gt;XI&gt;&gt;Political Science&gt;&gt;State, Govern...</td>\n",
              "      <td>Which of the following is not the element of ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Maharashtra New&gt;&gt;VII&gt;&gt;General Science&gt;&gt;Static ...</td>\n",
              "      <td>The process of electrically charging an objec...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be3b2d68-e80b-40ba-8aa4-9887941202f8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-be3b2d68-e80b-40ba-8aa4-9887941202f8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-be3b2d68-e80b-40ba-8aa4-9887941202f8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                      board_syllabus  ... difficulty_label\n",
              "2  ICSE OLD>>XI>>Political Science>>State, Govern...  ...                0\n",
              "3  Maharashtra New>>VII>>General Science>>Static ...  ...                1\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaozdK_RDJ0I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e536a2c-1358-4202-ad7b-f751edb13dce"
      },
      "source": [
        "for indices in kf.split(test_features):\n",
        "  print(len(indices[0]),len(indices[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3661 916\n",
            "3661 916\n",
            "3662 915\n",
            "3662 915\n",
            "3662 915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3gCmcJN2lJH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "005fb0e9-3781-4a46-e302-10e8cf469a6f"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "f1_multi_ensemble = []\n",
        "f1_int_ensemble =[]\n",
        "macro_f1_inti_ensemble = []\n",
        "macro_f1_multi_ensemble = []\n",
        "for indices in kf.split(test_features):\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  for sent in test_features[indices[0]]:\n",
        "\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 256,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  test_labels_tensor = torch.tensor(test_labels[indices[0]])\n",
        "  test_skill_labels_tensor = torch.tensor(test_skill_labels[indices[0]])\n",
        "\n",
        "  # test_text = torchtext.data.TabularDataset(examples=test.iloc[indices[1],:],\n",
        "  #                                    fields={'difficulty_label': ('label', target_diff),\n",
        "  #                                            'question_answer': ('text',text)})\n",
        "  # test_iter = torchtext.data.Iterator(dataset=test_text, batch_size=34,train=False, sort=False, sort_within_batch=False,shuffle=False)\n",
        "# Set the batch size.  /\n",
        "  # batch_size = 34  \n",
        "\n",
        "  prediction_data = TensorDataset(input_ids, attention_masks, test_labels_tensor,test_skill_labels_tensor)\n",
        "  # Create the DataLoader.\n",
        "  prediction_sampler = SequentialSampler(prediction_data)\n",
        "  prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=32)\n",
        "  f1_bo,macro_f1_bo = get_interactive_predictions(prediction_dataloader)\n",
        "  f1_mlp,macro_f1_mlp = get_multi_task_predictions(prediction_dataloader)\n",
        "  f1_multi_ensemble.append(f1_mlp)\n",
        "  f1_int_ensemble.append(f1_bo)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2zdPrxg2WUfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66vXZkmEmukt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "217af9b1-aa7b-4b7f-bcb1-09752de2d274"
      },
      "source": [
        "print(f1_int_ensemble)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.559500493839273, 0.5591086890204817, 0.5592984641019563, 0.5589826122226967, 0.5579003427739674]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVuCIr5rmukv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ecce29c-d531-4144-f9ca-b22cad0e7659"
      },
      "source": [
        "f1_multi_ensemble"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5415706960922761,\n",
              " 0.5464752720257292,\n",
              " 0.5455213042423982,\n",
              " 0.5466337606364109,\n",
              " 0.5423183782002412]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vts-3CwFmukw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00c51730-f3d9-459c-fde0-4775aca99629"
      },
      "source": [
        "from scipy import stats\n",
        "stats.ttest_rel(f1_int_ensemble,f1_multi_ensemble)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ttest_relResult(statistic=13.922217071286386, pvalue=0.00015435686488192736)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLO3BUOEKMpm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b8e84e6-fd4f-417b-bc1b-67635524f157"
      },
      "source": [
        "print(f1_int_ensemble)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.559500493839273, 0.5591086890204817, 0.5592984641019563, 0.5589826122226967, 0.5579003427739674]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71jVD2AAcMPe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "145b7a8a-32a0-4ed8-dc4d-718f069114ea"
      },
      "source": [
        "f1_multi_ensemble"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5415706960922761,\n",
              " 0.5464752720257292,\n",
              " 0.5455213042423982,\n",
              " 0.5466337606364109,\n",
              " 0.5423183782002412]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87jSlrNZJsfZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc7d92df-98e7-4f61-cf24-d9898c64b36e"
      },
      "source": [
        "from scipy import stats\n",
        "stats.ttest_rel(f1_int_ensemble,f1_multi_ensemble)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ttest_relResult(statistic=13.922217071286386, pvalue=0.00015435686488192736)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe4qYkV2C4fX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdf7e8bc-3f1d-44e4-a381-72ba8cd3325e"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "for sent in test_features:\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "test_skill_labels = torch.tensor(test_skill_labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 34\n",
        "# test_poincare_tensor = torch.tensor(poincare_embeddings_final,dtype=torch.float)\n",
        "# print(test_poincare_tensor.shape)\n",
        "# difficulty_tensor = torch.tensor(difficulty_level_vectors,dtype=torch.float)\n",
        "# print(\"difficulty_tensor\",difficulty_tensor.shape)\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, test_labels,test_skill_labels)\n",
        "# Create the DataLoader.\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPCktQT9DVT4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "425f6df0-ed64-40d5-d511-bbddfb925885"
      },
      "source": [
        "# Prediction on test set\n",
        "# device = ''\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model_interactive.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions,skill_predictions , true_labels, true_skill_labels = [], [], [], []\n",
        "\n",
        "# Predict ea\n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels,skill_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  # print(\"b_input_ids\",b_input_ids.shape)\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs,skill_ouputs = model_interactive(b_input_ids,b_input_mask)\n",
        "\n",
        "  logits = outputs\n",
        "  skill_logits = skill_ouputs\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  skill_logits = skill_logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  skill_labels = skill_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  skill_predictions.append(skill_logits)\n",
        "  true_labels.append(label_ids)\n",
        "  true_skill_labels.append(skill_labels)\n",
        "\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 4,577 test sentences...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "# mcc = matthews_corrcoef(flat_true_skill_labels, flat_skill_predictions)\n",
        "# \n",
        "# print('Total MCC: %.3f' % mcc)"
      ],
      "metadata": {
        "id": "dBaGljjsj6XF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbe2BbA4E20b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aa2460d-c51b-4df5-8d64-f9225280d76b"
      },
      "source": [
        "#difficuty macro\n",
        "print_metrics(flat_predictions,flat_true_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5442240407604801, 0.44662925306253287, 0.4906203134990908)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNp29QbiA1B8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a43c08d-0e5b-4c0d-a89f-52a64b864f8e"
      },
      "source": [
        "#difficulty\n",
        "print_weighted_metrics(flat_predictions,flat_true_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5562658106941797, 0.5641249726895347, 0.5601678270116647)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TJesN2Gm0OO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbb7d5ad-ebfc-4604-b7bd-068cc46c87b2"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model_interactive.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions,skill_predictions , true_labels, true_skill_labels = [], [], [], []\n",
        "\n",
        "# Predict ea\n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels,skill_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  # print(\"b_input_ids\",b_input_ids.shape)\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs,skill_ouputs = model_multi_task(b_input_ids,b_input_mask)\n",
        "\n",
        "  logits = outputs\n",
        "  skill_logits = skill_ouputs\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  skill_logits = skill_logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  skill_labels = skill_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  skill_predictions.append(skill_logits)\n",
        "  true_labels.append(label_ids)\n",
        "  true_skill_labels.append(skill_labels)\n",
        "\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 4,577 test sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "# mcc = matthews_corrcoef(flat_true_skill_labels, flat_skill_predictions)\n",
        "# \n",
        "# print('Total MCC: %.3f' % mcc)"
      ],
      "metadata": {
        "id": "CJT-yQtcm0OP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll6izlovm0OP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c19da8e6-0563-422c-e74a-50a2f55ad417"
      },
      "source": [
        "#difficuty macro\n",
        "print_metrics(flat_predictions,flat_true_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5161535345613788, 0.44006273510323307, 0.47508067653345765)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCtdzj5zm0OP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92136785-b0de-4c78-ba90-1bed80679eb6"
      },
      "source": [
        "#difficulty\n",
        "print_weighted_metrics(flat_predictions,flat_true_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5384631358864914, 0.5558225912169543, 0.5470051706796026)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test_features))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdzoZCHNgQa7",
        "outputId": "c79566a9-8b0d-49b6-b0db-88bb1f993d0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_bo,f1_mlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXu2Zh14bNtO",
        "outputId": "2bcbedb1-4fa3-4770-cd86-0f83ea154858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5579003427739674, 0.5423183782002412)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDxKTJqNSnFp"
      },
      "source": [
        "Now for macro f1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9YL5hHaSmd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fccee45d-c53b-40fd-b09c-185c7c3c069c"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "f1_multi_ensemble = []\n",
        "f1_int_ensemble =[]\n",
        "macro_f1_inti_ensemble = []\n",
        "macro_f1_multi_ensemble = []\n",
        "for indices in kf.split(test_features):\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  for sent in test_features[indices[0]]:\n",
        "\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 256,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  test_labels_tensor = torch.tensor(test_labels[indices[0]])\n",
        "  test_skill_labels_tensor = torch.tensor(test_skill_labels[indices[0]])\n",
        "\n",
        "  # test_text = torchtext.data.TabularDataset(examples=test.iloc[indices[1],:],\n",
        "  #                                    fields={'difficulty_label': ('label', target_diff),\n",
        "  #                                            'question_answer': ('text',text)})\n",
        "  # test_iter = torchtext.data.Iterator(dataset=test_text, batch_size=34,train=False, sort=False, sort_within_batch=False,shuffle=False)\n",
        "# Set the batch size.  /\n",
        "  # batch_size = 34  \n",
        "\n",
        "  prediction_data = TensorDataset(input_ids, attention_masks, test_labels_tensor,test_skill_labels_tensor)\n",
        "  # Create the DataLoader.\n",
        "  prediction_sampler = SequentialSampler(prediction_data)\n",
        "  prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=32)\n",
        "  f1_bo,macro_f1_bo = get_interactive_predictions(prediction_dataloader)\n",
        "  f1_mlp,macro_f1_mlp = get_multi_task_predictions(prediction_dataloader)\n",
        "  macro_f1_multi_ensemble.append(macro_f1_mlp)\n",
        "  macro_f1_inti_ensemble.append(macro_f1_bo)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31_jaZqASy6P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93b3e980-771b-42da-ceed-07b1edd5c2d5"
      },
      "source": [
        "print(macro_f1_multi_ensemble)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.4723323632017536, 0.47162524715025955, 0.47696706290500435, 0.4776026417020845, 0.48070496540321717]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoqkoAbaSy6Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca949762-8e35-4c16-ab10-158980bdf9f7"
      },
      "source": [
        "macro_f1_inti_ensemble"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4863973074087436,\n",
              " 0.4897739210478396,\n",
              " 0.491281270282824,\n",
              " 0.4872976829800696,\n",
              " 0.483150866886412]"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ManKEa4kSy6R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5827a5c1-5b97-45b9-a502-b9ad88462777"
      },
      "source": [
        "from scipy import stats\n",
        "stats.ttest_rel(macro_f1_inti_ensemble,macro_f1_multi_ensemble)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ttest_relResult(statistic=4.378008172058992, pvalue=0.011893396209914083)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPPkoifkKLxK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhb1vToRNmkx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bca5c177-e6c7-44f5-fa2a-82e8797d3c72"
      },
      "source": [
        "def accuracy_per_class(preds_flat, labels_flat):\n",
        "\n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {get_labels(label)}')\n",
        "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n",
        "accuracy_per_class(flat_predictions,flat_true_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class: Difficult\n",
            "Accuracy: 730/1646\n",
            "\n",
            "Class: Easy\n",
            "Accuracy: 1755/2207\n",
            "\n",
            "Class: Medium\n",
            "Accuracy: 59/724\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjdqIPm96UYJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Majority Voting"
      ],
      "metadata": {
        "id": "W10P9rK82085"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "    # Put model in evaluation mode\n",
        "    model.eval()\n",
        "    model_multi_task.eval()\n",
        "    model_cascade.eval()\n",
        "    model_interactive.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    predictions , true_labels,ids = [], [], []\n",
        "\n",
        "# 8 models in total\n",
        "    # Predict \n",
        "    for index,batch in enumerate(prediction_dataloader):\n",
        "      final_outputs = []\n",
        "      # Add batch to GPU\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      \n",
        "      # Unpack the inputs from our dataloader\n",
        "      b_input_ids, b_input_mask, b_labels, skill_labels = batch\n",
        "      # Telling the model not to compute or store gradients, saving memory and \n",
        "      # speeding up prediction\n",
        "      with torch.no_grad():\n",
        "          # Forward pass, calculate logit predictions\n",
        "            # print(\"multi\")\n",
        "\n",
        "          # multi task model\n",
        "          outputs,_ = model_multi_task(b_input_ids,b_input_mask)\n",
        "            # print(\"outputs\",outputs.shape,b_input_ids.shape,batch[0].shape,index)\n",
        "          final_outputs.append(outputs)\n",
        "            # print(\"cascade\")\n",
        "\n",
        "          # assuming skill is given interactive attention\n",
        "          output_skill_given = model_skill_given(b_input_ids,b_input_mask,skill_labels)\n",
        "          final_outputs.append(output_skill_given)\n",
        "\n",
        "          #bert cascade\n",
        "          output_cascade = model_cascade(b_input_ids,b_input_mask)\n",
        "          final_outputs.append(output_cascade)\n",
        "\n",
        "          # interactive bert with pretrained model for skilled prediction\n",
        "          outputs,_ = model_interactive_pre_trained(b_input_ids,b_input_mask)\n",
        "          final_outputs.append(outputs)\n",
        "\n",
        "            # print(\"normal\")\n",
        "          # output_difficulty = model(b_input_ids,b_input_mask)\n",
        "          # final_outputs.append(output_difficulty)\n",
        "\n",
        "          # interactive attention model (ours)\n",
        "          interactive_output,_ = model_interactive(b_input_ids,b_input_mask)\n",
        "          final_outputs.append(interactive_output)\n",
        "          params =dict()\n",
        "          params['lstm'] =1\n",
        "          params['gru'] = 1\n",
        "\n",
        "          # lstm plus GRU\n",
        "          out = make_lstm_and_gru_predictions(index,params)\n",
        "          final_outputs.append(out[0])\n",
        "          final_outputs.append(out[1])\n",
        "\n",
        "          # base difficulty bert model\n",
        "          output_difficulty = model(b_input_ids,b_input_mask)\n",
        "          final_outputs.append(output_difficulty)\n",
        "      # logits_2 = outputs\n",
        "      # logist_1 = output_bert[0]\n",
        "      predictions_1 = final_outputs\n",
        "      logits,_ = torch.max(torch.stack(predictions_1), dim=0)\n",
        "      # else:\n",
        "        # logits = predictions_1[0]\n",
        "      # Move logits and labels to CPU\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "      \n",
        "      # Store predictions and true labels\n",
        "      predictions.append(logits)\n",
        "      true_labels.append(label_ids)\n",
        "    flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "    flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "    # Combine the correct labels for each batch into a single list.\n",
        "    flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "    # metrics = precision_recall_fscore_support(flat_true_labels, flat_predictions, average='micro')\n",
        "    metrics = print_weighted_metrics(flat_predictions,flat_true_labels)\n",
        "    macro_metrics = print_metrics(flat_predictions,flat_true_labels)\n",
        "    print(\"macro_metrics\",macro_metrics)\n",
        "\n",
        "    print(\"weighted\",metrics)\n",
        "    print('    DONE.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHb5ELUF23GR",
        "outputId": "1207969c-f969-4561-f9bc-2ab80dd16a1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 4,577 test sentences...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning:\n",
            "\n",
            "The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "macro_metrics (0.5252243597242369, 0.4660716619455976, 0.49388312851016175)\n",
            "weighted (0.5499026145685715, 0.560847716845095, 0.5553212403284401)\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mean voting"
      ],
      "metadata": {
        "id": "6PgvQmCYEsoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "    # Put model in evaluation mode\n",
        "    model.eval()\n",
        "    model_multi_task.eval()\n",
        "    model_cascade.eval()\n",
        "    model_interactive.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    predictions , true_labels,ids = [], [], []\n",
        "\n",
        "\n",
        "    # Predict \n",
        "    for index,batch in enumerate(prediction_dataloader):\n",
        "      final_outputs = []\n",
        "      # Add batch to GPU\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      \n",
        "      # Unpack the inputs from our dataloader\n",
        "      b_input_ids, b_input_mask, b_labels, skill_labels = batch\n",
        "      # Telling the model not to compute or store gradients, saving memory and \n",
        "      # speeding up prediction\n",
        "      with torch.no_grad():\n",
        "          # Forward pass, calculate logit predictions\n",
        "            # print(\"multi\")\n",
        "          outputs,_ = model_multi_task(b_input_ids,b_input_mask)\n",
        "            # print(\"outputs\",outputs.shape,b_input_ids.shape,batch[0].shape,index)\n",
        "          final_outputs.append(outputs)\n",
        "            # print(\"cascade\")\n",
        "          output_skill_given = model_skill_given(b_input_ids,b_input_mask,skill_labels)\n",
        "          final_outputs.append(output_skill_given)\n",
        "          output_cascade = model_cascade(b_input_ids,b_input_mask)\n",
        "          final_outputs.append(output_cascade)\n",
        "          outputs,_ = model_interactive_pre_trained(b_input_ids,b_input_mask)\n",
        "          final_outputs.append(outputs)\n",
        "\n",
        "            # print(\"normal\")\n",
        "          # output_difficulty = model(b_input_ids,b_input_mask)\n",
        "          # final_outputs.append(output_difficulty)\n",
        "          interactive_output,_ = model_interactive(b_input_ids,b_input_mask)\n",
        "          final_outputs.append(interactive_output)\n",
        "          params =dict()\n",
        "          params['lstm'] =1\n",
        "          params['gru'] = 1\n",
        "          out = make_lstm_and_gru_predictions(index,params)\n",
        "          final_outputs.append(out[0])\n",
        "          final_outputs.append(out[1])\n",
        "          output_difficulty = model(b_input_ids,b_input_mask)\n",
        "          final_outputs.append(output_difficulty)\n",
        "      # logits_2 = outputs\n",
        "      # logist_1 = output_bert[0]\n",
        "      predictions_1 = final_outputs\n",
        "      logits = torch.mean(torch.stack(predictions_1), dim=0)\n",
        "      # else:\n",
        "        # logits = predictions_1[0]\n",
        "      # Move logits and labels to CPU\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "      \n",
        "      # Store predictions and true labels\n",
        "      predictions.append(logits)\n",
        "      true_labels.append(label_ids)\n",
        "    flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "    flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "    # Combine the correct labels for each batch into a single list.\n",
        "    flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "    # metrics = precision_recall_fscore_support(flat_true_labels, flat_predictions, average='micro')\n",
        "    metrics = print_weighted_metrics(flat_predictions,flat_true_labels)\n",
        "    macro_metrics = print_metrics(flat_predictions,flat_true_labels)\n",
        "    print(\"macro_metrics\",macro_metrics)\n",
        "\n",
        "    print(\"weighted\",metrics)\n",
        "    print('    DONE.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW217ax166ZA",
        "outputId": "0a307faf-53e2-4a9c-eaa2-8f5041ed8e14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 4,577 test sentences...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning:\n",
            "\n",
            "The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "macro_metrics (0.5471735665240417, 0.4572675311906578, 0.49819687081004643)\n",
            "weighted (0.5652408564340834, 0.5724273541621149, 0.5688114072262386)\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "r3y0fTWuErkO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}