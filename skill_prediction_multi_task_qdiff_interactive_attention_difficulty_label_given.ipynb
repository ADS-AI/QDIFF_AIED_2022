{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"skill_prediction_multi_task_qdiff_interactive_attention_difficulty_label_given.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ae74cd6e65ff460eb5e6738aad1dd4a7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a1d0679e813a451f9656aaa7dee722c3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_01cb33cb32b74a8abcbbd5bc7bef3d94","IPY_MODEL_3c365d4e85d04e309878fa0375e0f1ce","IPY_MODEL_4a0cf6f8baf648b6a562eac0f149e098"]}},"a1d0679e813a451f9656aaa7dee722c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"01cb33cb32b74a8abcbbd5bc7bef3d94":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7695ed12bc35447fb47121372b5615a6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fac051c9419c44aab8d00662bb599709"}},"3c365d4e85d04e309878fa0375e0f1ce":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c547944305ee435b807b1d0fe0efc88c","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f1cd4d2775404a3fb8c29e25239eed14"}},"4a0cf6f8baf648b6a562eac0f149e098":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_83bfcaae1b584349bcb029ed760c6f3a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 4.31MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1170b195c1e84593827d76999d64041d"}},"7695ed12bc35447fb47121372b5615a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fac051c9419c44aab8d00662bb599709":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c547944305ee435b807b1d0fe0efc88c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f1cd4d2775404a3fb8c29e25239eed14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"83bfcaae1b584349bcb029ed760c6f3a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1170b195c1e84593827d76999d64041d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sR9av2JU3kf6","outputId":"b756bdaa-b20b-494b-90a4-ab84a8a423a5","executionInfo":{"status":"ok","timestamp":1644079176086,"user_tz":-330,"elapsed":6108,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","import torch\n","import logging\n","logging.basicConfig(level=logging.ERROR)\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BzKeqoCs3kgA","outputId":"2021c0ce-7557-44ff-ad32-0013b1dca741","executionInfo":{"status":"ok","timestamp":1644079180651,"user_tz":-330,"elapsed":4586,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["!pip install transformers==3.2.0"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers==3.2.0\n","  Downloading transformers-3.2.0-py3-none-any.whl (1.0 MB)\n","\u001b[?25l\r\u001b[K     |▎                               | 10 kB 29.3 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 33.1 MB/s eta 0:00:01\r\u001b[K     |█                               | 30 kB 38.6 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40 kB 42.7 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51 kB 31.4 MB/s eta 0:00:01\r\u001b[K     |██                              | 61 kB 24.7 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81 kB 24.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 92 kB 26.6 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 133 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 143 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 153 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 163 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 174 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 184 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 194 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 204 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 215 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 225 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 235 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 245 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 256 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 266 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 276 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 286 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 296 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 307 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 317 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 327 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 337 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 348 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 358 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 368 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 378 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 389 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 399 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 409 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 419 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 430 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 440 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 450 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 460 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 471 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 481 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 491 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 501 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 512 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 522 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 532 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 542 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 552 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 563 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 573 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 583 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 593 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 604 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 614 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 624 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 634 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 645 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 655 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 665 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 675 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 686 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 696 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 706 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 716 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 727 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 737 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 747 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 757 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 768 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 778 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 788 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 798 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 808 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 819 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 829 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 839 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 849 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 860 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 870 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 880 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 890 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 901 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 911 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 921 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 931 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 942 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 952 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 962 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 972 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 983 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 993 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.0 MB 28.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0 MB 28.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (4.62.3)\n","Collecting tokenizers==0.8.1.rc2\n","  Downloading tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 52.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (1.19.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (2019.12.20)\n","Collecting sentencepiece!=0.1.92\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 54.0 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 69.1 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (3.4.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.2.0) (3.0.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2.0) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2.0) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.2.0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.2.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.2.0) (1.1.0)\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.47 sentencepiece-0.1.96 tokenizers-0.8.1rc2 transformers-3.2.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"GsADhaO93kgD","outputId":"add8dd53-64e8-47db-c9f5-94ba97d66df4","executionInfo":{"status":"ok","timestamp":1644079364760,"user_tz":-330,"elapsed":661,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["import pandas as pd\n","final_data = pd.read_csv(\"train_skill_name_difficulty.csv\")\n","final_data"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-9d30d853-2e45-4000-bcef-aa349ffc5f4c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>board_syllabus</th>\n","      <th>question_answer</th>\n","      <th>skill_label</th>\n","      <th>difficulty_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Raj English&gt;&gt;XII&gt;&gt;Biology&gt;&gt;Domestication, Cult...</td>\n","      <td>Among the following, freshwater fish is rohu ...</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Maharashtra New&gt;&gt;VI&gt;&gt;General Science&gt;&gt;Sound&gt;&gt;P...</td>\n","      <td>Which of the following statement is true? Sou...</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ICSE OLD&gt;&gt;XI&gt;&gt;Computer Science&gt;&gt;Functions&gt;&gt;Con...</td>\n","      <td>The process of using multiple constructors wi...</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>CBSE&gt;&gt;VI&gt;&gt;Science&gt;&gt;Separation of Substances&gt;&gt;S...</td>\n","      <td>Sieving is based on the difference in the siz...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>AP&gt;&gt;X&gt;&gt;Biology&gt;&gt;Excretion - The Wastage Dispos...</td>\n","      <td>The removal of toxic and unwanted waste subst...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>39124</th>\n","      <td>CAPS(South Africa)&gt;&gt;Grade 7&gt;&gt;Natural Sciences&gt;...</td>\n","      <td>How heat loss problems are prevented by birds...</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>39125</th>\n","      <td>CBSE&gt;&gt;X&gt;&gt;Science&gt;&gt;Metals and Non-Metal</td>\n","      <td>Give reasons why copper is used to make hot w...</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>39126</th>\n","      <td>CBSE&gt;&gt;VII&gt;&gt;Science&gt;&gt;Motion and Time</td>\n","      <td>The horizontal line in the graph is denoted as...</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>39127</th>\n","      <td>Tamil Nadu&gt;&gt;VI&gt;&gt;Science&gt;&gt;Term 1&gt;&gt;Physics&gt;&gt;Forc...</td>\n","      <td>SI unit of force is newton The SI unit of for...</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>39128</th>\n","      <td>Tamil Nadu&gt;&gt;VIII&gt;&gt;Science&gt;&gt;Term 1&gt;&gt;Physics&gt;&gt;Fo...</td>\n","      <td>In machines sliding frictions is replaced to ...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>39129 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d30d853-2e45-4000-bcef-aa349ffc5f4c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9d30d853-2e45-4000-bcef-aa349ffc5f4c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9d30d853-2e45-4000-bcef-aa349ffc5f4c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                          board_syllabus  ... difficulty_label\n","0      Raj English>>XII>>Biology>>Domestication, Cult...  ...                0\n","1      Maharashtra New>>VI>>General Science>>Sound>>P...  ...                2\n","2      ICSE OLD>>XI>>Computer Science>>Functions>>Con...  ...                0\n","3      CBSE>>VI>>Science>>Separation of Substances>>S...  ...                1\n","4      AP>>X>>Biology>>Excretion - The Wastage Dispos...  ...                1\n","...                                                  ...  ...              ...\n","39124  CAPS(South Africa)>>Grade 7>>Natural Sciences>...  ...                1\n","39125             CBSE>>X>>Science>>Metals and Non-Metal  ...                2\n","39126                CBSE>>VII>>Science>>Motion and Time  ...                1\n","39127  Tamil Nadu>>VI>>Science>>Term 1>>Physics>>Forc...  ...                2\n","39128  Tamil Nadu>>VIII>>Science>>Term 1>>Physics>>Fo...  ...                1\n","\n","[39129 rows x 4 columns]"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A0Ja4jiFhmdg","outputId":"4f9028ec-be1f-43d4-c775-e10cdbb8c20a","executionInfo":{"status":"ok","timestamp":1644079366545,"user_tz":-330,"elapsed":4,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["final_data[\"question_answer\"].values"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([' Among the following, freshwater fish is rohu Rohu is a fresh water fish. Other common freshwater fish are catla, common carp.',\n","       ' Which of the following statement is true? Sound requires a medium for propagation. Sound travels through a medium (solid, liquid or gas). It cannot travel through vacuum.',\n","       ' The process of using multiple constructors with the same name but with different parameters is known as: Constructor overloading Constructor overloading is a technique in Java in which a class can have any number of constructors that differ in parameter lists.',\n","       ...,\n","       'The horizontal line in the graph is denoted as the X-axis. The horizontal line points in the horizontal direction and is denoted as the X-axis in the graph.',\n","       ' SI unit of force is newton The SI unit of force is Newton (N), named after famous scientist Isaac Newton who discovered force of gravitation.',\n","       ' In machines sliding frictions is replaced to rolling by use of ball bearings Ball bearing roll to produce rolling;friction.'],\n","      dtype=object)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iQhO6qqt6lge","outputId":"d6055ad8-ce9b-4a3e-cbb8-78ddada94701","executionInfo":{"status":"ok","timestamp":1644079367191,"user_tz":-330,"elapsed":2,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["final_data['difficulty_label'].value_counts()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    19312\n","0    14146\n","2     5671\n","Name: difficulty_label, dtype: int64"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"2EkZ-3TZ5UBJ","executionInfo":{"status":"ok","timestamp":1644079367710,"user_tz":-330,"elapsed":3,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["def clean_sentence(question):\n","  # print(question)\n","  question = re.sub('<[^>]*>', ' ',question)\n","  question = re.sub(' +', ' ', question)\n","  question = re.sub('\\xa0','',question)\n","  question = question.rstrip()\n","  question = re.sub('nan','',question)\n","  question = re.sub(u'\\u2004','',question)\n","  question = re.sub(u'\\u2009','',question)\n","\n","  # question = question.decode(\"utf-8\")\n","  # question = question.replace(u'\\u200\\d*','').encode(\"utf-8\")\n","  question = re.sub('&nbsp','',question)\n","  question = re.sub('&ndash','',question)\n","  question = re.sub('\\r','',question)\n","  question = re.sub('\\t','',question)\n","  question = re.sub('\\n',' ',question)\n","\n","  question = re.sub('MathType@.*','',question)\n","  question = re.sub('&thinsp','',question)\n","  question = re.sub('&times','',question)\n","  question = re.sub('\\u200b','',question)\n","  question = re.sub('&rarr;;;','',question)\n","\n","  return question"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IMCV9mxDnaK0","outputId":"2a311e02-abdd-470c-9ede-ed76ee273def","executionInfo":{"status":"ok","timestamp":1644079387884,"user_tz":-330,"elapsed":20177,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"9exlBELH5oq9","executionInfo":{"status":"ok","timestamp":1644079391952,"user_tz":-330,"elapsed":4071,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["!cp \"/content/drive/My Drive/research_skill_name_prediction/label_encoder_difficulty_Lstm\"  /content"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"pUqcGtXwBIyl","executionInfo":{"status":"ok","timestamp":1644079393856,"user_tz":-330,"elapsed":626,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["!cp \"/content/drive/MyDrive/research_skill_name_prediction/label_encoder_skill_lstm\" /content"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rj-ow-6cqFyn","executionInfo":{"status":"ok","timestamp":1644079400733,"user_tz":-330,"elapsed":6880,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["!cp -r \"/content/drive/MyDrive/research_skill_name_prediction/model_bert_multi_task_interactive\" /content"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JYbSa7ZKAkfz","outputId":"b6aa878f-1313-4cee-9fa7-ab8033ea0f9b","executionInfo":{"status":"ok","timestamp":1644079400733,"user_tz":-330,"elapsed":9,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["import joblib\n","LE_skill = joblib.load('label_encoder_skill_lstm')\n","LE_skill.classes_"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n","  UserWarning,\n"]},{"output_type":"execute_result","data":{"text/plain":["array(['Analysing', 'Applying', 'Knowledge & understanding',\n","       'Remembering', 'Understanding'], dtype=object)"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"-OBarOLBz2nO","executionInfo":{"status":"ok","timestamp":1644079400733,"user_tz":-330,"elapsed":7,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["def get_labels(prediction):\n","    predicted_label =  LE.inverse_transform([prediction])\n","    return predicted_label[0]"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"XqWem79lbn1J","outputId":"7404f31b-a73d-4bf6-feb9-fccd81dd606e","executionInfo":{"status":"ok","timestamp":1644079401395,"user_tz":-330,"elapsed":668,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["final_data['skill_label'].value_counts().sort_values(ascending=False).plot(kind='bar')"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7fdb712cff10>"]},"metadata":{},"execution_count":14},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"RxliBQEJ9eTG","executionInfo":{"status":"ok","timestamp":1644079401396,"user_tz":-330,"elapsed":18,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["val = pd.read_csv(\"val_skill_name_difficulty.csv\")"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"07eBaI9wA2hL","outputId":"b7b2b6a6-460a-45da-93b6-31e457de669e","executionInfo":{"status":"ok","timestamp":1644079401396,"user_tz":-330,"elapsed":18,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["val"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-2aa6667a-1dfb-476f-a082-a2b2b8487a70\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>board_syllabus</th>\n","      <th>question_answer</th>\n","      <th>skill_label</th>\n","      <th>difficulty_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AP&gt;&gt;VII&gt;&gt;Science&gt;&gt;Animal Fibre&gt;&gt;Silk</td>\n","      <td>Name the two types of protein from which silk...</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Maharashtra New&gt;&gt;VIII&gt;&gt;General Science&gt;&gt;Man Ma...</td>\n","      <td>Give reasons: (i) Thermocol is used for the p...</td>\n","      <td>4</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>CBSE&gt;&gt;VI&gt;&gt;Science&gt;&gt;Fun with Magnets&gt;&gt;Demagneti...</td>\n","      <td>Identify the odd option. Rubbing a magnetic m...</td>\n","      <td>4</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Tamil Nadu&gt;&gt;VIII&gt;&gt;Science&gt;&gt;Term 1&gt;&gt;Physics&gt;&gt;Li...</td>\n","      <td>Find the speed of light in glass of refractiv...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Raj English&gt;&gt;XII&gt;&gt;Biology&gt;&gt;Integumentary Syste...</td>\n","      <td>Which of the following function is associated...</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2055</th>\n","      <td>CBSE&gt;&gt;XI&gt;&gt;Chemistry&gt;&gt;Chemistry : Part I&gt;&gt;Equil...</td>\n","      <td>The solubility of A 2 X 3 is y mol.dm -3 . So...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2056</th>\n","      <td>CBSE&gt;&gt;VI&gt;&gt;Computer Science&gt;&gt;Using Mail Merge&gt;&gt;...</td>\n","      <td>To create an invitation letter, click on Mail...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2057</th>\n","      <td>CBSE&gt;&gt;XII&gt;&gt;Physics&gt;&gt;Physics : Part - II&gt;&gt;Ray O...</td>\n","      <td>Choose the correct option about the intensity...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2058</th>\n","      <td>ICSE OLD&gt;&gt;VII&gt;&gt;Biology&gt;&gt;Organ System of Human ...</td>\n","      <td>Which of the following instrument is used to ...</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2059</th>\n","      <td>CBSE&gt;&gt;X&gt;&gt;Science&gt;&gt;Carbon and its Compounds&gt;&gt;Al...</td>\n","      <td>Identify the correct statement about allotrop...</td>\n","      <td>4</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2060 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2aa6667a-1dfb-476f-a082-a2b2b8487a70')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2aa6667a-1dfb-476f-a082-a2b2b8487a70 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2aa6667a-1dfb-476f-a082-a2b2b8487a70');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                         board_syllabus  ... difficulty_label\n","0                  AP>>VII>>Science>>Animal Fibre>>Silk  ...                0\n","1     Maharashtra New>>VIII>>General Science>>Man Ma...  ...                2\n","2     CBSE>>VI>>Science>>Fun with Magnets>>Demagneti...  ...                2\n","3     Tamil Nadu>>VIII>>Science>>Term 1>>Physics>>Li...  ...                0\n","4     Raj English>>XII>>Biology>>Integumentary Syste...  ...                0\n","...                                                 ...  ...              ...\n","2055  CBSE>>XI>>Chemistry>>Chemistry : Part I>>Equil...  ...                0\n","2056  CBSE>>VI>>Computer Science>>Using Mail Merge>>...  ...                1\n","2057  CBSE>>XII>>Physics>>Physics : Part - II>>Ray O...  ...                0\n","2058  ICSE OLD>>VII>>Biology>>Organ System of Human ...  ...                1\n","2059  CBSE>>X>>Science>>Carbon and its Compounds>>Al...  ...                0\n","\n","[2060 rows x 4 columns]"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"g8tVsjiWj-cF","outputId":"f91937cc-8756-443c-d641-e4c2a65e9e54","executionInfo":{"status":"ok","timestamp":1644079401396,"user_tz":-330,"elapsed":16,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["test = pd.read_csv(\"test_skill_name_difficulty.csv\")\n","test"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-f4768c80-d3ea-43bc-bd12-6540ba161538\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>board_syllabus</th>\n","      <th>question_answer</th>\n","      <th>skill_label</th>\n","      <th>difficulty_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>CBSE&gt;&gt;Nursery&gt;&gt;Environmental Science&gt;&gt;Common V...</td>\n","      <td>Write down the names of some common vegetable...</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>CBSE&gt;&gt;XII&gt;&gt;Physics&gt;&gt;Physics : Part - II&gt;&gt;Atoms</td>\n","      <td>Name the series of hydrogen atom which lies i...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ICSE OLD&gt;&gt;XI&gt;&gt;Political Science&gt;&gt;State, Govern...</td>\n","      <td>Which of the following is not the element of ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Maharashtra New&gt;&gt;VII&gt;&gt;General Science&gt;&gt;Static ...</td>\n","      <td>The process of electrically charging an objec...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Tamil Nadu&gt;&gt;IX&gt;&gt;Science&gt;&gt;Physics&gt;&gt;Measurement&gt;...</td>\n","      <td>The mass of an object is measured in kilogram...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4572</th>\n","      <td>ICSE OLD&gt;&gt;VIII&gt;&gt;Biology&gt;&gt;Nervous System And Se...</td>\n","      <td>Which of the following is the first cranial n...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4573</th>\n","      <td>CBSE&gt;&gt;VII&gt;&gt;Computer Science&gt;&gt;Advance features ...</td>\n","      <td>To ungroup the worksheets: Right-click on any...</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4574</th>\n","      <td>CBSE&gt;&gt;VIII&gt;&gt;Science&gt;&gt;Chemical Effects of Elect...</td>\n","      <td>After passing electricity through a solution ...</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4575</th>\n","      <td>CLSP&gt;&gt;Stage 9&gt;&gt;Science&gt;&gt;Chemistry&gt;&gt;Material pr...</td>\n","      <td>Identify the scientists who gave the “plum-pu...</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4576</th>\n","      <td>AP&gt;&gt;VIII&gt;&gt;Physical Science&gt;&gt;Physical Science (...</td>\n","      <td>What do you understand by the term static ele...</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4577 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4768c80-d3ea-43bc-bd12-6540ba161538')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f4768c80-d3ea-43bc-bd12-6540ba161538 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f4768c80-d3ea-43bc-bd12-6540ba161538');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                         board_syllabus  ... difficulty_label\n","0     CBSE>>Nursery>>Environmental Science>>Common V...  ...                2\n","1        CBSE>>XII>>Physics>>Physics : Part - II>>Atoms  ...                1\n","2     ICSE OLD>>XI>>Political Science>>State, Govern...  ...                0\n","3     Maharashtra New>>VII>>General Science>>Static ...  ...                1\n","4     Tamil Nadu>>IX>>Science>>Physics>>Measurement>...  ...                1\n","...                                                 ...  ...              ...\n","4572  ICSE OLD>>VIII>>Biology>>Nervous System And Se...  ...                1\n","4573  CBSE>>VII>>Computer Science>>Advance features ...  ...                0\n","4574  CBSE>>VIII>>Science>>Chemical Effects of Elect...  ...                2\n","4575  CLSP>>Stage 9>>Science>>Chemistry>>Material pr...  ...                0\n","4576  AP>>VIII>>Physical Science>>Physical Science (...  ...                1\n","\n","[4577 rows x 4 columns]"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bovSLwB26TRn","outputId":"e7527aed-a0d0-4f11-f8b7-af977b65d985","executionInfo":{"status":"ok","timestamp":1644079401397,"user_tz":-330,"elapsed":17,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["test[\"question_answer\"].values"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([' Write down the names of some common vegetables. Answer may vary Probable answer – Names of some common vegetables are potato, onion, tomato and carrot. ',\n","       ' Name the series of hydrogen atom which lies in the U.V region. Lyman series lies in the U.V region. ',\n","       ' Which of the following is not the element of an association? Relationships are abstract Each association has elements 1) a group of people, 2) voluntary Membership, 3) shared and common interests or needs as the basis, 4) some set of objective goals which are to be achieved collectively by all the members, 5) a voluntary organisation, and 6) co-operation among the members objectives pooled resources for funds needed for action.',\n","       ...,\n","       ' After passing electricity through a solution the change that takes place is a chemical change Physical changes are those changes that do not result in the production of a new substance whereas a chemical change involves the production of a new substance. For example: When electricity is passed in a solution containing water, bubbles of hydrogen and oxygen are formed.',\n","       ' Identify the scientists who gave the “plum-pudding” model of the atom. J. J. Thomson The &ldquo;plum-pudding&rdquo; model of the atom was developed by the J. J Thomson. He compared his model used for describing the structure of atom with a plum pudding in which negatively charged electrons were surrounded by a positively charged &lsquo;pudding&rsquo;.',\n","       ' What do you understand by the term static electricity? It is the electricity developed due to stationary electric charges on the body. '],\n","      dtype=object)"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"P8xfcPLU5sR5","outputId":"a91f229d-d936-4b7e-f753-6ecbe841900d","executionInfo":{"status":"ok","timestamp":1644079401397,"user_tz":-330,"elapsed":13,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["\n","import re\n","\n","test[\"question_answer\"] = test[\"question_answer\"].apply(lambda x : clean_sentence(x))\n","test"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-4fb06269-07d4-49c5-a641-a9eb33b2b77b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>board_syllabus</th>\n","      <th>question_answer</th>\n","      <th>skill_label</th>\n","      <th>difficulty_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>CBSE&gt;&gt;Nursery&gt;&gt;Environmental Science&gt;&gt;Common V...</td>\n","      <td>Write down the names of some common vegetable...</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>CBSE&gt;&gt;XII&gt;&gt;Physics&gt;&gt;Physics : Part - II&gt;&gt;Atoms</td>\n","      <td>Name the series of hydrogen atom which lies i...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ICSE OLD&gt;&gt;XI&gt;&gt;Political Science&gt;&gt;State, Govern...</td>\n","      <td>Which of the following is not the element of ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Maharashtra New&gt;&gt;VII&gt;&gt;General Science&gt;&gt;Static ...</td>\n","      <td>The process of electrically charging an objec...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Tamil Nadu&gt;&gt;IX&gt;&gt;Science&gt;&gt;Physics&gt;&gt;Measurement&gt;...</td>\n","      <td>The mass of an object is measured in kilogram...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4572</th>\n","      <td>ICSE OLD&gt;&gt;VIII&gt;&gt;Biology&gt;&gt;Nervous System And Se...</td>\n","      <td>Which of the following is the first cranial n...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4573</th>\n","      <td>CBSE&gt;&gt;VII&gt;&gt;Computer Science&gt;&gt;Advance features ...</td>\n","      <td>To ungroup the worksheets: Right-click on any...</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4574</th>\n","      <td>CBSE&gt;&gt;VIII&gt;&gt;Science&gt;&gt;Chemical Effects of Elect...</td>\n","      <td>After passing electricity through a solution ...</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4575</th>\n","      <td>CLSP&gt;&gt;Stage 9&gt;&gt;Science&gt;&gt;Chemistry&gt;&gt;Material pr...</td>\n","      <td>Identify the scientists who gave the “plum-pu...</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4576</th>\n","      <td>AP&gt;&gt;VIII&gt;&gt;Physical Science&gt;&gt;Physical Science (...</td>\n","      <td>What do you understand by the term static ele...</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4577 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4fb06269-07d4-49c5-a641-a9eb33b2b77b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4fb06269-07d4-49c5-a641-a9eb33b2b77b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4fb06269-07d4-49c5-a641-a9eb33b2b77b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                         board_syllabus  ... difficulty_label\n","0     CBSE>>Nursery>>Environmental Science>>Common V...  ...                2\n","1        CBSE>>XII>>Physics>>Physics : Part - II>>Atoms  ...                1\n","2     ICSE OLD>>XI>>Political Science>>State, Govern...  ...                0\n","3     Maharashtra New>>VII>>General Science>>Static ...  ...                1\n","4     Tamil Nadu>>IX>>Science>>Physics>>Measurement>...  ...                1\n","...                                                 ...  ...              ...\n","4572  ICSE OLD>>VIII>>Biology>>Nervous System And Se...  ...                1\n","4573  CBSE>>VII>>Computer Science>>Advance features ...  ...                0\n","4574  CBSE>>VIII>>Science>>Chemical Effects of Elect...  ...                2\n","4575  CLSP>>Stage 9>>Science>>Chemistry>>Material pr...  ...                0\n","4576  AP>>VIII>>Physical Science>>Physical Science (...  ...                1\n","\n","[4577 rows x 4 columns]"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sQ_zCeR06Z4P","outputId":"654302c5-5672-457f-9ad9-80baa6285ae6","executionInfo":{"status":"ok","timestamp":1644079401398,"user_tz":-330,"elapsed":13,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["test[\"question_answer\"].values"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([' Write down the names of some common vegetables. Answer may vary Probable answer – Names of some common vegetables are potato, onion, tomato and carrot.',\n","       ' Name the series of hydrogen atom which lies in the U.V region. Lyman series lies in the U.V region.',\n","       ' Which of the following is not the element of an association? Relationships are abstract Each association has elements 1) a group of people, 2) voluntary Membership, 3) shared and common interests or needs as the basis, 4) some set of objective goals which are to be achieved collectively by all the members, 5) a voluntary organisation, and 6) co-operation among the members objectives pooled resources for funds needed for action.',\n","       ...,\n","       ' After passing electricity through a solution the change that takes place is a chemical change Physical changes are those changes that do not result in the production of a new substance whereas a chemical change involves the production of a new substance. For example: When electricity is passed in a solution containing water, bubbles of hydrogen and oxygen are formed.',\n","       ' Identify the scientists who gave the “plum-pudding” model of the atom. J. J. Thomson The &ldquo;plum-pudding&rdquo; model of the atom was developed by the J. J Thomson. He compared his model used for describing the structure of atom with a plum pudding in which negatively charged electrons were surrounded by a positively charged &lsquo;pudding&rsquo;.',\n","       ' What do you understand by the term static electricity? It is the electricity developed due to stationary electric charges on the body.'],\n","      dtype=object)"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["ae74cd6e65ff460eb5e6738aad1dd4a7","a1d0679e813a451f9656aaa7dee722c3","01cb33cb32b74a8abcbbd5bc7bef3d94","3c365d4e85d04e309878fa0375e0f1ce","4a0cf6f8baf648b6a562eac0f149e098","7695ed12bc35447fb47121372b5615a6","fac051c9419c44aab8d00662bb599709","c547944305ee435b807b1d0fe0efc88c","f1cd4d2775404a3fb8c29e25239eed14","83bfcaae1b584349bcb029ed760c6f3a","1170b195c1e84593827d76999d64041d"]},"id":"FIrS5sxE3kgk","outputId":"7b448d46-bd0e-4da8-bdc2-12ff405612d7","executionInfo":{"status":"ok","timestamp":1644079403923,"user_tz":-330,"elapsed":2535,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["from transformers import BertTokenizer\n","\n","# Load the BERT tokenizer.\n","print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading BERT tokenizer...\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae74cd6e65ff460eb5e6738aad1dd4a7","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"wp64MkNB3kg1","executionInfo":{"status":"ok","timestamp":1644079403924,"user_tz":-330,"elapsed":17,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["def get_labels(prediction):\n","    predicted_label =  LE_skill.inverse_transform([prediction])\n","    return predicted_label[0]"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":107},"id":"uPgTmJPS3kg4","outputId":"042cc4f3-f4f5-4280-c901-f644b2617e99","executionInfo":{"status":"ok","timestamp":1644079403924,"user_tz":-330,"elapsed":17,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["import joblib\n","from sklearn.preprocessing import LabelEncoder\n","\n","LE = LabelEncoder()\n","LE = joblib.load('label_encoder_difficulty_Lstm')\n","\n","get_labels(0)"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n","  UserWarning,\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Analysing'"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"I_UpqLMG3kg9","outputId":"67c22789-794e-46ee-eba6-b274481e9492","executionInfo":{"status":"ok","timestamp":1644079403924,"user_tz":-330,"elapsed":14,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["final_data"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-0a38fc37-73a9-48a5-9214-e62ef7725c11\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>board_syllabus</th>\n","      <th>question_answer</th>\n","      <th>skill_label</th>\n","      <th>difficulty_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Raj English&gt;&gt;XII&gt;&gt;Biology&gt;&gt;Domestication, Cult...</td>\n","      <td>Among the following, freshwater fish is rohu ...</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Maharashtra New&gt;&gt;VI&gt;&gt;General Science&gt;&gt;Sound&gt;&gt;P...</td>\n","      <td>Which of the following statement is true? Sou...</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ICSE OLD&gt;&gt;XI&gt;&gt;Computer Science&gt;&gt;Functions&gt;&gt;Con...</td>\n","      <td>The process of using multiple constructors wi...</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>CBSE&gt;&gt;VI&gt;&gt;Science&gt;&gt;Separation of Substances&gt;&gt;S...</td>\n","      <td>Sieving is based on the difference in the siz...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>AP&gt;&gt;X&gt;&gt;Biology&gt;&gt;Excretion - The Wastage Dispos...</td>\n","      <td>The removal of toxic and unwanted waste subst...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>39124</th>\n","      <td>CAPS(South Africa)&gt;&gt;Grade 7&gt;&gt;Natural Sciences&gt;...</td>\n","      <td>How heat loss problems are prevented by birds...</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>39125</th>\n","      <td>CBSE&gt;&gt;X&gt;&gt;Science&gt;&gt;Metals and Non-Metal</td>\n","      <td>Give reasons why copper is used to make hot w...</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>39126</th>\n","      <td>CBSE&gt;&gt;VII&gt;&gt;Science&gt;&gt;Motion and Time</td>\n","      <td>The horizontal line in the graph is denoted as...</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>39127</th>\n","      <td>Tamil Nadu&gt;&gt;VI&gt;&gt;Science&gt;&gt;Term 1&gt;&gt;Physics&gt;&gt;Forc...</td>\n","      <td>SI unit of force is newton The SI unit of for...</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>39128</th>\n","      <td>Tamil Nadu&gt;&gt;VIII&gt;&gt;Science&gt;&gt;Term 1&gt;&gt;Physics&gt;&gt;Fo...</td>\n","      <td>In machines sliding frictions is replaced to ...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>39129 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a38fc37-73a9-48a5-9214-e62ef7725c11')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0a38fc37-73a9-48a5-9214-e62ef7725c11 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0a38fc37-73a9-48a5-9214-e62ef7725c11');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                          board_syllabus  ... difficulty_label\n","0      Raj English>>XII>>Biology>>Domestication, Cult...  ...                0\n","1      Maharashtra New>>VI>>General Science>>Sound>>P...  ...                2\n","2      ICSE OLD>>XI>>Computer Science>>Functions>>Con...  ...                0\n","3      CBSE>>VI>>Science>>Separation of Substances>>S...  ...                1\n","4      AP>>X>>Biology>>Excretion - The Wastage Dispos...  ...                1\n","...                                                  ...  ...              ...\n","39124  CAPS(South Africa)>>Grade 7>>Natural Sciences>...  ...                1\n","39125             CBSE>>X>>Science>>Metals and Non-Metal  ...                2\n","39126                CBSE>>VII>>Science>>Motion and Time  ...                1\n","39127  Tamil Nadu>>VI>>Science>>Term 1>>Physics>>Forc...  ...                2\n","39128  Tamil Nadu>>VIII>>Science>>Term 1>>Physics>>Fo...  ...                1\n","\n","[39129 rows x 4 columns]"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"MHdVe13Fr3vt","executionInfo":{"status":"ok","timestamp":1644079403925,"user_tz":-330,"elapsed":14,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["new_data = final_data"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"AkyM7gqv3khI","executionInfo":{"status":"ok","timestamp":1644079403925,"user_tz":-330,"elapsed":13,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["question_answer = new_data[\"question_answer\"].values\n","categories = new_data[\"difficulty_label\"].values\n","skill_category = new_data[\"skill_label\"].values"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ndpw0p1SBUoZ","outputId":"57fdb788-1380-4e7d-9f58-88f02bb7c05c","executionInfo":{"status":"ok","timestamp":1644079403926,"user_tz":-330,"elapsed":14,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["question_answer"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([' Among the following, freshwater fish is rohu Rohu is a fresh water fish. Other common freshwater fish are catla, common carp.',\n","       ' Which of the following statement is true? Sound requires a medium for propagation. Sound travels through a medium (solid, liquid or gas). It cannot travel through vacuum.',\n","       ' The process of using multiple constructors with the same name but with different parameters is known as: Constructor overloading Constructor overloading is a technique in Java in which a class can have any number of constructors that differ in parameter lists.',\n","       ...,\n","       'The horizontal line in the graph is denoted as the X-axis. The horizontal line points in the horizontal direction and is denoted as the X-axis in the graph.',\n","       ' SI unit of force is newton The SI unit of force is Newton (N), named after famous scientist Isaac Newton who discovered force of gravitation.',\n","       ' In machines sliding frictions is replaced to rolling by use of ball bearings Ball bearing roll to produce rolling;friction.'],\n","      dtype=object)"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"tFkS_H_83khL","outputId":"2a68a47f-0519-4306-8316-71cda694fef6","executionInfo":{"status":"ok","timestamp":1644079403926,"user_tz":-330,"elapsed":12,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["question_answer[0]"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["' Among the following, freshwater fish is rohu Rohu is a fresh water fish. Other common freshwater fish are catla, common carp.'"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ian7gSDE3khR","outputId":"58fc3e4f-3c18-4b63-f61f-4e5a2bc65ea3","executionInfo":{"status":"ok","timestamp":1644079403926,"user_tz":-330,"elapsed":12,"user":{"displayName":"anonymous anonymous","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06251276198200574004"}}},"source":["len(categories)"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["39129"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y_ZeuHc63khU","outputId":"f038aa99-28a2-461e-c841-0b2db8801241"},"source":["input_ids = []\n","attention_masks = []\n","\n","for sent in question_answer:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 128,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        truncation=True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', question_answer[0])\n","print('Token IDs:', input_ids[0])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"code","metadata":{"id":"iVGvVZb13kha"},"source":["print('Original: ', len(question_answer[1]))\n","print('Token IDs:', len(input_ids[1]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5nmRiaBbA9OH"},"source":["val_text = val[\"question_answer\"].values\n","val_labels = val[\"difficulty_label\"].values\n","val_skill_labels = val[\"skill_label\"].values\n","test_text = test[\"question_answer\"].values\n","test_labels = test[\"difficulty_label\"].values\n","test_skill_labels = test[\"skill_label\"].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E-s_H1WdyvCw"},"source":["test_labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YF-mKCC1CUjD"},"source":["val_labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sOQuDahhAzOO"},"source":["val_input_ids = []\n","val_attention_masks = []\n","\n","for sent in val_text:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 128,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        truncation=True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    val_input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    val_attention_masks.append(encoded_dict['attention_mask'])\n","# Convert the lists into tensors.\n","val_input_ids = torch.cat(val_input_ids, dim=0)\n","val_attention_masks = torch.cat(val_attention_masks, dim=0)\n","\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', val_text[0])\n","print('Token IDs:', val_attention_masks[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Siskea7qDLUG"},"source":["print('Original: ', val_text[1])\n","print('Token IDs:', val_input_ids[1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"irMTimjf3khd"},"source":["labels = torch.tensor(categories)\n","skill_category = torch.tensor(skill_category)\n","val_labels = torch.tensor(val_labels)\n","val_skill_labels = torch.tensor(val_skill_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PdOgWP_LKTHi"},"source":["val_labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OJJ0I8Ud3khf"},"source":["get_labels(1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z1ZAbQRfiG63"},"source":["len(set(final_data[\"question_answer\"].values).intersection(val[\"question_answer\"].values))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BNDW74Ny3khj"},"source":["num_classes = len(list(set(new_data[\"skill_label\"].values)))\n","list(set(new_data[\"skill_label\"].values))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jOBErYPYEUrl"},"source":["skill_label_count = len(list(set(new_data[\"skill_label\"].values)))\n","skill_label_count"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jYFIJaRPE20c"},"source":["list(set(new_data[\"skill_label\"].values))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZmaLk5Ab3khl"},"source":["from torch.utils.data import TensorDataset, random_split\n","# train_poincare_tensor = torch.tensor(poincare_embeddings_final,dtype=torch.float)\n","# difficulty_tensor = torch.tensor(difficulty_level_vectors,dtype=torch.float)\n","# Combine the training inputs into a TensorDataset.\n","dataset = TensorDataset(input_ids, attention_masks, labels,skill_category)\n","val_dataset = TensorDataset(val_input_ids, val_attention_masks,val_labels,val_skill_labels) \n","# Create a 90-10train-validation split.\n","\n","# Calculate the number of samples to include in each set.\n","# train_size = int(0.90 * len(dataset))\n","# val_size = len(dataset) - train_size\n","\n","# # Divide the dataset by randomly selecting samples.\n","# train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","# print('{:>5,} training samples'.format(train_size))\n","# # print('{:>5,} validation samples'.format(val_size))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D_lTinod3kho"},"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","batch_size = 32\n","train_dataloader = DataLoader(\n","            dataset,  # The training samples.\n","            sampler = RandomSampler(dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), \n","            batch_size = batch_size \n","        )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_2tmAMlw3khr"},"source":["from transformers import BertModel, AdamW, BertConfig\n","\n","# # Loads BertForSequenceClassification, the pretrained BERT model with a single \n","# model = BertModel.from_pretrained(\n","#     \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n","# )\n","\n","# # Tell pytorch to run this model on the GPU.\n","# model.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DkDmTZhVChN6"},"source":["set(test[\"question_answer\"].values).intersection(set(final_data[\"question_answer\"].values))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-AX-SagSE8CS"},"source":["num_classes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aHmQK0OP9mv-"},"source":["from torch import nn\n","# for plottign attentions\n","class MultiClassClassifier(nn.Module):\n","    def __init__(self, bert_model_path, labels_count,skill_label_count, hidden_dim=768, mlp_dim=500, extras_dim=140, dropout=0.1, freeze_bert=False):\n","        super().__init__()\n","\n","        self.bert = BertModel.from_pretrained(bert_model_path,output_hidden_states=True,output_attentions=True)\n","        self.dropout = nn.Dropout(dropout)\n","        self.mlp = nn.Sequential(\n","            nn.Linear(hidden_dim , mlp_dim),\n","            nn.ReLU(),\n","            # nn.Linear(mlp_dim, mlp_dim),\n","            # nn.ReLU(),\n","            # nn.Linear(mlp_dim, mlp_dim),\n","            # nn.ReLU(),            \n","            nn.Linear(mlp_dim, labels_count)\n","        )\n","        self.mlp2 = nn.Sequential(\n","            nn.Linear(hidden_dim , mlp_dim),\n","            nn.ReLU(),         \n","            nn.Linear(mlp_dim, skill_label_count)\n","        )\n","        # self.softmax = nn.LogSoftmax(dim=1)\n","        if freeze_bert:\n","            print(\"Freezing layers\")\n","            for param in self.bert.parameters():\n","                param.requires_grad = False\n","\n","    def forward(self, tokens, masks):\n","        _, pooled_output,hidden_states,attentions = self.bert(tokens, attention_mask=masks)\n","        dropout_output = self.dropout(pooled_output)\n","        concat_output = dropout_output\n","        mlp_output = self.mlp(concat_output)\n","        skill_output = self.mlp2(concat_output)\n","        # proba = self.sigmoid(mlp_output)\n","        # proba = self.softmax(mlp_output)\n","\n","        return mlp_output,skill_output,attentions"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3zS4Xp2b95ys"},"source":["LE.classes_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZAgBxwiDbcIj"},"source":["from torch import nn\n","\n","\n","class Attention(nn.Module):\n","  def __init__(self,vector_1_dim,vector_2_dim):\n","    super(Attention, self).__init__()\n","    self.Weights = nn.Parameter(torch.rand(vector_2_dim,vector_1_dim))\n","    self.bias = nn.Parameter(torch.zeros(1))\n","\n","  def forward(self,vector_1,vector_2):\n","    #(batch_size,vector_2_dim,vector_1_dim)\n","    weights = self.Weights.repeat(vector_2.size(0),1,1)\n","    vector_1 = vector_1.unsqueeze(-1)  # (batch_size,vector_2_dim,vector_1_dim)\n","    weights = weights.matmul(vector_1) # results in (batch_size,vector_2_dim,1)\n","    weights = weights.repeat(vector_2.size(1),1,1,1).transpose(0,1)\n","    vector_2 = vector_2.unsqueeze(-2)\n","    attention_weights = torch.tanh(vector_2.matmul(weights).squeeze() + self.bias) # batch_size, vector_2_dim.size(0)\n","    if len(attention_weights.shape) ==1:\n","      attention_weights = attention_weights.squeeze()\n","      attention_weights = attention_weights.reshape(1,-1)\n","    attention_weights = attention_weights.squeeze()\n","    # print(\"torch.exp(attention_weights)\",torch.exp(attention_weights).shape,attention_weights.shape,torch.exp(attention_weights).sum(dim=1).shape)\n","    attention_weights = torch.exp(attention_weights)/ torch.exp(attention_weights).sum(dim=1,keepdim=True)\n","\n","    return attention_weights\n","\n","# bloom interactive attention\n","class MultiClassClassifier(nn.Module):\n","    def __init__(self, bert_model_path, labels_count,skill_label_count, hidden_dim=768, mlp_dim=500, extras_dim=140, dropout=0.1, freeze_bert=False):\n","        super().__init__()\n","\n","        self.bert = BertModel.from_pretrained(bert_model_path,output_hidden_states=True,output_attentions=True)\n","        self.dropout = nn.Dropout(dropout)\n","        self.bloom_attention = Attention(768, 768)\n","\n","        self.mlp = nn.Sequential(\n","            nn.Linear(hidden_dim , mlp_dim),\n","            nn.ReLU(),\n","            # nn.Linear(mlp_dim, mlp_dim),\n","            # nn.ReLU(),\n","            # nn.Linear(mlp_dim, mlp_dim),\n","            # nn.ReLU(),            \n","            nn.Linear(mlp_dim, labels_count)\n","        )\n","        self.mlp2 = nn.Sequential(  \n","            nn.Linear(hidden_dim , mlp_dim),\n","            nn.ReLU(),         \n","            nn.Linear(mlp_dim, skill_label_count)\n","        )\n","        # self.softmax = nn.LogSoftmax(dim=1)\n","        if freeze_bert:\n","            print(\"Freezing layers\")\n","            for param in self.bert.parameters():\n","                param.requires_grad = False\n","\n","    def forward(self, tokens, masks,difficulty_label):\n","        _, pooled_output,hidden_states,attentions = self.bert(tokens, attention_mask=masks)\n","        # dropout_output = self.dropout(pooled_output)\n","        # concat_output = dropout_output\n","\n","        # # mlp_output = self.mlp(concat_output)\n","        # skill_output_probas = self.mlp2(concat_output)\n","        # skill_output = torch.argmax(skill_output_probas,axis=1).cpu().numpy()\n","        # skill_output = LE_skill.inverse_transform(skill_output)\n","        difficulty_input_ids = []\n","        difficulty_attention_masks = []\n","        difficulty_label = difficulty_label.cpu().numpy()\n","        difficulty_label = LE.inverse_transform(difficulty_label)\n","\n","        for difficulty_text in difficulty_label:\n","          encoded_difficulty_output = tokenizer.encode_plus(\n","                          difficulty_text,                      # Sentence to encode.\n","                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                          max_length = 128,           # Pad & truncate all sentences.\n","                          pad_to_max_length = True,\n","                          truncation=True,\n","                          return_attention_mask = True,   # Construct attn. masks.\n","                          return_tensors = 'pt',     # Return pytorch tensors.\n","                    )\n","          difficulty_input_ids.append(encoded_difficulty_output['input_ids'])\n","          difficulty_attention_masks.append(encoded_difficulty_output['attention_mask'])\n","        difficulty_input_ids = torch.cat(difficulty_input_ids,dim=0).cuda()\n","        difficulty_attention_masks = torch.cat(difficulty_attention_masks,dim=0).cuda()\n","        _,_,hidden_states_difficulty,_ = self.bert(difficulty_input_ids,difficulty_attention_masks)\n","\n","        difficulty_hidden_averaged =  torch.sum(hidden_states_difficulty[12],dim=1)/hidden_states_difficulty[12].shape[1]\n","\n","        bloom_attention_weights = self.bloom_attention(difficulty_hidden_averaged, hidden_states[12])\n","\n","        bloom_attention_weights = bloom_attention_weights.unsqueeze(-2)\n","        # print(\"context_attention_weights\",context_attention_weights.shape,context_out.shape)\n","        input_attended_vector = bloom_attention_weights.matmul(hidden_states[12]).squeeze()\n","        # print(\"input_attended_vector\",input_attended_vector.shape)\n","        mlp_output = self.mlp2(input_attended_vector)\n","\n","        # print(\"bloom attention weights\", bloom_attention_weights.shape)\n","        # print(\"_hidden_states\",hidden_states_skill[12].shape, hidden_states[12].shape,skill_hidden_averaged.shape)\n","\n","        # proba = self.sigmoid(mlp_output)\n","        # proba = self.softmax(mlp_output)\n","\n","        return mlp_output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aGU0MvlQ97pt","outputId":"5e282f90-d9ab-4f15-c969-e38d1bd28fce"},"source":["model = MultiClassClassifier('bert-base-uncased',num_classes, skill_label_count,768,500,140,dropout=0.1,freeze_bert=False)\n","# model.load_state_dict(torch.load(\"model_bert_multi_task_interactive/model_weights\"))\n","model.cuda()"],"execution_count":null,"outputs":[{"data":{"text/plain":["MultiClassClassifier(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (bloom_attention): Attention()\n","  (mlp): Sequential(\n","    (0): Linear(in_features=768, out_features=500, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=500, out_features=5, bias=True)\n","  )\n","  (mlp2): Sequential(\n","    (0): Linear(in_features=768, out_features=500, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=500, out_features=5, bias=True)\n","  )\n",")"]},"execution_count":75,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"awQ2Y9Jb3kht"},"source":["optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Ys-M4-e3khv"},"source":["from transformers import get_linear_schedule_with_warmup\n","\n","\n","epochs = 20\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","total_steps = len(train_dataloader) * epochs\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EenVUl0iDyc1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QrYqErOD3khx","outputId":"ca90d850-5e3a-4e82-c339-bcd2b7100ca5"},"source":["len(train_dataloader) "],"execution_count":null,"outputs":[{"data":{"text/plain":["1223"]},"execution_count":78,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EWVSE9LM3kh0","outputId":"1a598dcd-53bc-490e-ce31-5bc715a431a6"},"source":["1935 * 32"],"execution_count":null,"outputs":[{"data":{"text/plain":["61920"]},"execution_count":79,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"rcvxVVi63kh3"},"source":["scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GUw3zm6g3kh5"},"source":["import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ta6zfUTa3kh7"},"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GFq9gd5kQSHb"},"source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y-rKyCrwE7N4","outputId":"a22f460d-c05a-4945-bc65-d3efd450a2fe"},"source":["# model.to(device)\n","model"],"execution_count":null,"outputs":[{"data":{"text/plain":["MultiClassClassifier(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (bloom_attention): Attention()\n","  (mlp): Sequential(\n","    (0): Linear(in_features=768, out_features=500, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=500, out_features=5, bias=True)\n","  )\n","  (mlp2): Sequential(\n","    (0): Linear(in_features=768, out_features=500, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=500, out_features=5, bias=True)\n","  )\n",")"]},"execution_count":84,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"1NuM6yRptFtS"},"source":["for param in model.bert.encoder.layer[0:5].parameters():\n","    param.requires_grad=False\n","for param in model.bert.embeddings.parameters():\n","    param.requires_grad=False\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a_nmuoSgQ5t3"},"source":["class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'checkpoint.pt'\n","            trace_func (function): trace print function.\n","                            Default: print            \n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","        self.trace_func = trace_func\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E1rDO58zMfc8"},"source":["loss_func = nn.CrossEntropyLoss()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JNFL0393HQZc"},"source":[""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6LhAy2hZ3kh9","outputId":"9c2164a0-020f-4276-dbc5-e38fd95fb3ce"},"source":["import random\n","import numpy as np\n","\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# We'll store a number of quantities such as training and validation loss, \n","# validation accuracy, and timings.\n","training_stats = []\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","early_stopping = EarlyStopping(patience=2, verbose=True)\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_accuracy = 0\n","    total_train_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questimport gensim.downloader as api\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels\n","         \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        # b_poincare = batch[2].to(device)\n","        # b_difficulty = batch[3].to(device)\n","        b_labels = batch[2].to(device)\n","        skill_labels = batch[3].to(device)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        probas = model(b_input_ids,b_input_mask, b_labels)\n","\n","\n","        loss = loss_func(probas, skill_labels)\n","        # skill_loss = loss_func(skill_probs,skill_labels)\n","        # loss = loss_1 + skill_loss\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        # torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        # scheduler.step()\n","        logits = probas.detach().cpu().numpy()\n","        label_ids = skill_labels.to('cpu').numpy()\n","        total_train_accuracy += flat_accuracy(logits, label_ids)\n","    avg_train_accuracy = total_train_accuracy / len(train_dataloader)\n","    print(\" Train Accuracy: {0:.2f}\".format(avg_train_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader) \n","\n","            \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using \n","        # the `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        # b_poincare = batch[2].to(device)\n","        # b_difficulty = batch[3].to(device)\n","        b_labels = batch[2].to(device)\n","        skill_labels = batch[3].to(device)\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","\n","          logits = model(b_input_ids,b_input_mask, b_labels)\n","            \n","        # Accumulate the validation loss.\n","        loss = loss_func(logits, skill_labels)\n","        # skill_loss = loss_func(skill_logits,skill_labels)\n","        # loss = loss_1 + skill_loss\n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = skill_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    early_stopping(avg_val_loss, model)\n","    if early_stopping.early_stop:\n","      print(\"Early stopping\")\n","      break    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","    output_dir = 'model_bert_multi_task_interactive_difficulty_given/'\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    print(\"Saving model to %s\" % output_dir)\n","    tokenizer.save_pretrained(output_dir)\n","    torch.save(model.state_dict(), os.path.join(output_dir, 'model_weights'))\n","\n","    !rm -rf \"/content/drive/My Drive/research_skill_name_prediction/model_bert_multi_task_interactive_difficulty_given\"\n","    !mv model_bert_multi_task_interactive_difficulty_given \"/content/drive/My Drive/research_skill_name_prediction/\"\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["\n","======== Epoch 1 / 20 ========\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"name":"stdout","output_type":"stream","text":["  Batch    40  of  1,223.    Elapsed: 0:00:44.\n","  Batch    80  of  1,223.    Elapsed: 0:01:27.\n","  Batch   120  of  1,223.    Elapsed: 0:02:10.\n","  Batch   160  of  1,223.    Elapsed: 0:02:53.\n","  Batch   200  of  1,223.    Elapsed: 0:03:35.\n","  Batch   240  of  1,223.    Elapsed: 0:04:18.\n","  Batch   280  of  1,223.    Elapsed: 0:05:00.\n","  Batch   320  of  1,223.    Elapsed: 0:05:42.\n","  Batch   360  of  1,223.    Elapsed: 0:06:25.\n","  Batch   400  of  1,223.    Elapsed: 0:07:07.\n","  Batch   440  of  1,223.    Elapsed: 0:07:51.\n","  Batch   480  of  1,223.    Elapsed: 0:08:33.\n","  Batch   520  of  1,223.    Elapsed: 0:09:16.\n","  Batch   560  of  1,223.    Elapsed: 0:09:58.\n","  Batch   600  of  1,223.    Elapsed: 0:10:41.\n","  Batch   640  of  1,223.    Elapsed: 0:11:24.\n","  Batch   680  of  1,223.    Elapsed: 0:12:06.\n","  Batch   720  of  1,223.    Elapsed: 0:12:50.\n","  Batch   760  of  1,223.    Elapsed: 0:13:32.\n","  Batch   800  of  1,223.    Elapsed: 0:14:15.\n","  Batch   840  of  1,223.    Elapsed: 0:14:59.\n","  Batch   880  of  1,223.    Elapsed: 0:15:42.\n","  Batch   920  of  1,223.    Elapsed: 0:16:25.\n","  Batch   960  of  1,223.    Elapsed: 0:17:08.\n","  Batch 1,000  of  1,223.    Elapsed: 0:17:51.\n","  Batch 1,040  of  1,223.    Elapsed: 0:18:34.\n","  Batch 1,080  of  1,223.    Elapsed: 0:19:17.\n","  Batch 1,120  of  1,223.    Elapsed: 0:20:00.\n","  Batch 1,160  of  1,223.    Elapsed: 0:20:44.\n","  Batch 1,200  of  1,223.    Elapsed: 0:21:26.\n"," Train Accuracy: 0.46\n","\n","  Average training loss: 1.30\n","  Training epcoh took: 0:21:51\n","\n","Running Validation...\n","  Accuracy: 0.47\n","Validation loss decreased (inf --> 1.245433).  Saving model ...\n","  Validation Loss: 1.25\n","  Validation took: 0:00:35\n","Saving model to model_bert_multi_task_interactive_difficulty_given/\n","\n","======== Epoch 2 / 20 ========\n","Training...\n","  Batch    40  of  1,223.    Elapsed: 0:00:43.\n","  Batch    80  of  1,223.    Elapsed: 0:01:26.\n","  Batch   120  of  1,223.    Elapsed: 0:02:09.\n","  Batch   160  of  1,223.    Elapsed: 0:02:52.\n","  Batch   200  of  1,223.    Elapsed: 0:03:34.\n","  Batch   240  of  1,223.    Elapsed: 0:04:17.\n","  Batch   280  of  1,223.    Elapsed: 0:05:00.\n","  Batch   320  of  1,223.    Elapsed: 0:05:43.\n","  Batch   360  of  1,223.    Elapsed: 0:06:26.\n","  Batch   400  of  1,223.    Elapsed: 0:07:09.\n","  Batch   440  of  1,223.    Elapsed: 0:07:52.\n","  Batch   480  of  1,223.    Elapsed: 0:08:35.\n","  Batch   520  of  1,223.    Elapsed: 0:09:18.\n","  Batch   560  of  1,223.    Elapsed: 0:10:00.\n","  Batch   600  of  1,223.    Elapsed: 0:10:43.\n","  Batch   640  of  1,223.    Elapsed: 0:11:26.\n","  Batch   680  of  1,223.    Elapsed: 0:12:09.\n","  Batch   720  of  1,223.    Elapsed: 0:12:53.\n","  Batch   760  of  1,223.    Elapsed: 0:13:36.\n","  Batch   800  of  1,223.    Elapsed: 0:14:18.\n","  Batch   840  of  1,223.    Elapsed: 0:15:01.\n","  Batch   880  of  1,223.    Elapsed: 0:15:44.\n","  Batch   920  of  1,223.    Elapsed: 0:16:27.\n","  Batch   960  of  1,223.    Elapsed: 0:17:10.\n","  Batch 1,000  of  1,223.    Elapsed: 0:17:53.\n","  Batch 1,040  of  1,223.    Elapsed: 0:18:36.\n","  Batch 1,080  of  1,223.    Elapsed: 0:19:20.\n","  Batch 1,120  of  1,223.    Elapsed: 0:20:03.\n","  Batch 1,160  of  1,223.    Elapsed: 0:20:46.\n","  Batch 1,200  of  1,223.    Elapsed: 0:21:29.\n"," Train Accuracy: 0.52\n","\n","  Average training loss: 1.18\n","  Training epcoh took: 0:21:53\n","\n","Running Validation...\n","  Accuracy: 0.51\n","Validation loss decreased (1.245433 --> 1.215074).  Saving model ...\n","  Validation Loss: 1.22\n","  Validation took: 0:00:35\n","Saving model to model_bert_multi_task_interactive_difficulty_given/\n","\n","======== Epoch 3 / 20 ========\n","Training...\n","  Batch    40  of  1,223.    Elapsed: 0:00:43.\n","  Batch    80  of  1,223.    Elapsed: 0:01:26.\n","  Batch   120  of  1,223.    Elapsed: 0:02:09.\n","  Batch   160  of  1,223.    Elapsed: 0:02:52.\n","  Batch   200  of  1,223.    Elapsed: 0:03:35.\n","  Batch   240  of  1,223.    Elapsed: 0:04:18.\n","  Batch   280  of  1,223.    Elapsed: 0:05:01.\n","  Batch   320  of  1,223.    Elapsed: 0:05:45.\n","  Batch   360  of  1,223.    Elapsed: 0:06:28.\n","  Batch   400  of  1,223.    Elapsed: 0:07:11.\n","  Batch   440  of  1,223.    Elapsed: 0:07:54.\n","  Batch   480  of  1,223.    Elapsed: 0:08:37.\n","  Batch   520  of  1,223.    Elapsed: 0:09:20.\n","  Batch   560  of  1,223.    Elapsed: 0:10:03.\n","  Batch   600  of  1,223.    Elapsed: 0:10:46.\n","  Batch   640  of  1,223.    Elapsed: 0:11:29.\n","  Batch   680  of  1,223.    Elapsed: 0:12:12.\n","  Batch   720  of  1,223.    Elapsed: 0:12:55.\n","  Batch   760  of  1,223.    Elapsed: 0:13:39.\n","  Batch   800  of  1,223.    Elapsed: 0:14:22.\n","  Batch   840  of  1,223.    Elapsed: 0:15:05.\n","  Batch   880  of  1,223.    Elapsed: 0:15:48.\n","  Batch   920  of  1,223.    Elapsed: 0:16:32.\n","  Batch   960  of  1,223.    Elapsed: 0:17:15.\n","  Batch 1,000  of  1,223.    Elapsed: 0:17:58.\n","  Batch 1,040  of  1,223.    Elapsed: 0:18:42.\n","  Batch 1,080  of  1,223.    Elapsed: 0:19:25.\n","  Batch 1,120  of  1,223.    Elapsed: 0:20:08.\n","  Batch 1,160  of  1,223.    Elapsed: 0:20:51.\n","  Batch 1,200  of  1,223.    Elapsed: 0:21:34.\n"," Train Accuracy: 0.56\n","\n","  Average training loss: 1.09\n","  Training epcoh took: 0:21:59\n","\n","Running Validation...\n","  Accuracy: 0.50\n","EarlyStopping counter: 1 out of 2\n","  Validation Loss: 1.23\n","  Validation took: 0:00:34\n","Saving model to model_bert_multi_task_interactive_difficulty_given/\n","\n","======== Epoch 4 / 20 ========\n","Training...\n","  Batch    40  of  1,223.    Elapsed: 0:00:44.\n","  Batch    80  of  1,223.    Elapsed: 0:01:26.\n","  Batch   120  of  1,223.    Elapsed: 0:02:10.\n","  Batch   160  of  1,223.    Elapsed: 0:02:53.\n","  Batch   200  of  1,223.    Elapsed: 0:03:36.\n","  Batch   240  of  1,223.    Elapsed: 0:04:19.\n","  Batch   280  of  1,223.    Elapsed: 0:05:02.\n","  Batch   320  of  1,223.    Elapsed: 0:05:46.\n","  Batch   360  of  1,223.    Elapsed: 0:06:29.\n","  Batch   400  of  1,223.    Elapsed: 0:07:12.\n","  Batch   440  of  1,223.    Elapsed: 0:07:55.\n","  Batch   480  of  1,223.    Elapsed: 0:08:39.\n","  Batch   520  of  1,223.    Elapsed: 0:09:22.\n","  Batch   560  of  1,223.    Elapsed: 0:10:05.\n","  Batch   600  of  1,223.    Elapsed: 0:10:48.\n","  Batch   640  of  1,223.    Elapsed: 0:11:32.\n","  Batch   680  of  1,223.    Elapsed: 0:12:15.\n","  Batch   720  of  1,223.    Elapsed: 0:12:58.\n","  Batch   760  of  1,223.    Elapsed: 0:13:41.\n","  Batch   800  of  1,223.    Elapsed: 0:14:25.\n","  Batch   840  of  1,223.    Elapsed: 0:15:08.\n","  Batch   880  of  1,223.    Elapsed: 0:15:51.\n","  Batch   920  of  1,223.    Elapsed: 0:16:34.\n","  Batch   960  of  1,223.    Elapsed: 0:17:17.\n","  Batch 1,000  of  1,223.    Elapsed: 0:18:01.\n","  Batch 1,040  of  1,223.    Elapsed: 0:18:44.\n","  Batch 1,080  of  1,223.    Elapsed: 0:19:27.\n","  Batch 1,120  of  1,223.    Elapsed: 0:20:10.\n","  Batch 1,160  of  1,223.    Elapsed: 0:20:54.\n","  Batch 1,200  of  1,223.    Elapsed: 0:21:37.\n"," Train Accuracy: 0.60\n","\n","  Average training loss: 1.00\n","  Training epcoh took: 0:22:02\n","\n","Running Validation...\n","  Accuracy: 0.51\n","EarlyStopping counter: 2 out of 2\n","Early stopping\n","\n","Training complete!\n","Total training took 1:30:14 (h:mm:ss)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":166},"id":"6RACcsko3kh_","outputId":"641d793c-aa95-4c1b-e1d2-e0f023c099b9"},"source":["import pandas as pd\n","\n","# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Valid. Accur.</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>1.30</td>\n","      <td>1.25</td>\n","      <td>0.47</td>\n","      <td>0:21:51</td>\n","      <td>0:00:35</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.18</td>\n","      <td>1.22</td>\n","      <td>0.51</td>\n","      <td>0:21:53</td>\n","      <td>0:00:35</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.09</td>\n","      <td>1.23</td>\n","      <td>0.50</td>\n","      <td>0:21:59</td>\n","      <td>0:00:34</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n","epoch                                                                         \n","1               1.30         1.25           0.47       0:21:51         0:00:35\n","2               1.18         1.22           0.51       0:21:53         0:00:35\n","3               1.09         1.23           0.50       0:21:59         0:00:34"]},"execution_count":89,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":427},"id":"o5TicdiP3kiC","outputId":"d969700f-8f22-4f0e-e7c9-17c1d0febbdd"},"source":["import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","import seaborn as sns\n","\n","# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])\n","\n","plt.show()"],"execution_count":null,"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{"tags":[]},"output_type":"display_data"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DbiTDpVv3kiF","outputId":"09c5c9e4-a9d9-4883-f877-5c2ccf322e19"},"source":["import os\n","\n","\n","output_dir = 'model_bert_multi_task_interactive_difficulty_given/'\n","\n","# Create output directory if needed\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","print(\"Saving model to %s\" % output_dir)\n","\n","\n","# model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","# model_to_save.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Saving model to model_bert_multi_task_interactive_difficulty_given/\n"]},{"data":{"text/plain":["('model_bert_multi_task_interactive_difficulty_given/vocab.txt',\n"," 'model_bert_multi_task_interactive_difficulty_given/special_tokens_map.json',\n"," 'model_bert_multi_task_interactive_difficulty_given/added_tokens.json')"]},"execution_count":91,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"Kq9ByBbSjJlx"},"source":["  import json\n","  torch.save(model.state_dict(), os.path.join(output_dir, 'model_weights'))\n","  # with open(os.path.join(output_dir, 'model_config.json'), 'w') as f:\n","  #     json.dump(model.config, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1U2UQ29a3kiI"},"source":["# !pip install joblib\n","# import joblib\n","# joblib.dump(LE, \"label_encoder_BLOOM_LATEST\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4GFnEkPP3kiP"},"source":["from google.colab import files\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dpGY8vSDI6u4","outputId":"9019cd16-eb20-49dc-fe0a-0e72f9c34edf"},"source":["!zip -r model_bert_multi_task_interactive_difficulty_given.zip model_bert_multi_task_interactive_difficulty_given\n","# files.download('model_bert_difficulty_prediction.zip')"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["  adding: model_bert_multi_task_interactive_difficulty_given/ (stored 0%)\n","  adding: model_bert_multi_task_interactive_difficulty_given/vocab.txt (deflated 53%)\n","  adding: model_bert_multi_task_interactive_difficulty_given/tokenizer_config.json (stored 0%)\n","  adding: model_bert_multi_task_interactive_difficulty_given/model_weights (deflated 7%)\n","  adding: model_bert_multi_task_interactive_difficulty_given/special_tokens_map.json (deflated 40%)\n"]}]},{"cell_type":"code","metadata":{"id":"HvFDCDIxKDOf"},"source":["# !zip -r label_encoder_BLOOM_LATEST.zip label_encoder_BLOOM_LATEST\n","# files.download('label_encoder_BLOOM_LATEST.zip')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":402},"id":"FcSwwzAFyE7S","outputId":"79a3932a-29d7-4b77-e248-50f0521b720c"},"source":["test"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>board_syllabus</th>\n","      <th>question_answer</th>\n","      <th>skill_label</th>\n","      <th>difficulty_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>CBSE&gt;&gt;Nursery&gt;&gt;Environmental Science&gt;&gt;Common V...</td>\n","      <td>Write down the names of some common vegetable...</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>CBSE&gt;&gt;XII&gt;&gt;Physics&gt;&gt;Physics : Part - II&gt;&gt;Atoms</td>\n","      <td>Name the series of hydrogen atom which lies i...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ICSE OLD&gt;&gt;XI&gt;&gt;Political Science&gt;&gt;State, Govern...</td>\n","      <td>Which of the following is not the element of ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Maharashtra New&gt;&gt;VII&gt;&gt;General Science&gt;&gt;Static ...</td>\n","      <td>The process of electrically charging an objec...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Tamil Nadu&gt;&gt;IX&gt;&gt;Science&gt;&gt;Physics&gt;&gt;Measurement&gt;...</td>\n","      <td>The mass of an object is measured in kilogram...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4572</th>\n","      <td>ICSE OLD&gt;&gt;VIII&gt;&gt;Biology&gt;&gt;Nervous System And Se...</td>\n","      <td>Which of the following is the first cranial n...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4573</th>\n","      <td>CBSE&gt;&gt;VII&gt;&gt;Computer Science&gt;&gt;Advance features ...</td>\n","      <td>To ungroup the worksheets: Right-click on any...</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4574</th>\n","      <td>CBSE&gt;&gt;VIII&gt;&gt;Science&gt;&gt;Chemical Effects of Elect...</td>\n","      <td>After passing electricity through a solution ...</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4575</th>\n","      <td>CLSP&gt;&gt;Stage 9&gt;&gt;Science&gt;&gt;Chemistry&gt;&gt;Material pr...</td>\n","      <td>Identify the scientists who gave the “plum-pu...</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4576</th>\n","      <td>AP&gt;&gt;VIII&gt;&gt;Physical Science&gt;&gt;Physical Science (...</td>\n","      <td>What do you understand by the term static ele...</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4577 rows × 4 columns</p>\n","</div>"],"text/plain":["                                         board_syllabus  ... difficulty_label\n","0     CBSE>>Nursery>>Environmental Science>>Common V...  ...                2\n","1        CBSE>>XII>>Physics>>Physics : Part - II>>Atoms  ...                1\n","2     ICSE OLD>>XI>>Political Science>>State, Govern...  ...                0\n","3     Maharashtra New>>VII>>General Science>>Static ...  ...                1\n","4     Tamil Nadu>>IX>>Science>>Physics>>Measurement>...  ...                1\n","...                                                 ...  ...              ...\n","4572  ICSE OLD>>VIII>>Biology>>Nervous System And Se...  ...                1\n","4573  CBSE>>VII>>Computer Science>>Advance features ...  ...                0\n","4574  CBSE>>VIII>>Science>>Chemical Effects of Elect...  ...                2\n","4575  CLSP>>Stage 9>>Science>>Chemistry>>Material pr...  ...                0\n","4576  AP>>VIII>>Physical Science>>Physical Science (...  ...                1\n","\n","[4577 rows x 4 columns]"]},"execution_count":97,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"4178_yLFMWmx"},"source":["test_features = test[\"question_answer\"].values\n","test_labels = test[\"difficulty_label\"].values\n","test_skill_labels = test[\"skill_label\"].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DggP9Sxdv_-l","outputId":"44b2bd83-e9c2-4d05-894f-dd82a64bf23d"},"source":["test_labels"],"execution_count":null,"outputs":[{"data":{"text/plain":["array([2, 1, 0, ..., 2, 0, 1])"]},"execution_count":99,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ZpmBJuIC2nM","outputId":"e025226f-2c0a-4295-add5-e1ca9b50eae6"},"source":["test_features"],"execution_count":null,"outputs":[{"data":{"text/plain":["array([' Write down the names of some common vegetables. Answer may vary Probable answer – Names of some common vegetables are potato, onion, tomato and carrot.',\n","       ' Name the series of hydrogen atom which lies in the U.V region. Lyman series lies in the U.V region.',\n","       ' Which of the following is not the element of an association? Relationships are abstract Each association has elements 1) a group of people, 2) voluntary Membership, 3) shared and common interests or needs as the basis, 4) some set of objective goals which are to be achieved collectively by all the members, 5) a voluntary organisation, and 6) co-operation among the members objectives pooled resources for funds needed for action.',\n","       ...,\n","       ' After passing electricity through a solution the change that takes place is a chemical change Physical changes are those changes that do not result in the production of a new substance whereas a chemical change involves the production of a new substance. For example: When electricity is passed in a solution containing water, bubbles of hydrogen and oxygen are formed.',\n","       ' Identify the scientists who gave the “plum-pudding” model of the atom. J. J. Thomson The &ldquo;plum-pudding&rdquo; model of the atom was developed by the J. J Thomson. He compared his model used for describing the structure of atom with a plum pudding in which negatively charged electrons were surrounded by a positively charged &lsquo;pudding&rsquo;.',\n","       ' What do you understand by the term static electricity? It is the electricity developed due to stationary electric charges on the body.'],\n","      dtype=object)"]},"execution_count":100,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"MlOvANUwprAw","outputId":"01df537f-6f24-4189-8f1f-108ed177868c"},"source":["test_features[0]"],"execution_count":null,"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["' Write down the names of some common vegetables. Answer may vary Probable answer – Names of some common vegetables are potato, onion, tomato and carrot.'"]},"execution_count":101,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"-nCVhlaoXaXM","outputId":"a8e78256-691f-4368-840b-80c58061ff1e"},"source":["test_features[0]"],"execution_count":null,"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["' Write down the names of some common vegetables. Answer may vary Probable answer – Names of some common vegetables are potato, onion, tomato and carrot.'"]},"execution_count":102,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"2xncpeEmoGsB"},"source":["# syllabus = get_syllabus(test_features.values)\n","# poincare_emb_test = get_poincare_embeddings(syllabus)\n","# # for i,oincare in enumerate(poincare_emb_test):\n","# #   for x in oincare:\n","# #     print(i)\n","# #     print(oincare)\n","# #     print(poincare_model.kv.get_vector(str(x)))\n","\n","# poincare_embedding_test =  [exponential_map(np.expand_dims( np.hstack(  [ poincare_model.kv.get_vector(str(x)) for x in taxonomy ] ),axis=0)) for taxonomy in poincare_emb_test ]\n","# max_val = 0\n","# max_emb =None\n","# for embedding in poincare_embedding_test:\n","#   val = embedding.shape[1]\n","#   if val >max_val:\n","#     max_val=val\n","#     max_emb =embedding\n","# max_val\n","# concatenated_embedding = []\n","# for embedding in poincare_embedding_test:\n","#   if embedding.shape[1] < max_val:\n","#     new_embedding = np.append(embedding, np.expand_dims(np.zeros(max_val-embedding.shape[1]),axis=0),axis=1)\n","#   else:\n","#     new_embedding = embedding\n","#   concatenated_embedding.append(np.squeeze(new_embedding,axis=0))\n","# poincare_embeddings_final = np.stack(concatenated_embedding, axis=0)\n","# for feature_set in test_features:\n","#   if feature_set[1]!=feature_set[1]: #to check for nan\n","#     print(\"here\")\n","#     feature_set[1] = \"unk\"\n","#   else:\n","#     feature_set[1]=feature_set[1].lower()\n","# difficulty_level_vectors=[]\n","# for feature_set in test_features:\n","#   words = [word for word in feature_set[1].split(\" \")]\n","#   if len(words) > 1:\n","#     print(\"here\")\n","#     difficulty_level_vectors.append(np.mean(wv[words],axis=0))\n","#   else:\n","#     difficulty_level_vectors.append(wv[words].squeeze(axis=0))\n","# difficulty_level_vectors = np.array(difficulty_level_vectors)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qe4qYkV2C4fX","outputId":"b9da4123-e077-47b1-95cf-e33cb9a956c8"},"source":["input_ids = []\n","attention_masks = []\n","for sent in test_features:\n","\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 128,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        truncation=True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","test_labels = torch.tensor(test_labels)\n","test_skill_labels = torch.tensor(test_skill_labels)\n","\n","# Set the batch size.  \n","batch_size = 34\n","\n","# test_poincare_tensor = torch.tensor(poincare_embeddings_final,dtype=torch.float)\n","# print(test_poincare_tensor.shape)\n","# difficulty_tensor = torch.tensor(difficulty_level_vectors,dtype=torch.float)\n","# print(\"difficulty_tensor\",difficulty_tensor.shape)\n","# Combine the training inputs into a TensorDataset.\n","prediction_data = TensorDataset(input_ids, attention_masks, test_labels,test_skill_labels)\n","# Create the DataLoader.\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mPCktQT9DVT4","outputId":"c44d7bac-1bfa-44b5-c182-29281b9382db"},"source":["# Prediction on test set\n","\n","print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n","\n","# Put model in evaluation mode\n","model.eval()\n","\n","# Tracking variables \n","predictions,skill_predictions , true_labels, true_skill_labels = [], [], [], []\n","\n","# Predict ea\n","for batch in prediction_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  \n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels,skill_labels = batch\n","  \n","  # Telling the model not to compute or store gradients, saving memory and \n","  # speeding up prediction\n","  # print(\"b_input_ids\",b_input_ids.shape)\n","  with torch.no_grad():\n","      # Forward pass, calculate logit predictions\n","      outputs = model(b_input_ids,b_input_mask,b_labels)\n","\n","  logits = outputs\n","\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  # skill_logits = skill_logits.detach().cpu().numpy()\n","  label_ids = skill_labels.to('cpu').numpy()\n","  # skill_labels = skill_labels.to('cpu').numpy()\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  # skill_predictions.append(skill_logits)\n","  true_labels.append(label_ids)\n","  # true_skill_labels.append(skill_labels)\n","\n","\n","print('    DONE.')"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Predicting labels for 4,577 test sentences...\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"name":"stdout","output_type":"stream","text":["    DONE.\n"]}]},{"cell_type":"markdown","metadata":{"id":"U_WchmXtDspr"},"source":["print('Positive samples: %d of %d (%.2f%%)' % (final_data.label.sum(), len(final_data.label), (final_data.label.sum() / len(final_data.label) * 100.0)))"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s5BoY2hKGb7_","outputId":"10e513ca-774b-47dd-9fb4-ac3e7d02eb2b"},"source":["import numpy as np\n","pred =  np.argmax(predictions[0],axis=1).flatten()\n","pred"],"execution_count":null,"outputs":[{"data":{"text/plain":["array([4, 2, 0, 3, 3, 4, 2, 3, 3, 1, 3, 2, 4, 2, 3, 3, 2, 1, 1, 3, 4, 2,\n","       4, 0, 3, 4, 2, 4, 4, 1, 1, 3, 3, 4])"]},"execution_count":106,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tPuK0-vzGp3R","outputId":"b8d84221-0fb8-4969-b0ab-3368fa7a577c"},"source":["from sklearn.metrics import matthews_corrcoef\n","\n","matthews_set = []\n","\n","# Evaluate each test batch using Matthew's correlation coefficient\n","print('Calculating Matthews Corr. Coef. for each batch...')\n","\n","# For each input batch...\n","for i in range(len(true_labels)):\n","  \n","  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n","  # and one column for \"1\"). Pick the label with the highest value and turn this\n","  # in to a list of 0s and 1s.\n","  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n","  \n","  # Calculate and store the coef for this batch.  \n","  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n","  matthews_set.append(matthews)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Calculating Matthews Corr. Coef. for each batch...\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i5MKFS0iXm7l","outputId":"1dd4cf17-e011-4de9-dfb5-678713635aab"},"source":["import numpy as np\n","flat_predictions = np.concatenate(predictions, axis=0)\n","\n","flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","\n","# Combine the correct labels for each batch into a single list.\n","flat_true_labels = np.concatenate(true_labels, axis=0)\n","\n","# Calculate the MCC\n","mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n","\n","print('Total MCC: %.3f' % mcc)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Total MCC: 0.355\n"]}]},{"cell_type":"code","metadata":{"id":"nOTqUYPmEUCn"},"source":["flat_skill_predictions = np.concatenate(skill_predictions, axis=0)\n","\n","flat_skill_predictions = np.argmax(flat_skill_predictions, axis=1).flatten()\n","\n","# Combine the correct labels for each batch into a single list.\n","flat_true_skill_labels = np.concatenate(true_skill_labels, axis=0)\n","\n","# Calculate the MCC\n","mcc = matthews_corrcoef(flat_true_skill_labels, flat_skill_predictions)\n","\n","print('Total MCC: %.3f' % mcc)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FD3aaycBz4DR"},"source":["len(flat_true_skill_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zlqpVfk-NW_F"},"source":["def accuracy_per_class(preds_flat, labels_flat):\n","\n","    for label in np.unique(labels_flat):\n","        y_preds = preds_flat[labels_flat==label]\n","        y_true = labels_flat[labels_flat==label]\n","        print(f'Class: {get_labels(label)}')\n","        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o29QuEYW-mzm","outputId":"f07bcd35-943c-405d-c78f-7dc59c965ebb"},"source":["accuracy_per_class(flat_predictions,flat_true_labels)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Class: Analysing\n","Accuracy: 123/404\n","\n","Class: Applying\n","Accuracy: 226/602\n","\n","Class: Knowledge & understanding\n","Accuracy: 635/933\n","\n","Class: Remembering\n","Accuracy: 790/1356\n","\n","Class: Understanding\n","Accuracy: 546/1282\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ed7_zfiDNaOv","outputId":"213258a4-20b4-4765-cbba-992be288046d"},"source":["accuracy_per_class(flat_predictions,flat_true_labels)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Class: Difficult\n","Accuracy: 696/1646\n","\n","Class: Easy\n","Accuracy: 1835/2207\n","\n","Class: Medium\n","Accuracy: 39/724\n","\n"]}]},{"cell_type":"code","metadata":{"id":"4_vxvq7rHlgr"},"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n","\n","plt.title('MCC Score per Batch')\n","plt.ylabel('MCC Score (-1 to +1)')\n","plt.xlabel('Batch #')\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v48rDl4JHmhv"},"source":["flat_predictions = np.concatenate(predictions, axis=0)\n","\n","flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","\n","# Combine the correct labels for each batch into a single list.\n","flat_true_labels = np.concatenate(true_labels, axis=0)\n","\n","# Calculate the MCC\n","mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n","\n","print('Total MCC: %.3f' % mcc)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O5f5p01wfLM6"},"source":["flat_skill_predictions"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"drJC0xYkHr_8","outputId":"7e8380a5-75cb-4928-c869-29d9d6eb3cd9"},"source":["print('Total MCC: %.3f' % mcc)\n"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Total MCC: 0.247\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f8K0OFM-c7Fv","outputId":"3110853c-986d-469a-f981-701680d9c17e"},"source":["from sklearn.metrics import precision_recall_fscore_support\n","#skill\n","print(precision_recall_fscore_support(flat_true_labels, flat_predictions, average='micro'))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["(0.5068822372733232, 0.5068822372733232, 0.5068822372733232, None)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"44lMA088c7Fv","outputId":"92556661-b272-4f19-9e7f-cfa7f6564a25"},"source":["from sklearn.metrics import precision_recall_fscore_support\n","#skill\n","print(precision_recall_fscore_support(flat_true_labels, flat_predictions, average='macro'))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["(0.4763964284686266, 0.4737927696773556, 0.47377267550963714, None)\n"]}]},{"cell_type":"code","metadata":{"id":"zFediYEjlKjX"},"source":["def get_confusion_matrix(predicted,actual):\n","    conf_matrix = np.zeros((5, 5))\n","    for pred,act in zip(predicted,actual):\n","        conf_matrix[act,pred]+=1\n","    return conf_matrix\n","        \n","def get_TP(confusion_matrix,label):\n","    tp = confusion_matrix[label][label]\n","    return tp\n","\n","def get_FN(confusion_matrix,label):\n","    row = confusion_matrix[label,]\n","    row_truepositives = row[label]\n","    fn = row.sum() - row_truepositives\n","    return fn\n","\n","def get_FP(confusion_matrix,tag):\n","    col = confusion_matrix[:,tag]\n","    col_tp = col[tag]\n","    #  sum of all values in column except tp\n","    fp = col.sum() - col_tp\n","    return fp\n","def Precision(conf_matrix):\n","    precision = 0.0\n","    for label in [0,1,2,3,4]:\n","        dividor= get_TP(conf_matrix,label)+get_FP(conf_matrix,label)\n","        if dividor != 0.0:\n","            precision += (get_TP(conf_matrix,label))/dividor\n","    return (precision / 5)\n","\n","def Recall(conf_matrix):\n","    recall = 0.0\n","    for label in [0,1,2,3,4]:\n","        dividor=get_TP(conf_matrix,label)+get_FN(conf_matrix,label)\n","        if dividor != 0.0:\n","            recall += (get_TP(conf_matrix,label))/dividor\n","    return (recall / 5)\n","\n","def F1(precision,recall):\n","    return (2*precision*recall)/(precision+recall)\n","def accuracy_per_class(preds_flat, labels_flat):\n","\n","    for label in np.unique(labels_flat):\n","        y_preds = preds_flat[labels_flat==label]\n","        y_true = labels_flat[labels_flat==label]\n","        print(f'Class: {label}')\n","        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n","def print_metrics(predictions,test_labels):\n","    conf_matrix = get_confusion_matrix(predictions,test_labels)\n","    precision = Precision(conf_matrix)\n","    recall = Recall(conf_matrix)\n","    f1_score = F1(precision,recall)\n","    print(\"Macro : Precision:{}, Recall: {}, F1: {}\".format(precision,recall,f1_score))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aFEi23ejPfOm"},"source":["def Precision_macro_weighted(conf_matrix,test_samples):\n","    accum =0\n","    label_wise_precision = dict()\n","    for label in [0,1,2,3,4]:\n","        true_sample = [sample for sample in test_samples if sample==label ]\n","        if (get_TP(conf_matrix,label)+get_FP(conf_matrix,label))!=0:\n","            accum+= float(len(true_sample)) *(get_TP(conf_matrix,label)/(get_TP(conf_matrix,label)+get_FP(conf_matrix,label)))\n","            label_wise_precision[label] = get_TP(conf_matrix,label)/(get_TP(conf_matrix,label)+get_FP(conf_matrix,label))\n","\n","    \n","    precision =  accum/len(test_samples)\n","            \n","    return precision\n","\n","\n","def Recall_macro_weighted(conf_matrix,test_samples):\n","    accum =0\n","    label_wise_recall = dict()\n","    for label in [0,1,2,3,4]:\n","        true_sample = [sample for sample in test_samples if sample==label ]\n","\n","        if (get_TP(conf_matrix,label)+get_FN(conf_matrix,label))!=0:\n","            accum+= float(len(true_sample)) * (get_TP(conf_matrix,label)/(get_TP(conf_matrix,label)+get_FN(conf_matrix,label)))\n","            label_wise_recall[label] = get_TP(conf_matrix,label)/(get_TP(conf_matrix,label)+get_FN(conf_matrix,label))\n","\n","    \n","    recall =  accum/len(test_samples)\n","    return recall\n","def print_weighted_metrics(predictions,test_labels):\n","    conf_matrix = get_confusion_matrix(predictions,test_labels)\n","    precision = Precision_macro_weighted(conf_matrix,test_labels)\n","    recall = Recall_macro_weighted(conf_matrix,test_labels)\n","    f1_score = F1(precision,recall)\n","    print(\"Macro : Precision:{}, Recall: {}, F1: {}\".format(precision,recall,f1_score))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pbe2BbA4E20b","outputId":"f1a117a7-7409-4aed-96ab-2a7ffaf5cffa"},"source":["#skill macro\n","print_metrics(flat_predictions,flat_true_labels)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Macro : Precision:0.4763964284686266, Recall: 0.4737927696773556, F1: 0.4750910318681047\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nNp29QbiA1B8","outputId":"cb9c7a5d-fa5b-4c1d-8ca8-64a77985aae7"},"source":["#skill\n","print_weighted_metrics(flat_predictions,flat_true_labels)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Macro : Precision:0.4999090357887597, Recall: 0.5068822372733232, F1: 0.5033714877624509\n"]}]},{"cell_type":"code","metadata":{"id":"lbxR7mbxBCBP"},"source":["def accuracy_per_class(preds_flat, labels_flat):\n","\n","    for label in np.unique(labels_flat):\n","        y_preds = preds_flat[labels_flat==label]\n","        y_true = labels_flat[labels_flat==label]\n","        print(f'Class: {get_labels(label)}')\n","        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xXoacYx9BD_v","outputId":"a929053d-c5ee-44f4-efbd-cd8cd8e7a325"},"source":["accuracy_per_class(flat_predictions,flat_true_labels)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Class: 0\n","Accuracy: 696/1646\n","\n","Class: 1\n","Accuracy: 1835/2207\n","\n","Class: 2\n","Accuracy: 39/724\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0DaR_83RQ9Fp","outputId":"8841a43d-581a-4c58-e649-63a32ed04d48"},"source":["accuracy_per_class(flat_skill_predictions,flat_true_skill_labels)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Class: Analysing\n","Accuracy: 125/404\n","\n","Class: Applying\n","Accuracy: 150/602\n","\n","Class: Knowledge & understanding\n","Accuracy: 613/933\n","\n","Class: Remembering\n","Accuracy: 831/1356\n","\n","Class: Understanding\n","Accuracy: 557/1282\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"qvJNY5FEVOn4","outputId":"95bfb07c-3ff8-4cc7-9df2-eb721c4239b6"},"source":["get_labels(1)"],"execution_count":null,"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Easy'"]},"execution_count":107,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"vu6lbpuxxbxk"},"source":["!cp -r /content/model_bert_multi_task_interactive_skill_given.zip \"/content/drive/My Drive/research_skill_name_prediction/\" "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K6dumvtLVV6w"},"source":["!cp -r /content/model_bert_multi_task_interactive_skill_given \"/content/drive/My Drive/research_skill_name_prediction/\" "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nv242vUH68jm"},"source":["!cp -r \"/content/drive/My Drive/research_skill_name_prediction/model_bert_multi_task_prediction.zip\" /content/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PNaswzbJ7EOw","outputId":"33fcba65-ff87-4bc7-88e8-1890bb03b6d8"},"source":["!unzip model_bert_multi_task_prediction.zip"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Archive:  model_bert_multi_task_prediction.zip\n","   creating: model_bert_multi_task_prediction/\n","  inflating: model_bert_multi_task_prediction/model_weights  \n","  inflating: model_bert_multi_task_prediction/tokenizer_config.json  \n","  inflating: model_bert_multi_task_prediction/special_tokens_map.json  \n","  inflating: model_bert_multi_task_prediction/vocab.txt  \n"]}]},{"cell_type":"code","metadata":{"id":"uSK1y-sQ8UAq"},"source":["!cp -r /content/model_bert_multi_task_prediction \"/content/drive/My Drive/research_skill_name_prediction/\" "],"execution_count":null,"outputs":[]}]}