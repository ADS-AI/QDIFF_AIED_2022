{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"multi_task_qdiff_interactive_attention_pre_trained_skill_bert.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"widgets":{"application/vnd.jupyter.widget-state+json":{"558606ca009b4d5ca5019d7806dd842c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_32bdb2a87bdd41cbaf42fb2bfb98f3e2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_96a17bb0760b49f3812cbf51d3548f8b","IPY_MODEL_ed75ccb4ccd140ae82ed5d9e3b3109cb"]}},"32bdb2a87bdd41cbaf42fb2bfb98f3e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"96a17bb0760b49f3812cbf51d3548f8b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1368c7cd17d943c5908ea6fbdadca7ba","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_84abbb525b2840fabb68450669f40aab"}},"ed75ccb4ccd140ae82ed5d9e3b3109cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2024b3b773084d4a93e45e00eb7781af","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 2.13MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_08690340ac1f452980e240f733250a54"}},"1368c7cd17d943c5908ea6fbdadca7ba":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"84abbb525b2840fabb68450669f40aab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2024b3b773084d4a93e45e00eb7781af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"08690340ac1f452980e240f733250a54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sR9av2JU3kf6","outputId":"42fc2337-0ecd-421f-c003-e9442f54c90b"},"source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","import torch\n","import logging\n","logging.basicConfig(level=logging.ERROR)\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla K80\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BzKeqoCs3kgA","outputId":"7ebadf7b-8a2b-47f3-92be-fe48fe9961fd"},"source":["!pip install transformers==3.2.0"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers==3.2.0\n","  Downloading transformers-3.2.0-py3-none-any.whl (1.0 MB)\n","\u001b[K     |████████████████████████████████| 1.0 MB 4.1 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 35.5 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (21.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (4.62.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (1.19.5)\n","Collecting sentencepiece!=0.1.92\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 39.0 MB/s \n","\u001b[?25hCollecting tokenizers==0.8.1.rc2\n","  Downloading tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 36.2 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (3.0.12)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.2.0) (2.4.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2.0) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2.0) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.2.0) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.2.0) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.2.0) (1.15.0)\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.45 sentencepiece-0.1.96 tokenizers-0.8.1rc2 transformers-3.2.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":407},"id":"GsADhaO93kgD","outputId":"569288c1-99de-4c9c-f933-80b7a043fde9"},"source":["import pandas as pd\n","final_data = pd.read_csv(\"train_skill_name_difficulty.csv\")\n","final_data"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>board_syllabus</th>\n","      <th>question_answer</th>\n","      <th>skill_label</th>\n","      <th>difficulty_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Raj English&gt;&gt;XII&gt;&gt;Biology&gt;&gt;Domestication, Cult...</td>\n","      <td>Among the following, freshwater fish is rohu ...</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Maharashtra New&gt;&gt;VI&gt;&gt;General Science&gt;&gt;Sound&gt;&gt;P...</td>\n","      <td>Which of the following statement is true? Sou...</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ICSE OLD&gt;&gt;XI&gt;&gt;Computer Science&gt;&gt;Functions&gt;&gt;Con...</td>\n","      <td>The process of using multiple constructors wi...</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>CBSE&gt;&gt;VI&gt;&gt;Science&gt;&gt;Separation of Substances&gt;&gt;S...</td>\n","      <td>Sieving is based on the difference in the siz...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>AP&gt;&gt;X&gt;&gt;Biology&gt;&gt;Excretion - The Wastage Dispos...</td>\n","      <td>The removal of toxic and unwanted waste subst...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>39124</th>\n","      <td>CAPS(South Africa)&gt;&gt;Grade 7&gt;&gt;Natural Sciences&gt;...</td>\n","      <td>How heat loss problems are prevented by birds...</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>39125</th>\n","      <td>CBSE&gt;&gt;X&gt;&gt;Science&gt;&gt;Metals and Non-Metal</td>\n","      <td>Give reasons why copper is used to make hot w...</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>39126</th>\n","      <td>CBSE&gt;&gt;VII&gt;&gt;Science&gt;&gt;Motion and Time</td>\n","      <td>The horizontal line in the graph is denoted as...</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>39127</th>\n","      <td>Tamil Nadu&gt;&gt;VI&gt;&gt;Science&gt;&gt;Term 1&gt;&gt;Physics&gt;&gt;Forc...</td>\n","      <td>SI unit of force is newton The SI unit of for...</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>39128</th>\n","      <td>Tamil Nadu&gt;&gt;VIII&gt;&gt;Science&gt;&gt;Term 1&gt;&gt;Physics&gt;&gt;Fo...</td>\n","      <td>In machines sliding frictions is replaced to ...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>39129 rows × 4 columns</p>\n","</div>"],"text/plain":["                                          board_syllabus  ... difficulty_label\n","0      Raj English>>XII>>Biology>>Domestication, Cult...  ...                0\n","1      Maharashtra New>>VI>>General Science>>Sound>>P...  ...                2\n","2      ICSE OLD>>XI>>Computer Science>>Functions>>Con...  ...                0\n","3      CBSE>>VI>>Science>>Separation of Substances>>S...  ...                1\n","4      AP>>X>>Biology>>Excretion - The Wastage Dispos...  ...                1\n","...                                                  ...  ...              ...\n","39124  CAPS(South Africa)>>Grade 7>>Natural Sciences>...  ...                1\n","39125             CBSE>>X>>Science>>Metals and Non-Metal  ...                2\n","39126                CBSE>>VII>>Science>>Motion and Time  ...                1\n","39127  Tamil Nadu>>VI>>Science>>Term 1>>Physics>>Forc...  ...                2\n","39128  Tamil Nadu>>VIII>>Science>>Term 1>>Physics>>Fo...  ...                1\n","\n","[39129 rows x 4 columns]"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A0Ja4jiFhmdg","outputId":"0ae01e68-ecea-4781-9dc6-d3e43e0501cd"},"source":["final_data[\"question_answer\"].values"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([' Among the following, freshwater fish is rohu Rohu is a fresh water fish. Other common freshwater fish are catla, common carp.',\n","       ' Which of the following statement is true? Sound requires a medium for propagation. Sound travels through a medium (solid, liquid or gas). It cannot travel through vacuum.',\n","       ' The process of using multiple constructors with the same name but with different parameters is known as: Constructor overloading Constructor overloading is a technique in Java in which a class can have any number of constructors that differ in parameter lists.',\n","       ...,\n","       'The horizontal line in the graph is denoted as the X-axis. The horizontal line points in the horizontal direction and is denoted as the X-axis in the graph.',\n","       ' SI unit of force is newton The SI unit of force is Newton (N), named after famous scientist Isaac Newton who discovered force of gravitation.',\n","       ' In machines sliding frictions is replaced to rolling by use of ball bearings Ball bearing roll to produce rolling;friction.'],\n","      dtype=object)"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iQhO6qqt6lge","outputId":"005306d2-bccc-4fa8-d902-2617ba2c40dd"},"source":["final_data['difficulty_label'].value_counts()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    19312\n","0    14146\n","2     5671\n","Name: difficulty_label, dtype: int64"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"2EkZ-3TZ5UBJ"},"source":["def clean_sentence(question):\n","  # print(question)\n","  question = re.sub('<[^>]*>', ' ',question)\n","  question = re.sub(' +', ' ', question)\n","  question = re.sub('\\xa0','',question)\n","  question = question.rstrip()\n","  question = re.sub('nan','',question)\n","  question = re.sub(u'\\u2004','',question)\n","  question = re.sub(u'\\u2009','',question)\n","\n","  # question = question.decode(\"utf-8\")\n","  # question = question.replace(u'\\u200\\d*','').encode(\"utf-8\")\n","  question = re.sub('&nbsp','',question)\n","  question = re.sub('&ndash','',question)\n","  question = re.sub('\\r','',question)\n","  question = re.sub('\\t','',question)\n","  question = re.sub('\\n',' ',question)\n","\n","  question = re.sub('MathType@.*','',question)\n","  question = re.sub('&thinsp','',question)\n","  question = re.sub('&times','',question)\n","  question = re.sub('\\u200b','',question)\n","  question = re.sub('&rarr;;;','',question)\n","\n","  return question"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IMCV9mxDnaK0","outputId":"15a1d53c-c57f-4be0-c4a1-d3019b8f7cde"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"9exlBELH5oq9"},"source":["!cp \"/content/drive/My Drive/research_skill_name_prediction/label_encoder_difficulty_Lstm\"  /content"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pUqcGtXwBIyl"},"source":["!cp \"/content/drive/MyDrive/research_skill_name_prediction/label_encoder_skill_lstm\" /content"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rj-ow-6cqFyn"},"source":["!cp -r \"/content/drive/MyDrive/research_skill_name_prediction/model_bert_multi_task_interactive_pre_trained_skill_bert\" /content"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cov2EsRThbfF"},"source":["!cp -r \"/content/drive/MyDrive/research_skill_name_prediction/qdiff_skill_only_prediction_bert\" /content"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JYbSa7ZKAkfz","outputId":"3caf8c5d-32a0-4c65-a807-1640f9f24d02"},"source":["import joblib\n","LE_skill = joblib.load('label_encoder_skill_lstm')\n","LE_skill.classes_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['Analysing', 'Applying', 'Knowledge & understanding',\n","       'Remembering', 'Understanding'], dtype=object)"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"-OBarOLBz2nO"},"source":["def get_labels(prediction):\n","    predicted_label =  LE.inverse_transform([prediction])\n","    return predicted_label[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"id":"XqWem79lbn1J","outputId":"31338a08-9ce9-4f89-cb75-377fcc56dd2e"},"source":["final_data['difficulty_label'].value_counts().sort_values(ascending=False).plot(kind='bar')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f7e92619a50>"]},"metadata":{"tags":[]},"execution_count":14},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"RxliBQEJ9eTG"},"source":["val = pd.read_csv(\"val_skill_name_difficulty.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":402},"id":"07eBaI9wA2hL","outputId":"285d7ba3-73ba-4082-8669-8d0795d0a72a"},"source":["val"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>board_syllabus</th>\n","      <th>question_answer</th>\n","      <th>skill_label</th>\n","      <th>difficulty_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AP&gt;&gt;VII&gt;&gt;Science&gt;&gt;Animal Fibre&gt;&gt;Silk</td>\n","      <td>Name the two types of protein from which silk...</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Maharashtra New&gt;&gt;VIII&gt;&gt;General Science&gt;&gt;Man Ma...</td>\n","      <td>Give reasons: (i) Thermocol is used for the p...</td>\n","      <td>4</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>CBSE&gt;&gt;VI&gt;&gt;Science&gt;&gt;Fun with Magnets&gt;&gt;Demagneti...</td>\n","      <td>Identify the odd option. Rubbing a magnetic m...</td>\n","      <td>4</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Tamil Nadu&gt;&gt;VIII&gt;&gt;Science&gt;&gt;Term 1&gt;&gt;Physics&gt;&gt;Li...</td>\n","      <td>Find the speed of light in glass of refractiv...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Raj English&gt;&gt;XII&gt;&gt;Biology&gt;&gt;Integumentary Syste...</td>\n","      <td>Which of the following function is associated...</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2055</th>\n","      <td>CBSE&gt;&gt;XI&gt;&gt;Chemistry&gt;&gt;Chemistry : Part I&gt;&gt;Equil...</td>\n","      <td>The solubility of A 2 X 3 is y mol.dm -3 . So...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2056</th>\n","      <td>CBSE&gt;&gt;VI&gt;&gt;Computer Science&gt;&gt;Using Mail Merge&gt;&gt;...</td>\n","      <td>To create an invitation letter, click on Mail...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2057</th>\n","      <td>CBSE&gt;&gt;XII&gt;&gt;Physics&gt;&gt;Physics : Part - II&gt;&gt;Ray O...</td>\n","      <td>Choose the correct option about the intensity...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2058</th>\n","      <td>ICSE OLD&gt;&gt;VII&gt;&gt;Biology&gt;&gt;Organ System of Human ...</td>\n","      <td>Which of the following instrument is used to ...</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2059</th>\n","      <td>CBSE&gt;&gt;X&gt;&gt;Science&gt;&gt;Carbon and its Compounds&gt;&gt;Al...</td>\n","      <td>Identify the correct statement about allotrop...</td>\n","      <td>4</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2060 rows × 4 columns</p>\n","</div>"],"text/plain":["                                         board_syllabus  ... difficulty_label\n","0                  AP>>VII>>Science>>Animal Fibre>>Silk  ...                0\n","1     Maharashtra New>>VIII>>General Science>>Man Ma...  ...                2\n","2     CBSE>>VI>>Science>>Fun with Magnets>>Demagneti...  ...                2\n","3     Tamil Nadu>>VIII>>Science>>Term 1>>Physics>>Li...  ...                0\n","4     Raj English>>XII>>Biology>>Integumentary Syste...  ...                0\n","...                                                 ...  ...              ...\n","2055  CBSE>>XI>>Chemistry>>Chemistry : Part I>>Equil...  ...                0\n","2056  CBSE>>VI>>Computer Science>>Using Mail Merge>>...  ...                1\n","2057  CBSE>>XII>>Physics>>Physics : Part - II>>Ray O...  ...                0\n","2058  ICSE OLD>>VII>>Biology>>Organ System of Human ...  ...                1\n","2059  CBSE>>X>>Science>>Carbon and its Compounds>>Al...  ...                0\n","\n","[2060 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":402},"id":"g8tVsjiWj-cF","outputId":"bfa26a75-60df-47dc-da85-cb06c93320e9"},"source":["test = pd.read_csv(\"test_skill_name_difficulty.csv\")\n","test"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>board_syllabus</th>\n","      <th>question_answer</th>\n","      <th>skill_label</th>\n","      <th>difficulty_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>CBSE&gt;&gt;Nursery&gt;&gt;Environmental Science&gt;&gt;Common V...</td>\n","      <td>Write down the names of some common vegetable...</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>CBSE&gt;&gt;XII&gt;&gt;Physics&gt;&gt;Physics : Part - II&gt;&gt;Atoms</td>\n","      <td>Name the series of hydrogen atom which lies i...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ICSE OLD&gt;&gt;XI&gt;&gt;Political Science&gt;&gt;State, Govern...</td>\n","      <td>Which of the following is not the element of ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Maharashtra New&gt;&gt;VII&gt;&gt;General Science&gt;&gt;Static ...</td>\n","      <td>The process of electrically charging an objec...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Tamil Nadu&gt;&gt;IX&gt;&gt;Science&gt;&gt;Physics&gt;&gt;Measurement&gt;...</td>\n","      <td>The mass of an object is measured in kilogram...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4572</th>\n","      <td>ICSE OLD&gt;&gt;VIII&gt;&gt;Biology&gt;&gt;Nervous System And Se...</td>\n","      <td>Which of the following is the first cranial n...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4573</th>\n","      <td>CBSE&gt;&gt;VII&gt;&gt;Computer Science&gt;&gt;Advance features ...</td>\n","      <td>To ungroup the worksheets: Right-click on any...</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4574</th>\n","      <td>CBSE&gt;&gt;VIII&gt;&gt;Science&gt;&gt;Chemical Effects of Elect...</td>\n","      <td>After passing electricity through a solution ...</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4575</th>\n","      <td>CLSP&gt;&gt;Stage 9&gt;&gt;Science&gt;&gt;Chemistry&gt;&gt;Material pr...</td>\n","      <td>Identify the scientists who gave the “plum-pu...</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4576</th>\n","      <td>AP&gt;&gt;VIII&gt;&gt;Physical Science&gt;&gt;Physical Science (...</td>\n","      <td>What do you understand by the term static ele...</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4577 rows × 4 columns</p>\n","</div>"],"text/plain":["                                         board_syllabus  ... difficulty_label\n","0     CBSE>>Nursery>>Environmental Science>>Common V...  ...                2\n","1        CBSE>>XII>>Physics>>Physics : Part - II>>Atoms  ...                1\n","2     ICSE OLD>>XI>>Political Science>>State, Govern...  ...                0\n","3     Maharashtra New>>VII>>General Science>>Static ...  ...                1\n","4     Tamil Nadu>>IX>>Science>>Physics>>Measurement>...  ...                1\n","...                                                 ...  ...              ...\n","4572  ICSE OLD>>VIII>>Biology>>Nervous System And Se...  ...                1\n","4573  CBSE>>VII>>Computer Science>>Advance features ...  ...                0\n","4574  CBSE>>VIII>>Science>>Chemical Effects of Elect...  ...                2\n","4575  CLSP>>Stage 9>>Science>>Chemistry>>Material pr...  ...                0\n","4576  AP>>VIII>>Physical Science>>Physical Science (...  ...                1\n","\n","[4577 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bovSLwB26TRn","outputId":"c308c0d7-9014-4078-ac73-b80fe5db7a96"},"source":["test[\"question_answer\"].values"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([' Write down the names of some common vegetables. Answer may vary Probable answer – Names of some common vegetables are potato, onion, tomato and carrot. ',\n","       ' Name the series of hydrogen atom which lies in the U.V region. Lyman series lies in the U.V region. ',\n","       ' Which of the following is not the element of an association? Relationships are abstract Each association has elements 1) a group of people, 2) voluntary Membership, 3) shared and common interests or needs as the basis, 4) some set of objective goals which are to be achieved collectively by all the members, 5) a voluntary organisation, and 6) co-operation among the members objectives pooled resources for funds needed for action.',\n","       ...,\n","       ' After passing electricity through a solution the change that takes place is a chemical change Physical changes are those changes that do not result in the production of a new substance whereas a chemical change involves the production of a new substance. For example: When electricity is passed in a solution containing water, bubbles of hydrogen and oxygen are formed.',\n","       ' Identify the scientists who gave the “plum-pudding” model of the atom. J. J. Thomson The &ldquo;plum-pudding&rdquo; model of the atom was developed by the J. J Thomson. He compared his model used for describing the structure of atom with a plum pudding in which negatively charged electrons were surrounded by a positively charged &lsquo;pudding&rsquo;.',\n","       ' What do you understand by the term static electricity? It is the electricity developed due to stationary electric charges on the body. '],\n","      dtype=object)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":402},"id":"P8xfcPLU5sR5","outputId":"f6b05718-29b4-424b-deb1-ebef51d254f9"},"source":["\n","import re\n","\n","test[\"question_answer\"] = test[\"question_answer\"].apply(lambda x : clean_sentence(x))\n","test"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>board_syllabus</th>\n","      <th>question_answer</th>\n","      <th>skill_label</th>\n","      <th>difficulty_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>CBSE&gt;&gt;Nursery&gt;&gt;Environmental Science&gt;&gt;Common V...</td>\n","      <td>Write down the names of some common vegetable...</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>CBSE&gt;&gt;XII&gt;&gt;Physics&gt;&gt;Physics : Part - II&gt;&gt;Atoms</td>\n","      <td>Name the series of hydrogen atom which lies i...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ICSE OLD&gt;&gt;XI&gt;&gt;Political Science&gt;&gt;State, Govern...</td>\n","      <td>Which of the following is not the element of ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Maharashtra New&gt;&gt;VII&gt;&gt;General Science&gt;&gt;Static ...</td>\n","      <td>The process of electrically charging an objec...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Tamil Nadu&gt;&gt;IX&gt;&gt;Science&gt;&gt;Physics&gt;&gt;Measurement&gt;...</td>\n","      <td>The mass of an object is measured in kilogram...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4572</th>\n","      <td>ICSE OLD&gt;&gt;VIII&gt;&gt;Biology&gt;&gt;Nervous System And Se...</td>\n","      <td>Which of the following is the first cranial n...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4573</th>\n","      <td>CBSE&gt;&gt;VII&gt;&gt;Computer Science&gt;&gt;Advance features ...</td>\n","      <td>To ungroup the worksheets: Right-click on any...</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4574</th>\n","      <td>CBSE&gt;&gt;VIII&gt;&gt;Science&gt;&gt;Chemical Effects of Elect...</td>\n","      <td>After passing electricity through a solution ...</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4575</th>\n","      <td>CLSP&gt;&gt;Stage 9&gt;&gt;Science&gt;&gt;Chemistry&gt;&gt;Material pr...</td>\n","      <td>Identify the scientists who gave the “plum-pu...</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4576</th>\n","      <td>AP&gt;&gt;VIII&gt;&gt;Physical Science&gt;&gt;Physical Science (...</td>\n","      <td>What do you understand by the term static ele...</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4577 rows × 4 columns</p>\n","</div>"],"text/plain":["                                         board_syllabus  ... difficulty_label\n","0     CBSE>>Nursery>>Environmental Science>>Common V...  ...                2\n","1        CBSE>>XII>>Physics>>Physics : Part - II>>Atoms  ...                1\n","2     ICSE OLD>>XI>>Political Science>>State, Govern...  ...                0\n","3     Maharashtra New>>VII>>General Science>>Static ...  ...                1\n","4     Tamil Nadu>>IX>>Science>>Physics>>Measurement>...  ...                1\n","...                                                 ...  ...              ...\n","4572  ICSE OLD>>VIII>>Biology>>Nervous System And Se...  ...                1\n","4573  CBSE>>VII>>Computer Science>>Advance features ...  ...                0\n","4574  CBSE>>VIII>>Science>>Chemical Effects of Elect...  ...                2\n","4575  CLSP>>Stage 9>>Science>>Chemistry>>Material pr...  ...                0\n","4576  AP>>VIII>>Physical Science>>Physical Science (...  ...                1\n","\n","[4577 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sQ_zCeR06Z4P","outputId":"fdb5b135-552c-4316-816b-d317049198aa"},"source":["test[\"question_answer\"].values"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([' Write down the names of some common vegetables. Answer may vary Probable answer – Names of some common vegetables are potato, onion, tomato and carrot.',\n","       ' Name the series of hydrogen atom which lies in the U.V region. Lyman series lies in the U.V region.',\n","       ' Which of the following is not the element of an association? Relationships are abstract Each association has elements 1) a group of people, 2) voluntary Membership, 3) shared and common interests or needs as the basis, 4) some set of objective goals which are to be achieved collectively by all the members, 5) a voluntary organisation, and 6) co-operation among the members objectives pooled resources for funds needed for action.',\n","       ...,\n","       ' After passing electricity through a solution the change that takes place is a chemical change Physical changes are those changes that do not result in the production of a new substance whereas a chemical change involves the production of a new substance. For example: When electricity is passed in a solution containing water, bubbles of hydrogen and oxygen are formed.',\n","       ' Identify the scientists who gave the “plum-pudding” model of the atom. J. J. Thomson The &ldquo;plum-pudding&rdquo; model of the atom was developed by the J. J Thomson. He compared his model used for describing the structure of atom with a plum pudding in which negatively charged electrons were surrounded by a positively charged &lsquo;pudding&rsquo;.',\n","       ' What do you understand by the term static electricity? It is the electricity developed due to stationary electric charges on the body.'],\n","      dtype=object)"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["558606ca009b4d5ca5019d7806dd842c","32bdb2a87bdd41cbaf42fb2bfb98f3e2","96a17bb0760b49f3812cbf51d3548f8b","ed75ccb4ccd140ae82ed5d9e3b3109cb","1368c7cd17d943c5908ea6fbdadca7ba","84abbb525b2840fabb68450669f40aab","2024b3b773084d4a93e45e00eb7781af","08690340ac1f452980e240f733250a54"]},"id":"FIrS5sxE3kgk","outputId":"fddc617f-8af3-49ab-c205-962af875cc15"},"source":["from transformers import BertTokenizer\n","\n","# Load the BERT tokenizer.\n","print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loading BERT tokenizer...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"558606ca009b4d5ca5019d7806dd842c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wp64MkNB3kg1"},"source":["def get_labels(prediction):\n","    predicted_label =  LE.inverse_transform([prediction])\n","    return predicted_label[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"uPgTmJPS3kg4","outputId":"364778ba-b451-4cad-e16b-2506c8e75dca"},"source":["import joblib\n","from sklearn.preprocessing import LabelEncoder\n","\n","LE = LabelEncoder()\n","LE = joblib.load('label_encoder_difficulty_Lstm')\n","\n","get_labels(0)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Difficult'"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":402},"id":"I_UpqLMG3kg9","outputId":"be3dc8d1-3134-4843-8fb1-b1f4ab26a2c7"},"source":["final_data"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>board_syllabus</th>\n","      <th>question_answer</th>\n","      <th>skill_label</th>\n","      <th>difficulty_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Raj English&gt;&gt;XII&gt;&gt;Biology&gt;&gt;Domestication, Cult...</td>\n","      <td>Among the following, freshwater fish is rohu ...</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Maharashtra New&gt;&gt;VI&gt;&gt;General Science&gt;&gt;Sound&gt;&gt;P...</td>\n","      <td>Which of the following statement is true? Sou...</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ICSE OLD&gt;&gt;XI&gt;&gt;Computer Science&gt;&gt;Functions&gt;&gt;Con...</td>\n","      <td>The process of using multiple constructors wi...</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>CBSE&gt;&gt;VI&gt;&gt;Science&gt;&gt;Separation of Substances&gt;&gt;S...</td>\n","      <td>Sieving is based on the difference in the siz...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>AP&gt;&gt;X&gt;&gt;Biology&gt;&gt;Excretion - The Wastage Dispos...</td>\n","      <td>The removal of toxic and unwanted waste subst...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>39124</th>\n","      <td>CAPS(South Africa)&gt;&gt;Grade 7&gt;&gt;Natural Sciences&gt;...</td>\n","      <td>How heat loss problems are prevented by birds...</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>39125</th>\n","      <td>CBSE&gt;&gt;X&gt;&gt;Science&gt;&gt;Metals and Non-Metal</td>\n","      <td>Give reasons why copper is used to make hot w...</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>39126</th>\n","      <td>CBSE&gt;&gt;VII&gt;&gt;Science&gt;&gt;Motion and Time</td>\n","      <td>The horizontal line in the graph is denoted as...</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>39127</th>\n","      <td>Tamil Nadu&gt;&gt;VI&gt;&gt;Science&gt;&gt;Term 1&gt;&gt;Physics&gt;&gt;Forc...</td>\n","      <td>SI unit of force is newton The SI unit of for...</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>39128</th>\n","      <td>Tamil Nadu&gt;&gt;VIII&gt;&gt;Science&gt;&gt;Term 1&gt;&gt;Physics&gt;&gt;Fo...</td>\n","      <td>In machines sliding frictions is replaced to ...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>39129 rows × 4 columns</p>\n","</div>"],"text/plain":["                                          board_syllabus  ... difficulty_label\n","0      Raj English>>XII>>Biology>>Domestication, Cult...  ...                0\n","1      Maharashtra New>>VI>>General Science>>Sound>>P...  ...                2\n","2      ICSE OLD>>XI>>Computer Science>>Functions>>Con...  ...                0\n","3      CBSE>>VI>>Science>>Separation of Substances>>S...  ...                1\n","4      AP>>X>>Biology>>Excretion - The Wastage Dispos...  ...                1\n","...                                                  ...  ...              ...\n","39124  CAPS(South Africa)>>Grade 7>>Natural Sciences>...  ...                1\n","39125             CBSE>>X>>Science>>Metals and Non-Metal  ...                2\n","39126                CBSE>>VII>>Science>>Motion and Time  ...                1\n","39127  Tamil Nadu>>VI>>Science>>Term 1>>Physics>>Forc...  ...                2\n","39128  Tamil Nadu>>VIII>>Science>>Term 1>>Physics>>Fo...  ...                1\n","\n","[39129 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"MHdVe13Fr3vt"},"source":["new_data = final_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AkyM7gqv3khI"},"source":["question_answer = new_data[\"question_answer\"].values\n","categories = new_data[\"difficulty_label\"].values\n","skill_category = new_data[\"skill_label\"].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ndpw0p1SBUoZ","outputId":"25321d59-02d1-4a8e-d5f7-0646846baa63"},"source":["question_answer"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([' Among the following, freshwater fish is rohu Rohu is a fresh water fish. Other common freshwater fish are catla, common carp.',\n","       ' Which of the following statement is true? Sound requires a medium for propagation. Sound travels through a medium (solid, liquid or gas). It cannot travel through vacuum.',\n","       ' The process of using multiple constructors with the same name but with different parameters is known as: Constructor overloading Constructor overloading is a technique in Java in which a class can have any number of constructors that differ in parameter lists.',\n","       ...,\n","       'The horizontal line in the graph is denoted as the X-axis. The horizontal line points in the horizontal direction and is denoted as the X-axis in the graph.',\n","       ' SI unit of force is newton The SI unit of force is Newton (N), named after famous scientist Isaac Newton who discovered force of gravitation.',\n","       ' In machines sliding frictions is replaced to rolling by use of ball bearings Ball bearing roll to produce rolling;friction.'],\n","      dtype=object)"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"tFkS_H_83khL","outputId":"0e876706-9e19-4c3d-a82a-ba0adf1f522f"},"source":["question_answer[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["' Among the following, freshwater fish is rohu Rohu is a fresh water fish. Other common freshwater fish are catla, common carp.'"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ian7gSDE3khR","outputId":"32922b42-55e7-49f5-a389-8b5cc19553a8"},"source":["len(categories)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["39129"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y_ZeuHc63khU","outputId":"02803395-1d70-41f5-ea3d-93ff3be1e690"},"source":["input_ids = []\n","attention_masks = []\n","\n","for sent in question_answer:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 128,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        truncation=True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', question_answer[0])\n","print('Token IDs:', input_ids[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Original:   Among the following, freshwater fish is rohu Rohu is a fresh water fish. Other common freshwater fish are catla, common carp.\n","Token IDs: tensor([  101,  2426,  1996,  2206,  1010, 12573,  3869,  2003, 20996,  6979,\n","        20996,  6979,  2003,  1037,  4840,  2300,  3869,  1012,  2060,  2691,\n","        12573,  3869,  2024,  4937,  2721,  1010,  2691, 29267,  1012,   102,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iVGvVZb13kha","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d438ebca-fa21-4ec3-c82d-094e3e06d493"},"source":["print('Original: ', len(question_answer[1]))\n","print('Token IDs:', len(input_ids[1]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Original:  171\n","Token IDs: 128\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5nmRiaBbA9OH"},"source":["val_text = val[\"question_answer\"].values\n","val_labels = val[\"difficulty_label\"].values\n","val_skill_labels = val[\"skill_label\"].values\n","test_text = test[\"question_answer\"].values\n","test_labels = test[\"difficulty_label\"].values\n","test_skill_labels = test[\"skill_label\"].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E-s_H1WdyvCw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6ab99d30-14fa-4ac5-8ccf-208f145ec79a"},"source":["test_labels"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2, 1, 0, ..., 2, 0, 1])"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"YF-mKCC1CUjD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b093d893-9845-42ba-f8df-a9d9e28be3b3"},"source":["val_labels"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 2, 2, ..., 0, 1, 0])"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"sOQuDahhAzOO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9ae96220-86d7-43d9-c230-3b23423ba26b"},"source":["val_input_ids = []\n","val_attention_masks = []\n","\n","for sent in val_text:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 128,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        truncation=True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    val_input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    val_attention_masks.append(encoded_dict['attention_mask'])\n","# Convert the lists into tensors.\n","val_input_ids = torch.cat(val_input_ids, dim=0)\n","val_attention_masks = torch.cat(val_attention_masks, dim=0)\n","\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', val_text[0])\n","print('Token IDs:', val_attention_masks[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Original:   Name the two types of protein from which silk is made. Sericin and fibroin \n","Token IDs: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Siskea7qDLUG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1b3d5b92-d4d5-4efd-cb02-27be01225e30"},"source":["print('Original: ', val_text[1])\n","print('Token IDs:', val_input_ids[1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Original:   Give reasons: (i) Thermocol is used for the packing of delicate items. (ii) Name two diseases that may develop in people working in thermocol industries. (i) Thermocol is a good shock-absorber, therefore, it is used for packing of delicate items. (ii) People working in thermocol industries may suffer from blood cancer such as leukemia and lymphoma or have problems in eyes and respiratory system. \n","Token IDs: tensor([  101,  2507,  4436,  1024,  1006,  1045,  1007,  1996, 10867, 24163,\n","         2140,  2003,  2109,  2005,  1996, 14743,  1997, 10059,  5167,  1012,\n","         1006,  2462,  1007,  2171,  2048,  7870,  2008,  2089,  4503,  1999,\n","         2111,  2551,  1999,  1996, 10867, 24163,  2140,  6088,  1012,  1006,\n","         1045,  1007,  1996, 10867, 24163,  2140,  2003,  1037,  2204,  5213,\n","         1011, 16888,  2121,  1010,  3568,  1010,  2009,  2003,  2109,  2005,\n","        14743,  1997, 10059,  5167,  1012,  1006,  2462,  1007,  2111,  2551,\n","         1999,  1996, 10867, 24163,  2140,  6088,  2089,  9015,  2013,  2668,\n","         4456,  2107,  2004, 25468,  1998,  1048, 24335,  8458,  9626,  2030,\n","         2031,  3471,  1999,  2159,  1998, 16464,  2291,  1012,   102,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"irMTimjf3khd"},"source":["labels = torch.tensor(categories)\n","skill_category = torch.tensor(skill_category)\n","val_labels = torch.tensor(val_labels)\n","val_skill_labels = torch.tensor(val_skill_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PdOgWP_LKTHi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b8bc8527-549b-42ab-9f85-1a36dee7c847"},"source":["val_labels"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0, 2, 2,  ..., 0, 1, 0])"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"OJJ0I8Ud3khf","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"bdb7f2ff-61ed-440b-8a8d-6c18d97abbfc"},"source":["get_labels(1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Easy'"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"Z1ZAbQRfiG63","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1d6825bf-fcf1-4f45-ba79-d261cc9ea9c2"},"source":["len(set(final_data[\"question_answer\"].values).intersection(val[\"question_answer\"].values))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"BNDW74Ny3khj","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a44ddb26-481c-4eb7-8399-665ed35cd756"},"source":["num_classes = len(list(set(categories)))\n","list(set(categories))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0, 1, 2]"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"jOBErYPYEUrl","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c0f1aa9a-02b8-4644-8311-999118a2116b"},"source":["skill_label_count = len(list(set(new_data[\"skill_label\"].values)))\n","skill_label_count"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"jYFIJaRPE20c","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1a58b63e-f74e-4317-8f06-72c975f509fd"},"source":["list(set(new_data[\"skill_label\"].values))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0, 1, 2, 3, 4]"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"ZmaLk5Ab3khl"},"source":["from torch.utils.data import TensorDataset, random_split\n","# train_poincare_tensor = torch.tensor(poincare_embeddings_final,dtype=torch.float)\n","# difficulty_tensor = torch.tensor(difficulty_level_vectors,dtype=torch.float)\n","# Combine the training inputs into a TensorDataset.\n","dataset = TensorDataset(input_ids, attention_masks, labels,skill_category)\n","val_dataset = TensorDataset(val_input_ids, val_attention_masks,val_labels,val_skill_labels) \n","# Create a 90-10train-validation split.\n","\n","# Calculate the number of samples to include in each set.\n","# train_size = int(0.90 * len(dataset))\n","# val_size = len(dataset) - train_size\n","\n","# # Divide the dataset by randomly selecting samples.\n","# train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","# print('{:>5,} training samples'.format(train_size))\n","# # print('{:>5,} validation samples'.format(val_size))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D_lTinod3kho"},"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","batch_size = 32\n","train_dataloader = DataLoader(\n","            dataset,  # The training samples.\n","            sampler = RandomSampler(dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), \n","            batch_size = batch_size \n","        )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_2tmAMlw3khr"},"source":["from transformers import BertModel, AdamW, BertConfig\n","\n","# # Loads BertForSequenceClassification, the pretrained BERT model with a single \n","# model = BertModel.from_pretrained(\n","#     \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n","# )\n","\n","# # Tell pytorch to run this model on the GPU.\n","# model.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DkDmTZhVChN6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3f8ea467-2f6d-43ec-daf2-da26f86fabcb"},"source":["set(test[\"question_answer\"].values).intersection(set(final_data[\"question_answer\"].values))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["set()"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"id":"-AX-SagSE8CS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f00322ff-9566-4453-d854-86704761e0e5"},"source":["num_classes"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"aHmQK0OP9mv-"},"source":["from torch import nn\n","# for plottign attentions\n","class MultiClassClassifier(nn.Module):\n","    def __init__(self, bert_model_path, labels_count,skill_label_count, hidden_dim=768, mlp_dim=500, extras_dim=140, dropout=0.1, freeze_bert=False):\n","        super().__init__()\n","\n","        self.bert = BertModel.from_pretrained(bert_model_path,output_hidden_states=True,output_attentions=True)\n","        self.dropout = nn.Dropout(dropout)\n","        self.mlp = nn.Sequential(\n","            nn.Linear(hidden_dim , mlp_dim),\n","            nn.ReLU(),\n","            # nn.Linear(mlp_dim, mlp_dim),\n","            # nn.ReLU(),\n","            # nn.Linear(mlp_dim, mlp_dim),\n","            # nn.ReLU(),            \n","            nn.Linear(mlp_dim, labels_count)\n","        )\n","        self.mlp2 = nn.Sequential(\n","            nn.Linear(hidden_dim , mlp_dim),\n","            nn.ReLU(),         \n","            nn.Linear(mlp_dim, skill_label_count)\n","        )\n","        # self.softmax = nn.LogSoftmax(dim=1)\n","        if freeze_bert:\n","            print(\"Freezing layers\")\n","            for param in self.bert.parameters():\n","                param.requires_grad = False\n","\n","    def forward(self, tokens, masks):\n","        _, pooled_output,hidden_states,attentions = self.bert(tokens, attention_mask=masks)\n","        dropout_output = self.dropout(pooled_output)\n","        concat_output = dropout_output\n","        mlp_output = self.mlp(concat_output)\n","        skill_output = self.mlp2(concat_output)\n","        # proba = self.sigmoid(mlp_output)\n","        # proba = self.softmax(mlp_output)\n","\n","        return mlp_output,skill_output,attentions"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nQ9_trOX96Tv"},"source":["from torch import nn\n","class SkillClassifier(nn.Module):\n","    def __init__(self, bert_model_path, labels_count, hidden_dim=768, mlp_dim=500, extras_dim=140, dropout=0.1, freeze_bert=False):\n","        super().__init__()\n","\n","        self.bert = BertModel.from_pretrained(bert_model_path,output_hidden_states=True,output_attentions=True)\n","        self.dropout = nn.Dropout(dropout)\n","        self.mlp = nn.Sequential(\n","            nn.Linear(hidden_dim , mlp_dim),\n","            nn.ReLU(),\n","            # nn.Linear(mlp_dim, mlp_dim),\n","            # nn.ReLU(),\n","            # nn.Linear(mlp_dim, mlp_dim),\n","            # nn.ReLU(),            \n","            nn.Linear(mlp_dim, 5)\n","        )\n","        # self.softmax = nn.LogSoftmax(dim=1)\n","        if freeze_bert:\n","            print(\"Freezing layers\")\n","            for param in self.bert.parameters():\n","                param.requires_grad = False\n","\n","    def forward(self, tokens, masks):\n","        _, pooled_output,_,_ = self.bert(tokens, attention_mask=masks)\n","        dropout_output = self.dropout(pooled_output)\n","        concat_output = dropout_output\n","        mlp_output = self.mlp(concat_output)\n","        # proba = self.sigmoid(mlp_output)\n","        # proba = self.softmax(mlp_output)\n","\n","        return mlp_output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7uqkkw379_WB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5ef7e6b9-2c7e-45c2-e950-a25b8066fbaf"},"source":["skill_model = SkillClassifier('bert-base-uncased',num_classes, 768,500,140,dropout=0.1,freeze_bert=False)\n","skill_model.load_state_dict(torch.load(\"qdiff_skill_only_prediction_bert/model_weights\"))\n","skill_model.cuda()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SkillClassifier(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (mlp): Sequential(\n","    (0): Linear(in_features=768, out_features=500, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=500, out_features=5, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":53}]},{"cell_type":"code","metadata":{"id":"ZAgBxwiDbcIj"},"source":["from torch import nn\n","\n","\n","class Attention(nn.Module):\n","  def __init__(self,vector_1_dim,vector_2_dim):\n","    super(Attention, self).__init__()\n","    self.Weights = nn.Parameter(torch.rand(vector_2_dim,vector_1_dim))\n","    self.bias = nn.Parameter(torch.zeros(1))\n","\n","  def forward(self,vector_1,vector_2):\n","    #(batch_size,vector_2_dim,vector_1_dim)\n","    weights = self.Weights.repeat(vector_2.size(0),1,1)\n","    vector_1 = vector_1.unsqueeze(-1)  # (batch_size,vector_2_dim,vector_1_dim)\n","    weights = weights.matmul(vector_1) # results in (batch_size,vector_2_dim,1)\n","    weights = weights.repeat(vector_2.size(1),1,1,1).transpose(0,1)\n","    vector_2 = vector_2.unsqueeze(-2)\n","    attention_weights = torch.tanh(vector_2.matmul(weights).squeeze() + self.bias) # batch_size, vector_2_dim.size(0)\n","    if len(attention_weights.shape) ==1:\n","      attention_weights = attention_weights.squeeze()\n","      attention_weights = attention_weights.reshape(1,-1)\n","    attention_weights = attention_weights.squeeze()\n","    # print(\"torch.exp(attention_weights)\",torch.exp(attention_weights).shape,attention_weights.shape,torch.exp(attention_weights).sum(dim=1).shape)\n","    attention_weights = torch.exp(attention_weights)/ torch.exp(attention_weights).sum(dim=1,keepdim=True)\n","\n","    return attention_weights\n","\n","# bloom interactive attention\n","class MultiClassClassifier(nn.Module):\n","    def __init__(self, bert_model_path, labels_count,skill_label_count, hidden_dim=768, mlp_dim=500, extras_dim=140, dropout=0.1, freeze_bert=False):\n","        super().__init__()\n","\n","        self.bert = BertModel.from_pretrained(bert_model_path,output_hidden_states=True,output_attentions=True)\n","\n","        self.skill_bert = skill_model\n","        self.dropout = nn.Dropout(dropout)\n","        self.bloom_attention = Attention(768, 768)\n","\n","        self.mlp = nn.Sequential(\n","            nn.Linear(hidden_dim , mlp_dim),\n","            nn.ReLU(),\n","            # nn.Linear(mlp_dim, mlp_dim),\n","            # nn.ReLU(),\n","            # nn.Linear(mlp_dim, mlp_dim),\n","            # nn.ReLU(),            \n","            nn.Linear(mlp_dim, labels_count)\n","        )\n","        self.mlp2 = nn.Sequential(  \n","            nn.Linear(hidden_dim , mlp_dim),\n","            nn.ReLU(),         \n","            nn.Linear(mlp_dim, skill_label_count)\n","        )\n","        # self.softmax = nn.LogSoftmax(dim=1)\n","        if freeze_bert:\n","            print(\"Freezing layers\")\n","            for param in self.bert.parameters():\n","                param.requires_grad = False\n","\n","    def forward(self, tokens, masks):\n","        _, pooled_output,hidden_states,attentions = self.bert(tokens, attention_mask=masks)\n","        dropout_output = self.dropout(pooled_output)\n","        concat_output = dropout_output\n","\n","        # mlp_output = self.mlp(concat_output)\n","        skill_output_probas = self.skill_bert(tokens,masks)\n","        skill_output = torch.argmax(skill_output_probas,axis=1).cpu().numpy()\n","        skill_output = LE_skill.inverse_transform(skill_output)\n","        skill_input_ids = []\n","        skill_attention_masks = []\n","        for skill_text in skill_output:\n","          encoded_skill_output = tokenizer.encode_plus(\n","                          skill_text,                      # Sentence to encode.\n","                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                          max_length = 128,           # Pad & truncate all sentences.\n","                          pad_to_max_length = True,\n","                          truncation=True,\n","                          return_attention_mask = True,   # Construct attn. masks.\n","                          return_tensors = 'pt',     # Return pytorch tensors.\n","                    )\n","          skill_input_ids.append(encoded_skill_output['input_ids'])\n","          skill_attention_masks.append(encoded_skill_output['attention_mask'])\n","        skill_input_ids = torch.cat(skill_input_ids,dim=0).cuda()\n","        skill_attention_masks = torch.cat(skill_attention_masks,dim=0).cuda()\n","        _,_,hidden_states_skill,_ = self.skill_bert.bert(skill_input_ids,skill_attention_masks)\n","\n","        skill_hidden_averaged =  torch.sum(hidden_states_skill[12],dim=1)/hidden_states_skill[12].shape[1]\n","\n","        bloom_attention_weights = self.bloom_attention(skill_hidden_averaged, hidden_states[12])\n","\n","        bloom_attention_weights = bloom_attention_weights.unsqueeze(-2)\n","        # print(\"context_attention_weights\",context_attention_weights.shape,context_out.shape)\n","        input_attended_vector = bloom_attention_weights.matmul(hidden_states[12]).squeeze()\n","\n","        mlp_output = self.mlp(input_attended_vector)\n","\n","        # print(\"bloom attention weights\", bloom_attention_weights.shape)\n","        # print(\"_hidden_states\",hidden_states_skill[12].shape, hidden_states[12].shape,skill_hidden_averaged.shape)\n","\n","        # proba = self.sigmoid(mlp_output)\n","        # proba = self.softmax(mlp_output)\n","\n","        return mlp_output,skill_output_probas"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aGU0MvlQ97pt","colab":{"base_uri":"https://localhost:8080/"},"outputId":"565a85ec-f746-401d-8e5d-92326c514350"},"source":["model = MultiClassClassifier('bert-base-uncased',num_classes, skill_label_count,768,500,140,dropout=0.1,freeze_bert=False)\n","model.load_state_dict(torch.load(\"model_bert_multi_task_interactive_pre_trained_skill_bert/model_weights\"))\n","model.cuda()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MultiClassClassifier(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (skill_bert): SkillClassifier(\n","    (bert): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (mlp): Sequential(\n","      (0): Linear(in_features=768, out_features=500, bias=True)\n","      (1): ReLU()\n","      (2): Linear(in_features=500, out_features=5, bias=True)\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (bloom_attention): Attention()\n","  (mlp): Sequential(\n","    (0): Linear(in_features=768, out_features=500, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=500, out_features=3, bias=True)\n","  )\n","  (mlp2): Sequential(\n","    (0): Linear(in_features=768, out_features=500, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=500, out_features=5, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":79}]},{"cell_type":"code","metadata":{"id":"awQ2Y9Jb3kht"},"source":["optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Ys-M4-e3khv"},"source":["from transformers import get_linear_schedule_with_warmup\n","\n","\n","epochs = 20\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","total_steps = len(train_dataloader) * epochs\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EenVUl0iDyc1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QrYqErOD3khx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e2d35d9c-0d6f-4e68-d99c-c64e28e9c092"},"source":["len(train_dataloader) "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1223"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"code","metadata":{"id":"EWVSE9LM3kh0","colab":{"base_uri":"https://localhost:8080/"},"outputId":"daaf56ad-c6d5-45b7-aad8-bba2dbb6ffc1"},"source":["1935 * 32"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["61920"]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"code","metadata":{"id":"rcvxVVi63kh3"},"source":["scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GUw3zm6g3kh5"},"source":["import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ta6zfUTa3kh7"},"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GFq9gd5kQSHb"},"source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y-rKyCrwE7N4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"734044db-e019-4d3f-dfdd-aaaf2a7057bc"},"source":["# model.to(device)\n","model"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MultiClassClassifier(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (skill_bert): SkillClassifier(\n","    (bert): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (mlp): Sequential(\n","      (0): Linear(in_features=768, out_features=500, bias=True)\n","      (1): ReLU()\n","      (2): Linear(in_features=500, out_features=5, bias=True)\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (bloom_attention): Attention()\n","  (mlp): Sequential(\n","    (0): Linear(in_features=768, out_features=500, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=500, out_features=3, bias=True)\n","  )\n","  (mlp2): Sequential(\n","    (0): Linear(in_features=768, out_features=500, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=500, out_features=5, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":64}]},{"cell_type":"code","metadata":{"id":"1NuM6yRptFtS"},"source":["for param in model.bert.encoder.layer[0:5].parameters():\n","    param.requires_grad=False\n","for param in model.bert.embeddings.parameters():\n","    param.requires_grad=False\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t85MA9XN9eVH"},"source":["for param in model.skill_bert.bert.encoder.layer.parameters():\n","    param.requires_grad=False\n","for param in model.skill_bert.bert.embeddings.parameters():\n","    param.requires_grad=False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a_nmuoSgQ5t3"},"source":["class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'checkpoint.pt'\n","            trace_func (function): trace print function.\n","                            Default: print            \n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","        self.trace_func = trace_func\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E1rDO58zMfc8"},"source":["loss_func = nn.CrossEntropyLoss()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JNFL0393HQZc"},"source":[""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6LhAy2hZ3kh9","outputId":"628d2a24-803a-4866-f316-eb8f3271180d"},"source":["import random\n","import numpy as np\n","\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# We'll store a number of quantities such as training and validation loss, \n","# validation accuracy, and timings.\n","training_stats = []\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","early_stopping = EarlyStopping(patience=2, verbose=True)\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_accuracy = 0\n","    total_train_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questimport gensim.downloader as api\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels\n","         \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        # b_poincare = batch[2].to(device)\n","        # b_difficulty = batch[3].to(device)\n","        b_labels = batch[2].to(device)\n","        skill_labels = batch[3].to(device)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        probas, skill_probs = model(b_input_ids,b_input_mask)\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        loss_1 = loss_func(probas, b_labels)\n","        skill_loss = loss_func(skill_probs,skill_labels)\n","        loss = loss_1 + skill_loss\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        # torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        # scheduler.step()\n","        logits = probas.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        total_train_accuracy += flat_accuracy(logits, label_ids)\n","    avg_train_accuracy = total_train_accuracy / len(train_dataloader)\n","    print(\" Train Accuracy: {0:.2f}\".format(avg_train_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader) \n","\n","            \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using \n","        # the `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        # b_poincare = batch[2].to(device)\n","        # b_difficulty = batch[3].to(device)\n","        b_labels = batch[2].to(device)\n","        skill_labels = batch[3].to(device)\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","\n","          logits, skill_logits = model(b_input_ids,b_input_mask)\n","            \n","        # Accumulate the validation loss.\n","        loss_1 = loss_func(logits, b_labels)\n","        skill_loss = loss_func(skill_logits,skill_labels)\n","        loss = loss_1 + skill_loss\n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    early_stopping(avg_val_loss, model)\n","    if early_stopping.early_stop:\n","      print(\"Early stopping\")\n","      break    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","    output_dir = 'model_bert_multi_task_interactive_pre_trained_skill_bert/'\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    print(\"Saving model to %s\" % output_dir)\n","    tokenizer.save_pretrained(output_dir)\n","    torch.save(model.state_dict(), os.path.join(output_dir, 'model_weights'))\n","\n","    !rm -rf \"/content/drive/My Drive/research_skill_name_prediction/model_bert_multi_task_interactive_pre_trained_skill_bert\"\n","    !mv model_bert_multi_task_interactive_pre_trained_skill_bert \"/content/drive/My Drive/research_skill_name_prediction/\"\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 20 ========\n","Training...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["  Batch    40  of  1,223.    Elapsed: 0:00:38.\n","  Batch    80  of  1,223.    Elapsed: 0:01:19.\n","  Batch   120  of  1,223.    Elapsed: 0:01:59.\n","  Batch   160  of  1,223.    Elapsed: 0:02:39.\n","  Batch   200  of  1,223.    Elapsed: 0:03:19.\n","  Batch   240  of  1,223.    Elapsed: 0:03:59.\n","  Batch   280  of  1,223.    Elapsed: 0:04:39.\n","  Batch   320  of  1,223.    Elapsed: 0:05:19.\n","  Batch   360  of  1,223.    Elapsed: 0:05:59.\n","  Batch   400  of  1,223.    Elapsed: 0:06:40.\n","  Batch   440  of  1,223.    Elapsed: 0:07:20.\n","  Batch   480  of  1,223.    Elapsed: 0:08:00.\n","  Batch   520  of  1,223.    Elapsed: 0:08:40.\n","  Batch   560  of  1,223.    Elapsed: 0:09:20.\n","  Batch   600  of  1,223.    Elapsed: 0:10:00.\n","  Batch   640  of  1,223.    Elapsed: 0:10:40.\n","  Batch   680  of  1,223.    Elapsed: 0:11:20.\n","  Batch   720  of  1,223.    Elapsed: 0:12:00.\n","  Batch   760  of  1,223.    Elapsed: 0:12:40.\n","  Batch   800  of  1,223.    Elapsed: 0:13:20.\n","  Batch   840  of  1,223.    Elapsed: 0:14:00.\n","  Batch   880  of  1,223.    Elapsed: 0:14:40.\n","  Batch   920  of  1,223.    Elapsed: 0:15:20.\n","  Batch   960  of  1,223.    Elapsed: 0:16:00.\n","  Batch 1,000  of  1,223.    Elapsed: 0:16:40.\n","  Batch 1,040  of  1,223.    Elapsed: 0:17:20.\n","  Batch 1,080  of  1,223.    Elapsed: 0:18:00.\n","  Batch 1,120  of  1,223.    Elapsed: 0:18:40.\n","  Batch 1,160  of  1,223.    Elapsed: 0:19:20.\n","  Batch 1,200  of  1,223.    Elapsed: 0:20:00.\n"," Train Accuracy: 0.55\n","\n","  Average training loss: 1.75\n","  Training epcoh took: 0:20:23\n","\n","Running Validation...\n","  Accuracy: 0.54\n","Validation loss decreased (inf --> 2.292187).  Saving model ...\n","  Validation Loss: 2.29\n","  Validation took: 0:00:49\n","Saving model to model_bert_multi_task_interactive_pre_trained_skill_bert/\n","\n","======== Epoch 2 / 20 ========\n","Training...\n","  Batch    40  of  1,223.    Elapsed: 0:00:41.\n","  Batch    80  of  1,223.    Elapsed: 0:01:21.\n","  Batch   120  of  1,223.    Elapsed: 0:02:01.\n","  Batch   160  of  1,223.    Elapsed: 0:02:41.\n","  Batch   200  of  1,223.    Elapsed: 0:03:21.\n","  Batch   240  of  1,223.    Elapsed: 0:04:01.\n","  Batch   280  of  1,223.    Elapsed: 0:04:41.\n","  Batch   320  of  1,223.    Elapsed: 0:05:21.\n","  Batch   360  of  1,223.    Elapsed: 0:06:01.\n","  Batch   400  of  1,223.    Elapsed: 0:06:41.\n","  Batch   440  of  1,223.    Elapsed: 0:07:21.\n","  Batch   480  of  1,223.    Elapsed: 0:08:01.\n","  Batch   520  of  1,223.    Elapsed: 0:08:41.\n","  Batch   560  of  1,223.    Elapsed: 0:09:21.\n","  Batch   600  of  1,223.    Elapsed: 0:10:01.\n","  Batch   640  of  1,223.    Elapsed: 0:10:41.\n","  Batch   680  of  1,223.    Elapsed: 0:11:21.\n","  Batch   720  of  1,223.    Elapsed: 0:12:01.\n","  Batch   760  of  1,223.    Elapsed: 0:12:41.\n","  Batch   800  of  1,223.    Elapsed: 0:13:21.\n","  Batch   840  of  1,223.    Elapsed: 0:14:01.\n","  Batch   880  of  1,223.    Elapsed: 0:14:41.\n","  Batch   920  of  1,223.    Elapsed: 0:15:21.\n","  Batch   960  of  1,223.    Elapsed: 0:16:01.\n","  Batch 1,000  of  1,223.    Elapsed: 0:16:41.\n","  Batch 1,040  of  1,223.    Elapsed: 0:17:21.\n","  Batch 1,080  of  1,223.    Elapsed: 0:18:01.\n","  Batch 1,120  of  1,223.    Elapsed: 0:18:41.\n","  Batch 1,160  of  1,223.    Elapsed: 0:19:21.\n","  Batch 1,200  of  1,223.    Elapsed: 0:20:01.\n"," Train Accuracy: 0.57\n","\n","  Average training loss: 1.69\n","  Training epcoh took: 0:20:24\n","\n","Running Validation...\n","  Accuracy: 0.55\n","EarlyStopping counter: 1 out of 2\n","  Validation Loss: 2.32\n","  Validation took: 0:00:46\n","Saving model to model_bert_multi_task_interactive_pre_trained_skill_bert/\n","\n","======== Epoch 3 / 20 ========\n","Training...\n","  Batch    40  of  1,223.    Elapsed: 0:00:41.\n","  Batch    80  of  1,223.    Elapsed: 0:01:21.\n","  Batch   120  of  1,223.    Elapsed: 0:02:01.\n","  Batch   160  of  1,223.    Elapsed: 0:02:41.\n","  Batch   200  of  1,223.    Elapsed: 0:03:20.\n","  Batch   240  of  1,223.    Elapsed: 0:04:00.\n","  Batch   280  of  1,223.    Elapsed: 0:04:40.\n","  Batch   320  of  1,223.    Elapsed: 0:05:20.\n","  Batch   360  of  1,223.    Elapsed: 0:06:00.\n","  Batch   400  of  1,223.    Elapsed: 0:06:40.\n","  Batch   440  of  1,223.    Elapsed: 0:07:20.\n","  Batch   480  of  1,223.    Elapsed: 0:08:00.\n","  Batch   520  of  1,223.    Elapsed: 0:08:40.\n","  Batch   560  of  1,223.    Elapsed: 0:09:20.\n","  Batch   600  of  1,223.    Elapsed: 0:10:00.\n","  Batch   640  of  1,223.    Elapsed: 0:10:40.\n","  Batch   680  of  1,223.    Elapsed: 0:11:20.\n","  Batch   720  of  1,223.    Elapsed: 0:12:00.\n","  Batch   760  of  1,223.    Elapsed: 0:12:40.\n","  Batch   800  of  1,223.    Elapsed: 0:13:20.\n","  Batch   840  of  1,223.    Elapsed: 0:14:00.\n","  Batch   880  of  1,223.    Elapsed: 0:14:40.\n","  Batch   920  of  1,223.    Elapsed: 0:15:20.\n","  Batch   960  of  1,223.    Elapsed: 0:16:00.\n","  Batch 1,000  of  1,223.    Elapsed: 0:16:40.\n","  Batch 1,040  of  1,223.    Elapsed: 0:17:21.\n","  Batch 1,080  of  1,223.    Elapsed: 0:18:01.\n","  Batch 1,120  of  1,223.    Elapsed: 0:18:41.\n","  Batch 1,160  of  1,223.    Elapsed: 0:19:21.\n","  Batch 1,200  of  1,223.    Elapsed: 0:20:01.\n"," Train Accuracy: 0.59\n","\n","  Average training loss: 1.64\n","  Training epcoh took: 0:20:24\n","\n","Running Validation...\n","  Accuracy: 0.55\n","Validation loss decreased (2.292187 --> 2.288839).  Saving model ...\n","  Validation Loss: 2.29\n","  Validation took: 0:00:49\n","Saving model to model_bert_multi_task_interactive_pre_trained_skill_bert/\n","\n","======== Epoch 4 / 20 ========\n","Training...\n","  Batch    40  of  1,223.    Elapsed: 0:00:41.\n","  Batch    80  of  1,223.    Elapsed: 0:01:21.\n","  Batch   120  of  1,223.    Elapsed: 0:02:01.\n","  Batch   160  of  1,223.    Elapsed: 0:02:41.\n","  Batch   200  of  1,223.    Elapsed: 0:03:21.\n","  Batch   240  of  1,223.    Elapsed: 0:04:01.\n","  Batch   280  of  1,223.    Elapsed: 0:04:41.\n","  Batch   320  of  1,223.    Elapsed: 0:05:21.\n","  Batch   360  of  1,223.    Elapsed: 0:06:02.\n","  Batch   400  of  1,223.    Elapsed: 0:06:42.\n","  Batch   440  of  1,223.    Elapsed: 0:07:22.\n","  Batch   480  of  1,223.    Elapsed: 0:08:02.\n","  Batch   520  of  1,223.    Elapsed: 0:08:43.\n","  Batch   560  of  1,223.    Elapsed: 0:09:23.\n","  Batch   600  of  1,223.    Elapsed: 0:10:03.\n","  Batch   640  of  1,223.    Elapsed: 0:10:43.\n","  Batch   680  of  1,223.    Elapsed: 0:11:23.\n","  Batch   720  of  1,223.    Elapsed: 0:12:03.\n","  Batch   760  of  1,223.    Elapsed: 0:12:44.\n","  Batch   800  of  1,223.    Elapsed: 0:13:24.\n","  Batch   840  of  1,223.    Elapsed: 0:14:04.\n","  Batch   880  of  1,223.    Elapsed: 0:14:44.\n","  Batch   920  of  1,223.    Elapsed: 0:15:24.\n","  Batch   960  of  1,223.    Elapsed: 0:16:04.\n","  Batch 1,000  of  1,223.    Elapsed: 0:16:44.\n","  Batch 1,040  of  1,223.    Elapsed: 0:17:25.\n","  Batch 1,080  of  1,223.    Elapsed: 0:18:05.\n","  Batch 1,120  of  1,223.    Elapsed: 0:18:45.\n","  Batch 1,160  of  1,223.    Elapsed: 0:19:25.\n","  Batch 1,200  of  1,223.    Elapsed: 0:20:05.\n"," Train Accuracy: 0.63\n","\n","  Average training loss: 1.58\n","  Training epcoh took: 0:20:28\n","\n","Running Validation...\n","  Accuracy: 0.54\n","EarlyStopping counter: 1 out of 2\n","  Validation Loss: 2.34\n","  Validation took: 0:00:46\n","Saving model to model_bert_multi_task_interactive_pre_trained_skill_bert/\n","\n","======== Epoch 5 / 20 ========\n","Training...\n","  Batch    40  of  1,223.    Elapsed: 0:00:41.\n","  Batch    80  of  1,223.    Elapsed: 0:01:21.\n","  Batch   120  of  1,223.    Elapsed: 0:02:01.\n","  Batch   160  of  1,223.    Elapsed: 0:02:41.\n","  Batch   200  of  1,223.    Elapsed: 0:03:21.\n","  Batch   240  of  1,223.    Elapsed: 0:04:02.\n","  Batch   280  of  1,223.    Elapsed: 0:04:42.\n","  Batch   320  of  1,223.    Elapsed: 0:05:22.\n","  Batch   360  of  1,223.    Elapsed: 0:06:02.\n","  Batch   400  of  1,223.    Elapsed: 0:06:42.\n","  Batch   440  of  1,223.    Elapsed: 0:07:22.\n","  Batch   480  of  1,223.    Elapsed: 0:08:02.\n","  Batch   520  of  1,223.    Elapsed: 0:08:42.\n","  Batch   560  of  1,223.    Elapsed: 0:09:22.\n","  Batch   600  of  1,223.    Elapsed: 0:10:03.\n","  Batch   640  of  1,223.    Elapsed: 0:10:43.\n","  Batch   680  of  1,223.    Elapsed: 0:11:23.\n","  Batch   720  of  1,223.    Elapsed: 0:12:03.\n","  Batch   760  of  1,223.    Elapsed: 0:12:43.\n","  Batch   800  of  1,223.    Elapsed: 0:13:23.\n","  Batch   840  of  1,223.    Elapsed: 0:14:03.\n","  Batch   880  of  1,223.    Elapsed: 0:14:44.\n","  Batch   920  of  1,223.    Elapsed: 0:15:24.\n","  Batch   960  of  1,223.    Elapsed: 0:16:04.\n","  Batch 1,000  of  1,223.    Elapsed: 0:16:44.\n","  Batch 1,040  of  1,223.    Elapsed: 0:17:24.\n","  Batch 1,080  of  1,223.    Elapsed: 0:18:04.\n","  Batch 1,120  of  1,223.    Elapsed: 0:18:45.\n","  Batch 1,160  of  1,223.    Elapsed: 0:19:25.\n","  Batch 1,200  of  1,223.    Elapsed: 0:20:05.\n"," Train Accuracy: 0.68\n","\n","  Average training loss: 1.48\n","  Training epcoh took: 0:20:28\n","\n","Running Validation...\n","  Accuracy: 0.52\n","EarlyStopping counter: 2 out of 2\n","Early stopping\n","\n","Training complete!\n","Total training took 1:47:44 (h:mm:ss)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"6RACcsko3kh_","outputId":"27ccec6a-1810-4c00-e149-1bcbc5ef79b4"},"source":["import pandas as pd\n","\n","# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Valid. Accur.</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>1.75</td>\n","      <td>2.29</td>\n","      <td>0.54</td>\n","      <td>0:20:23</td>\n","      <td>0:00:49</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.69</td>\n","      <td>2.32</td>\n","      <td>0.55</td>\n","      <td>0:20:24</td>\n","      <td>0:00:46</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.64</td>\n","      <td>2.29</td>\n","      <td>0.55</td>\n","      <td>0:20:24</td>\n","      <td>0:00:49</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.58</td>\n","      <td>2.34</td>\n","      <td>0.54</td>\n","      <td>0:20:28</td>\n","      <td>0:00:46</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n","epoch                                                                         \n","1               1.75         2.29           0.54       0:20:23         0:00:49\n","2               1.69         2.32           0.55       0:20:24         0:00:46\n","3               1.64         2.29           0.55       0:20:24         0:00:49\n","4               1.58         2.34           0.54       0:20:28         0:00:46"]},"metadata":{"tags":[]},"execution_count":67}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":427},"id":"o5TicdiP3kiC","outputId":"3fcf4c9f-b4cd-4ed3-9c2e-26f154acee90"},"source":["import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","import seaborn as sns\n","\n","# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])\n","\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DbiTDpVv3kiF","outputId":"a42bd2e2-3787-4a3d-cb64-7e0c326d029a"},"source":["import os\n","\n","\n","output_dir = 'model_bert_multi_task_interactive_pre_trained_skill_bert/'\n","\n","# Create output directory if needed\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","print(\"Saving model to %s\" % output_dir)\n","\n","\n","# model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","# model_to_save.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Saving model to model_bert_multi_task_interactive_pre_trained_skill_bert/\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["('model_bert_multi_task_interactive_pre_trained_skill_bert/vocab.txt',\n"," 'model_bert_multi_task_interactive_pre_trained_skill_bert/special_tokens_map.json',\n"," 'model_bert_multi_task_interactive_pre_trained_skill_bert/added_tokens.json')"]},"metadata":{"tags":[]},"execution_count":107}]},{"cell_type":"code","metadata":{"id":"Kq9ByBbSjJlx"},"source":["  import json\n","  torch.save(model.state_dict(), os.path.join(output_dir, 'model_weights'))\n","  # with open(os.path.join(output_dir, 'model_config.json'), 'w') as f:\n","  #     json.dump(model.config, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1U2UQ29a3kiI"},"source":["# !pip install joblib\n","# import joblib\n","# joblib.dump(LE, \"label_encoder_BLOOM_LATEST\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4GFnEkPP3kiP"},"source":["from google.colab import files\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dpGY8vSDI6u4","outputId":"7f319546-794d-44d5-cec8-c61277ff81fc"},"source":["!zip -r model_bert_multi_task_interactive_pre_trained_skill_bert.zip model_bert_multi_task_interactive_pre_trained_skill_bert\n","# files.download('model_bert_difficulty_prediction.zip')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  adding: model_bert_multi_task_interactive_pre_trained_skill_bert/ (stored 0%)\n","  adding: model_bert_multi_task_interactive_pre_trained_skill_bert/vocab.txt (deflated 53%)\n","  adding: model_bert_multi_task_interactive_pre_trained_skill_bert/tokenizer_config.json (stored 0%)\n","  adding: model_bert_multi_task_interactive_pre_trained_skill_bert/model_weights (deflated 7%)\n","  adding: model_bert_multi_task_interactive_pre_trained_skill_bert/special_tokens_map.json (deflated 40%)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HvFDCDIxKDOf"},"source":["# !zip -r label_encoder_BLOOM_LATEST.zip label_encoder_BLOOM_LATEST\n","# files.download('label_encoder_BLOOM_LATEST.zip')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":402},"id":"FcSwwzAFyE7S","outputId":"0bc83a91-c5aa-4ec0-d608-ce1958623f80"},"source":["test"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>board_syllabus</th>\n","      <th>question_answer</th>\n","      <th>skill_label</th>\n","      <th>difficulty_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>CBSE&gt;&gt;Nursery&gt;&gt;Environmental Science&gt;&gt;Common V...</td>\n","      <td>Write down the names of some common vegetable...</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>CBSE&gt;&gt;XII&gt;&gt;Physics&gt;&gt;Physics : Part - II&gt;&gt;Atoms</td>\n","      <td>Name the series of hydrogen atom which lies i...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ICSE OLD&gt;&gt;XI&gt;&gt;Political Science&gt;&gt;State, Govern...</td>\n","      <td>Which of the following is not the element of ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Maharashtra New&gt;&gt;VII&gt;&gt;General Science&gt;&gt;Static ...</td>\n","      <td>The process of electrically charging an objec...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Tamil Nadu&gt;&gt;IX&gt;&gt;Science&gt;&gt;Physics&gt;&gt;Measurement&gt;...</td>\n","      <td>The mass of an object is measured in kilogram...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4572</th>\n","      <td>ICSE OLD&gt;&gt;VIII&gt;&gt;Biology&gt;&gt;Nervous System And Se...</td>\n","      <td>Which of the following is the first cranial n...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4573</th>\n","      <td>CBSE&gt;&gt;VII&gt;&gt;Computer Science&gt;&gt;Advance features ...</td>\n","      <td>To ungroup the worksheets: Right-click on any...</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4574</th>\n","      <td>CBSE&gt;&gt;VIII&gt;&gt;Science&gt;&gt;Chemical Effects of Elect...</td>\n","      <td>After passing electricity through a solution ...</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4575</th>\n","      <td>CLSP&gt;&gt;Stage 9&gt;&gt;Science&gt;&gt;Chemistry&gt;&gt;Material pr...</td>\n","      <td>Identify the scientists who gave the “plum-pu...</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4576</th>\n","      <td>AP&gt;&gt;VIII&gt;&gt;Physical Science&gt;&gt;Physical Science (...</td>\n","      <td>What do you understand by the term static ele...</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4577 rows × 4 columns</p>\n","</div>"],"text/plain":["                                         board_syllabus  ... difficulty_label\n","0     CBSE>>Nursery>>Environmental Science>>Common V...  ...                2\n","1        CBSE>>XII>>Physics>>Physics : Part - II>>Atoms  ...                1\n","2     ICSE OLD>>XI>>Political Science>>State, Govern...  ...                0\n","3     Maharashtra New>>VII>>General Science>>Static ...  ...                1\n","4     Tamil Nadu>>IX>>Science>>Physics>>Measurement>...  ...                1\n","...                                                 ...  ...              ...\n","4572  ICSE OLD>>VIII>>Biology>>Nervous System And Se...  ...                1\n","4573  CBSE>>VII>>Computer Science>>Advance features ...  ...                0\n","4574  CBSE>>VIII>>Science>>Chemical Effects of Elect...  ...                2\n","4575  CLSP>>Stage 9>>Science>>Chemistry>>Material pr...  ...                0\n","4576  AP>>VIII>>Physical Science>>Physical Science (...  ...                1\n","\n","[4577 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":80}]},{"cell_type":"code","metadata":{"id":"4178_yLFMWmx"},"source":["test_features = test[\"question_answer\"].values\n","test_labels = test[\"difficulty_label\"].values\n","test_skill_labels = test[\"skill_label\"].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DggP9Sxdv_-l","outputId":"6261484c-b239-4429-906f-f5497074700f"},"source":["test_labels"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2, 1, 0, ..., 2, 0, 1])"]},"metadata":{"tags":[]},"execution_count":82}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ZpmBJuIC2nM","outputId":"5cb2fac2-ed31-4733-b806-2ddd11b9f8fd"},"source":["test_features"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([' Write down the names of some common vegetables. Answer may vary Probable answer – Names of some common vegetables are potato, onion, tomato and carrot.',\n","       ' Name the series of hydrogen atom which lies in the U.V region. Lyman series lies in the U.V region.',\n","       ' Which of the following is not the element of an association? Relationships are abstract Each association has elements 1) a group of people, 2) voluntary Membership, 3) shared and common interests or needs as the basis, 4) some set of objective goals which are to be achieved collectively by all the members, 5) a voluntary organisation, and 6) co-operation among the members objectives pooled resources for funds needed for action.',\n","       ...,\n","       ' After passing electricity through a solution the change that takes place is a chemical change Physical changes are those changes that do not result in the production of a new substance whereas a chemical change involves the production of a new substance. For example: When electricity is passed in a solution containing water, bubbles of hydrogen and oxygen are formed.',\n","       ' Identify the scientists who gave the “plum-pudding” model of the atom. J. J. Thomson The &ldquo;plum-pudding&rdquo; model of the atom was developed by the J. J Thomson. He compared his model used for describing the structure of atom with a plum pudding in which negatively charged electrons were surrounded by a positively charged &lsquo;pudding&rsquo;.',\n","       ' What do you understand by the term static electricity? It is the electricity developed due to stationary electric charges on the body.'],\n","      dtype=object)"]},"metadata":{"tags":[]},"execution_count":83}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"MlOvANUwprAw","outputId":"af37914a-6e17-447e-9fa2-17ca15aa8e31"},"source":["test_features[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["' Write down the names of some common vegetables. Answer may vary Probable answer – Names of some common vegetables are potato, onion, tomato and carrot.'"]},"metadata":{"tags":[]},"execution_count":84}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"-nCVhlaoXaXM","outputId":"418c97dd-c3d2-4c7a-cdc4-a27e0f9cb5e5"},"source":["test_features[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["' Write down the names of some common vegetables. Answer may vary Probable answer – Names of some common vegetables are potato, onion, tomato and carrot.'"]},"metadata":{"tags":[]},"execution_count":85}]},{"cell_type":"code","metadata":{"id":"2xncpeEmoGsB"},"source":["# syllabus = get_syllabus(test_features.values)\n","# poincare_emb_test = get_poincare_embeddings(syllabus)\n","# # for i,oincare in enumerate(poincare_emb_test):\n","# #   for x in oincare:\n","# #     print(i)\n","# #     print(oincare)\n","# #     print(poincare_model.kv.get_vector(str(x)))\n","\n","# poincare_embedding_test =  [exponential_map(np.expand_dims( np.hstack(  [ poincare_model.kv.get_vector(str(x)) for x in taxonomy ] ),axis=0)) for taxonomy in poincare_emb_test ]\n","# max_val = 0\n","# max_emb =None\n","# for embedding in poincare_embedding_test:\n","#   val = embedding.shape[1]\n","#   if val >max_val:\n","#     max_val=val\n","#     max_emb =embedding\n","# max_val\n","# concatenated_embedding = []\n","# for embedding in poincare_embedding_test:\n","#   if embedding.shape[1] < max_val:\n","#     new_embedding = np.append(embedding, np.expand_dims(np.zeros(max_val-embedding.shape[1]),axis=0),axis=1)\n","#   else:\n","#     new_embedding = embedding\n","#   concatenated_embedding.append(np.squeeze(new_embedding,axis=0))\n","# poincare_embeddings_final = np.stack(concatenated_embedding, axis=0)\n","# for feature_set in test_features:\n","#   if feature_set[1]!=feature_set[1]: #to check for nan\n","#     print(\"here\")\n","#     feature_set[1] = \"unk\"\n","#   else:\n","#     feature_set[1]=feature_set[1].lower()\n","# difficulty_level_vectors=[]\n","# for feature_set in test_features:\n","#   words = [word for word in feature_set[1].split(\" \")]\n","#   if len(words) > 1:\n","#     print(\"here\")\n","#     difficulty_level_vectors.append(np.mean(wv[words],axis=0))\n","#   else:\n","#     difficulty_level_vectors.append(wv[words].squeeze(axis=0))\n","# difficulty_level_vectors = np.array(difficulty_level_vectors)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qe4qYkV2C4fX","outputId":"91e50fee-bf0f-4581-9a70-d5c6fd89169a"},"source":["input_ids = []\n","attention_masks = []\n","for sent in test_features:\n","\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 128,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        truncation=True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","test_labels = torch.tensor(test_labels)\n","test_skill_labels = torch.tensor(test_skill_labels)\n","\n","# Set the batch size.  \n","batch_size = 34\n","# test_poincare_tensor = torch.tensor(poincare_embeddings_final,dtype=torch.float)\n","# print(test_poincare_tensor.shape)\n","# difficulty_tensor = torch.tensor(difficulty_level_vectors,dtype=torch.float)\n","# print(\"difficulty_tensor\",difficulty_tensor.shape)\n","# Combine the training inputs into a TensorDataset.\n","prediction_data = TensorDataset(input_ids, attention_masks, test_labels,test_skill_labels)\n","# Create the DataLoader.\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mPCktQT9DVT4","outputId":"c82a1548-b71c-4a57-9daa-91b8fa49060f"},"source":["# Prediction on test set\n","\n","print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n","\n","# Put model in evaluation mode\n","model.eval()\n","\n","# Tracking variables \n","predictions,skill_predictions , true_labels, true_skill_labels = [], [], [], []\n","\n","# Predict ea\n","for batch in prediction_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  \n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels,skill_labels = batch\n","  \n","  # Telling the model not to compute or store gradients, saving memory and \n","  # speeding up prediction\n","  # print(\"b_input_ids\",b_input_ids.shape)\n","  with torch.no_grad():\n","      # Forward pass, calculate logit predictions\n","      outputs,skill_ouputs = model(b_input_ids,b_input_mask)\n","\n","  logits = outputs\n","  skill_logits = skill_ouputs\n","\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  skill_logits = skill_logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  skill_labels = skill_labels.to('cpu').numpy()\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  skill_predictions.append(skill_logits)\n","  true_labels.append(label_ids)\n","  true_skill_labels.append(skill_labels)\n","\n","\n","print('    DONE.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Predicting labels for 4,577 test sentences...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["    DONE.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"U_WchmXtDspr"},"source":["print('Positive samples: %d of %d (%.2f%%)' % (final_data.label.sum(), len(final_data.label), (final_data.label.sum() / len(final_data.label) * 100.0)))"]},{"cell_type":"code","metadata":{"id":"7vbdVvUXDxgf","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b52e0770-1564-44af-8289-7d807b4c277d"},"source":["true_skill_labels[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([3, 1, 0, 3, 3, 1, 2, 3, 4, 1, 4, 2, 4, 3, 3, 3, 2, 4, 1, 4, 3, 2,\n","       3, 4, 3, 4, 2, 2, 4, 3, 1, 3, 3, 4])"]},"metadata":{"tags":[]},"execution_count":89}]},{"cell_type":"code","metadata":{"id":"s5BoY2hKGb7_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"802c8ad2-e8f0-4a3c-c5c2-cae7dbafba4f"},"source":["import numpy as np\n","pred =  np.argmax(predictions[0],axis=1).flatten()\n","pred"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2, 1, 0, 1, 1, 0, 1, 2, 1, 0, 2, 1, 2, 1, 1, 1, 1, 0, 0, 1, 2, 1,\n","       0, 2, 1, 1, 1, 1, 0, 1, 0, 2, 0, 1])"]},"metadata":{"tags":[]},"execution_count":90}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tPuK0-vzGp3R","outputId":"88e805a3-48f0-481d-c8db-eb8d7226cf82"},"source":["from sklearn.metrics import matthews_corrcoef\n","\n","matthews_set = []\n","\n","# Evaluate each test batch using Matthew's correlation coefficient\n","print('Calculating Matthews Corr. Coef. for each batch...')\n","\n","# For each input batch...\n","for i in range(len(true_labels)):\n","  \n","  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n","  # and one column for \"1\"). Pick the label with the highest value and turn this\n","  # in to a list of 0s and 1s.\n","  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n","  \n","  # Calculate and store the coef for this batch.  \n","  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n","  matthews_set.append(matthews)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Calculating Matthews Corr. Coef. for each batch...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i5MKFS0iXm7l","outputId":"20b72414-15ad-439d-c86d-90781e260741"},"source":["import numpy as np\n","flat_predictions = np.concatenate(predictions, axis=0)\n","\n","flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","\n","# Combine the correct labels for each batch into a single list.\n","flat_true_labels = np.concatenate(true_labels, axis=0)\n","\n","# Calculate the MCC\n","mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n","\n","print('Total MCC: %.3f' % mcc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Total MCC: 0.233\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nOTqUYPmEUCn","outputId":"09e0519e-cc7c-4328-a43a-c182d5390b43"},"source":["flat_skill_predictions = np.concatenate(skill_predictions, axis=0)\n","\n","flat_skill_predictions = np.argmax(flat_skill_predictions, axis=1).flatten()\n","\n","# Combine the correct labels for each batch into a single list.\n","flat_true_skill_labels = np.concatenate(true_skill_labels, axis=0)\n","\n","# Calculate the MCC\n","mcc = matthews_corrcoef(flat_true_skill_labels, flat_skill_predictions)\n","\n","print('Total MCC: %.3f' % mcc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Total MCC: 0.343\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"id":"EdmAmoA0Y4zS","outputId":"e2b00332-0a72-45d7-a77e-1252f762fdb0"},"source":["question_answer[30]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["' Match Column I with Column II and select the correct match from the following options.  Column I  Column II a Food allergy i Pollen grains b Dust allergy ii Aspirin c Seasonal allergy iii Avocado d Drug allergy iv Asthma a-iii, b-iv, c-i, d-ii Food allergy refers to an abnormal response to a food triggered by the body&#39;s immune system.    Dust allergy is a perennial allergy.    Seasonal allergy occur during a particular period due to pollen grains, smog etc.    A drug allergy refers to the abnormal reaction of the immune system to a medication.'"]},"metadata":{"tags":[]},"execution_count":95}]},{"cell_type":"code","metadata":{"id":"zlqpVfk-NW_F"},"source":["def accuracy_per_class(preds_flat, labels_flat):\n","\n","    for label in np.unique(labels_flat):\n","        y_preds = preds_flat[labels_flat==label]\n","        y_true = labels_flat[labels_flat==label]\n","        print(f'Class: {get_labels(label)}')\n","        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o29QuEYW-mzm","outputId":"2d58e8aa-96a1-4771-af6c-da09c8fef7df"},"source":["accuracy_per_class(flat_predictions,flat_true_labels)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Class: Difficult\n","Accuracy: 675/1646\n","\n","Class: Easy\n","Accuracy: 1477/2207\n","\n","Class: Medium\n","Accuracy: 277/724\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ed7_zfiDNaOv","outputId":"f6931c7d-c78b-441d-9441-521a3f162800"},"source":["accuracy_per_class(flat_predictions,flat_true_labels)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Class: Difficult\n","Accuracy: 710/1646\n","\n","Class: Easy\n","Accuracy: 1620/2207\n","\n","Class: Medium\n","Accuracy: 181/724\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":427},"id":"4_vxvq7rHlgr","outputId":"e13b9400-db28-41fa-dbf7-1c8a900ae7ce"},"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n","\n","plt.title('MCC Score per Batch')\n","plt.ylabel('MCC Score (-1 to +1)')\n","plt.xlabel('Batch #')\n","\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v48rDl4JHmhv","outputId":"19e34c88-e5e9-40f6-bf2a-3df0bd2af1f7"},"source":["flat_predictions = np.concatenate(predictions, axis=0)\n","\n","flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","\n","# Combine the correct labels for each batch into a single list.\n","flat_true_labels = np.concatenate(true_labels, axis=0)\n","\n","# Calculate the MCC\n","mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n","\n","print('Total MCC: %.3f' % mcc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Total MCC: 0.233\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"drJC0xYkHr_8","outputId":"7e8380a5-75cb-4928-c869-29d9d6eb3cd9"},"source":["print('Total MCC: %.3f' % mcc)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Total MCC: 0.247\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f8K0OFM-c7Fv","outputId":"66c1041a-8bdc-4693-bf68-8f119b72b86f"},"source":["from sklearn.metrics import precision_recall_fscore_support\n","#difficulty\n","print(precision_recall_fscore_support(flat_true_labels, flat_predictions, average='micro'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(0.5306969630762508, 0.5306969630762508, 0.5306969630762508, None)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"44lMA088c7Fv","outputId":"b86c22c0-e2c4-404b-b7db-1b21b970f820"},"source":["from sklearn.metrics import precision_recall_fscore_support\n","#difficulty\n","print(precision_recall_fscore_support(flat_true_labels, flat_predictions, average='macro'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(0.4916142304947111, 0.4873053314683979, 0.4837227077919244, None)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ul7CnYqIYjmH","outputId":"50c0f3f1-543f-4a94-cba7-9940732635fd"},"source":["from sklearn.metrics import precision_recall_fscore_support\n","#difficulty\n","print(precision_recall_fscore_support(flat_true_labels, flat_predictions, average='weighted'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(0.5354487960967275, 0.5306969630762508, 0.5269171115799955, None)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TBpMQFrz9Als","outputId":"6898caaa-19ef-47e5-b8e9-474786be1ee7"},"source":["from sklearn.metrics import precision_recall_fscore_support\n","#skill_name\n","print(precision_recall_fscore_support(flat_true_skill_labels, flat_skill_predictions, average='micro'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(0.5012016604762946, 0.5012016604762946, 0.5012016604762946, None)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hcaAMXG69Als","outputId":"fa6f0113-3657-4681-9775-91960e20695d"},"source":["from sklearn.metrics import precision_recall_fscore_support\n","#skill name\n","print(precision_recall_fscore_support(flat_true_skill_labels, flat_skill_predictions, average='macro'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(0.4829542858816799, 0.4630626921284685, 0.4700329767990987, None)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zivypLKV9Als","outputId":"62809433-2b0d-4334-a2bd-923f66e46211"},"source":["from sklearn.metrics import precision_recall_fscore_support\n","#skill name\n","print(precision_recall_fscore_support(flat_true_skill_labels, flat_skill_predictions, average='weighted'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(0.4963391871168191, 0.5012016604762946, 0.4967305425385167, None)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zFediYEjlKjX"},"source":["def get_confusion_matrix(predicted,actual):\n","    conf_matrix = np.zeros((5, 5))\n","    for pred,act in zip(predicted,actual):\n","        conf_matrix[act,pred]+=1\n","    return conf_matrix\n","        \n","def get_TP(confusion_matrix,label):\n","    tp = confusion_matrix[label][label]\n","    return tp\n","\n","def get_FN(confusion_matrix,label):\n","    row = confusion_matrix[label,]\n","    row_truepositives = row[label]\n","    fn = row.sum() - row_truepositives\n","    return fn\n","\n","def get_FP(confusion_matrix,tag):\n","    col = confusion_matrix[:,tag]\n","    col_tp = col[tag]\n","    #  sum of all values in column except tp\n","    fp = col.sum() - col_tp\n","    return fp\n","def Precision(conf_matrix):\n","    precision = 0.0\n","    for label in [0,1,2,3,4]:\n","        dividor= get_TP(conf_matrix,label)+get_FP(conf_matrix,label)\n","        if dividor != 0.0:\n","            precision += (get_TP(conf_matrix,label))/dividor\n","    return (precision / 5)\n","\n","def Recall(conf_matrix):\n","    recall = 0.0\n","    for label in [0,1,2,3,4]:\n","        dividor=get_TP(conf_matrix,label)+get_FN(conf_matrix,label)\n","        if dividor != 0.0:\n","            recall += (get_TP(conf_matrix,label))/dividor\n","    return (recall / 5)\n","\n","def F1(precision,recall):\n","    return (2*precision*recall)/(precision+recall)\n","def accuracy_per_class(preds_flat, labels_flat):\n","\n","    for label in np.unique(labels_flat):\n","        y_preds = preds_flat[labels_flat==label]\n","        y_true = labels_flat[labels_flat==label]\n","        print(f'Class: {label}')\n","        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n","def print_metrics(predictions,test_labels):\n","    conf_matrix = get_confusion_matrix(predictions,test_labels)\n","    precision = Precision(conf_matrix)\n","    recall = Recall(conf_matrix)\n","    f1_score = F1(precision,recall)\n","    print(\"Macro : Precision:{}, Recall: {}, F1: {}\".format(precision,recall,f1_score))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aFEi23ejPfOm"},"source":["def Precision_macro_weighted(conf_matrix,test_samples):\n","    accum =0\n","    label_wise_precision = dict()\n","    for label in [0,1,2,3,4]:\n","        true_sample = [sample for sample in test_samples if sample==label ]\n","        if (get_TP(conf_matrix,label)+get_FP(conf_matrix,label))!=0:\n","            accum+= float(len(true_sample)) *(get_TP(conf_matrix,label)/(get_TP(conf_matrix,label)+get_FP(conf_matrix,label)))\n","            label_wise_precision[label] = get_TP(conf_matrix,label)/(get_TP(conf_matrix,label)+get_FP(conf_matrix,label))\n","\n","    \n","    precision =  accum/len(test_samples)\n","            \n","    return precision\n","\n","\n","def Recall_macro_weighted(conf_matrix,test_samples):\n","    accum =0\n","    label_wise_recall = dict()\n","    for label in [0,1,2,3,4]:\n","        true_sample = [sample for sample in test_samples if sample==label ]\n","\n","        if (get_TP(conf_matrix,label)+get_FN(conf_matrix,label))!=0:\n","            accum+= float(len(true_sample)) * (get_TP(conf_matrix,label)/(get_TP(conf_matrix,label)+get_FN(conf_matrix,label)))\n","            label_wise_recall[label] = get_TP(conf_matrix,label)/(get_TP(conf_matrix,label)+get_FN(conf_matrix,label))\n","\n","    \n","    recall =  accum/len(test_samples)\n","    return recall\n","def print_weighted_metrics(predictions,test_labels):\n","    conf_matrix = get_confusion_matrix(predictions,test_labels)\n","    precision = Precision_macro_weighted(conf_matrix,test_labels)\n","    recall = Recall_macro_weighted(conf_matrix,test_labels)\n","    f1_score = F1(precision,recall)\n","    print(\"Macro : Precision:{}, Recall: {}, F1: {}\".format(precision,recall,f1_score))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pbe2BbA4E20b","outputId":"97634a8b-4300-42de-d681-f431541902d3"},"source":["#difficuty macro\n","print_metrics(flat_predictions,flat_true_labels)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Macro : Precision:0.4916142304947111, Recall: 0.4873053314683979, F1: 0.48945029776580296\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nNp29QbiA1B8","outputId":"f4902706-10d0-48fe-e92b-3fb061e9df8f"},"source":["#difficulty\n","print_weighted_metrics(flat_predictions,flat_true_labels)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Macro : Precision:0.5354487960967275, Recall: 0.5306969630762508, F1: 0.5330622900789755\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1hNCTTaiK9NU","colab":{"base_uri":"https://localhost:8080/"},"outputId":"804aff0c-aeed-46a7-e811-f54aa3c01e62"},"source":["#skill name\n","print_metrics(flat_skill_predictions,flat_true_skill_labels)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Macro : Precision:0.4829542858816799, Recall: 0.4630626921284685, F1: 0.47279936194327715\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PN7dldMoEMq0","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fdd852bb-d302-4f0b-aab7-62ac79de21bb"},"source":["#skill name\n","print_weighted_metrics(flat_skill_predictions,flat_true_skill_labels)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Macro : Precision:0.4963391871168191, Recall: 0.5012016604762946, F1: 0.4987585728296372\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lbxR7mbxBCBP"},"source":["def accuracy_per_class(preds_flat, labels_flat):\n","\n","    for label in np.unique(labels_flat):\n","        y_preds = preds_flat[labels_flat==label]\n","        y_true = labels_flat[labels_flat==label]\n","        print(f'Class: {get_labels(label)}')\n","        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xXoacYx9BD_v","outputId":"c1fc8968-6da2-455c-c0d3-d45e60d695b2"},"source":["accuracy_per_class(flat_predictions,flat_true_labels)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Class: Difficult\n","Accuracy: 710/1646\n","\n","Class: Easy\n","Accuracy: 1620/2207\n","\n","Class: Medium\n","Accuracy: 181/724\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0DaR_83RQ9Fp","outputId":"8841a43d-581a-4c58-e649-63a32ed04d48"},"source":["accuracy_per_class(flat_skill_predictions,flat_true_skill_labels)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Class: Analysing\n","Accuracy: 125/404\n","\n","Class: Applying\n","Accuracy: 150/602\n","\n","Class: Knowledge & understanding\n","Accuracy: 613/933\n","\n","Class: Remembering\n","Accuracy: 831/1356\n","\n","Class: Understanding\n","Accuracy: 557/1282\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vu6lbpuxxbxk"},"source":["!cp -r /content/model_bert_multi_task_interactive_pre_trained_skill_bert.zip \"/content/drive/My Drive/research_skill_name_prediction/\" "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nv242vUH68jm"},"source":["!cp -r \"/content/drive/My Drive/research_skill_name_prediction/model_bert_multi_task_prediction.zip\" /content/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PNaswzbJ7EOw","outputId":"33fcba65-ff87-4bc7-88e8-1890bb03b6d8"},"source":["!unzip model_bert_multi_task_prediction.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Archive:  model_bert_multi_task_prediction.zip\n","   creating: model_bert_multi_task_prediction/\n","  inflating: model_bert_multi_task_prediction/model_weights  \n","  inflating: model_bert_multi_task_prediction/tokenizer_config.json  \n","  inflating: model_bert_multi_task_prediction/special_tokens_map.json  \n","  inflating: model_bert_multi_task_prediction/vocab.txt  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uSK1y-sQ8UAq"},"source":["!cp -r /content/model_bert_multi_task_interactive_pre_trained_skill_bert \"/content/drive/My Drive/research_skill_name_prediction/\" "],"execution_count":null,"outputs":[]}]}