{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "multi-task_qdiff_interactive_attention_pre_trained_skill_bert_data_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2163f0d34482460096bd3247a6057f8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b55ff6dfe2d948bd85f36e8a5848b451",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1f2c696376c845388b8f59ac455c6484",
              "IPY_MODEL_52fff86ba05c4ac489f5a0384be31d6d",
              "IPY_MODEL_52ec394c33ab4d47b60a0fd396091016"
            ]
          }
        },
        "b55ff6dfe2d948bd85f36e8a5848b451": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f2c696376c845388b8f59ac455c6484": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_413147f0bf5947c7afb0a9f6d78bbb71",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0920603cf12b406da50cfabf26167cd4"
          }
        },
        "52fff86ba05c4ac489f5a0384be31d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ac3d2ed6b2654b109f09d850497fe444",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cc05be07421e454d9ecad268f1e919b4"
          }
        },
        "52ec394c33ab4d47b60a0fd396091016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5e2dedab978b4938a937e1438cf51c30",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 867kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d25a95295f4742b5b7aa31a212f9f558"
          }
        },
        "413147f0bf5947c7afb0a9f6d78bbb71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0920603cf12b406da50cfabf26167cd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ac3d2ed6b2654b109f09d850497fe444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cc05be07421e454d9ecad268f1e919b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e2dedab978b4938a937e1438cf51c30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d25a95295f4742b5b7aa31a212f9f558": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8709f741370f4b32aca425b6c186ae4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e0e14c1d03f8485c8f764c1d8b758e0c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e3b9cd4386b54073a8c47166e86e880f",
              "IPY_MODEL_333531fbe35542c882a74e695bef1598",
              "IPY_MODEL_027f5922a1cc414da45a7fdcbd8b34a2"
            ]
          }
        },
        "e0e14c1d03f8485c8f764c1d8b758e0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3b9cd4386b54073a8c47166e86e880f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9804fc777e4941168e16798870d9d9df",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f0200f499c644d26b3ed405c920e5e7b"
          }
        },
        "333531fbe35542c882a74e695bef1598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_38bfa6161042464987f31e02e710d212",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0d8d89ad70b4b789bd61a85e210e2c0"
          }
        },
        "027f5922a1cc414da45a7fdcbd8b34a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7ede42df5f19469ebba6feae6502b2f3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 9.93kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_10c313b910bb4e98b69e7f095bad84c7"
          }
        },
        "9804fc777e4941168e16798870d9d9df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f0200f499c644d26b3ed405c920e5e7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "38bfa6161042464987f31e02e710d212": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0d8d89ad70b4b789bd61a85e210e2c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7ede42df5f19469ebba6feae6502b2f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "10c313b910bb4e98b69e7f095bad84c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f92017a763f34f39a999a4e4384627bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a89bfc8c32a8414bbc945c437d9fcc86",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_74627ed667d94325bc86fc2bf45f07a7",
              "IPY_MODEL_15e8893cb9df4c00aacb26f51ce1edd4",
              "IPY_MODEL_0045e9039cd447629b136c0e0f18acf8"
            ]
          }
        },
        "a89bfc8c32a8414bbc945c437d9fcc86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "74627ed667d94325bc86fc2bf45f07a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_034831822daa4e00b3e98128c85f44dc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb07c3c0b5284342a0ea791098953630"
          }
        },
        "15e8893cb9df4c00aacb26f51ce1edd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3a6189c72f204ec3853827ab8df865ac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d31e916ce5e2451aa91c7ebf98771cb6"
          }
        },
        "0045e9039cd447629b136c0e0f18acf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_be816c6fc2d54c1b8f051d3760d958de",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:16&lt;00:00, 27.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ee11cb95d4d1404890d58f2b9c3aac01"
          }
        },
        "034831822daa4e00b3e98128c85f44dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb07c3c0b5284342a0ea791098953630": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a6189c72f204ec3853827ab8df865ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d31e916ce5e2451aa91c7ebf98771cb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be816c6fc2d54c1b8f051d3760d958de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ee11cb95d4d1404890d58f2b9c3aac01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sR9av2JU3kf6",
        "outputId": "9b67f50a-80ff-45c2-fa42-900908ddc785"
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "import torch\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzKeqoCs3kgA",
        "outputId": "161534df-0b3c-4768-ef87-8c04b62260d7"
      },
      "source": [
        "!pip install transformers==3.2.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==3.2.0\n",
            "  Downloading transformers-3.2.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 27.7 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |█                               | 30 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███                             | 92 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████                        | 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 266 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 276 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 286 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 296 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 307 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 317 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 327 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 337 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 348 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 358 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 368 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 378 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 389 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 399 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 409 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 419 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 430 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 440 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 450 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 460 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 471 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 481 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 491 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 501 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 512 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 522 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 532 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 542 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 552 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 563 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 573 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 583 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 593 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 604 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 614 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 624 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 634 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 645 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 655 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 665 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 675 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 686 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 696 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 706 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 716 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 727 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 737 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 747 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 757 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 768 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 778 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 788 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 798 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 808 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 819 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 829 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 839 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 849 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 860 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 870 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 880 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 890 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 901 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 911 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 921 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 931 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 942 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 952 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 962 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 972 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 983 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 993 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 35.0 MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc2\n",
            "  Downloading tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 44.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (4.62.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 36.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (21.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.2.0) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2.0) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2.0) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.2.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.2.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.2.0) (1.0.1)\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.45 sentencepiece-0.1.96 tokenizers-0.8.1rc2 transformers-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "GsADhaO93kgD",
        "outputId": "f61abe01-0884-451c-8e59-dc77993d3e64"
      },
      "source": [
        "import pandas as pd\n",
        "final_data = pd.read_csv(\"/content/train_qdiff_data_2_soft_labeled.csv\")\n",
        "final_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>DifficultyFromAnswerer</th>\n",
              "      <th>question_answer</th>\n",
              "      <th>difficulty_label</th>\n",
              "      <th>skill_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Is the dialect spoken in Jeju located in fact ...</td>\n",
              "      <td>The dialect spoken in Jeju is in fact classifi...</td>\n",
              "      <td>hard</td>\n",
              "      <td>Is the dialect spoken in Jeju located in fact ...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What cello manufacturer should I buy from if I...</td>\n",
              "      <td>Luis &amp; Clark</td>\n",
              "      <td>hard</td>\n",
              "      <td>What cello manufacturer should I buy from if I...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Does it have a border with Norway?</td>\n",
              "      <td>yes</td>\n",
              "      <td>medium</td>\n",
              "      <td>Does it have a border with Norway? yes</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How many people use the bus network daily?</td>\n",
              "      <td>More than 2.78 million people.</td>\n",
              "      <td>easy</td>\n",
              "      <td>How many people use the bus network daily? Mor...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Who founded Montevideo?</td>\n",
              "      <td>The Spanish.</td>\n",
              "      <td>medium</td>\n",
              "      <td>Who founded Montevideo? The Spanish.</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2763</th>\n",
              "      <td>Did he become a professor before the revolutio...</td>\n",
              "      <td>yes</td>\n",
              "      <td>hard</td>\n",
              "      <td>Did he become a professor before the revolutio...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2764</th>\n",
              "      <td>Does Vietnamese borrow from Latin and Greek?</td>\n",
              "      <td>No, Vietnamese does not borrow from Latin and ...</td>\n",
              "      <td>medium</td>\n",
              "      <td>Does Vietnamese borrow from Latin and Greek? N...</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2765</th>\n",
              "      <td>Where is San Francisco?</td>\n",
              "      <td>San Francisco is in California.</td>\n",
              "      <td>medium</td>\n",
              "      <td>Where is San Francisco? San Francisco is in Ca...</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2766</th>\n",
              "      <td>What is the primary item in an otter's diet?</td>\n",
              "      <td>fish</td>\n",
              "      <td>medium</td>\n",
              "      <td>What is the primary item in an otter's diet? fish</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2767</th>\n",
              "      <td>Where are turtle eggs layed?</td>\n",
              "      <td>Turtles lay eggs on land.</td>\n",
              "      <td>hard</td>\n",
              "      <td>Where are turtle eggs layed? Turtles lay eggs ...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2768 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Question  ... skill_label\n",
              "0     Is the dialect spoken in Jeju located in fact ...  ...           3\n",
              "1     What cello manufacturer should I buy from if I...  ...           3\n",
              "2                    Does it have a border with Norway?  ...           2\n",
              "3            How many people use the bus network daily?  ...           2\n",
              "4                               Who founded Montevideo?  ...           2\n",
              "...                                                 ...  ...         ...\n",
              "2763  Did he become a professor before the revolutio...  ...           3\n",
              "2764       Does Vietnamese borrow from Latin and Greek?  ...           3\n",
              "2765                            Where is San Francisco?  ...           3\n",
              "2766       What is the primary item in an otter's diet?  ...           2\n",
              "2767                       Where are turtle eggs layed?  ...           3\n",
              "\n",
              "[2768 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0Ja4jiFhmdg",
        "outputId": "d046ca0f-2131-41a4-d9cc-184abfef190f"
      },
      "source": [
        "final_data[\"question_answer\"].values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Is the dialect spoken in Jeju located in fact classified as a different language by all Korean linguists? The dialect spoken in Jeju is in fact classified as a different language by some Korean linguists.',\n",
              "       'What cello manufacturer should I buy from if I want to play outside? Luis & Clark',\n",
              "       'Does it have a border with Norway? yes', ...,\n",
              "       'Where is San Francisco? San Francisco is in California.',\n",
              "       \"What is the primary item in an otter's diet? fish\",\n",
              "       'Where are turtle eggs layed? Turtles lay eggs on land.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQhO6qqt6lge",
        "outputId": "8a361c51-a022-4ae1-cde9-d59631985f12"
      },
      "source": [
        "final_data['difficulty_label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1099\n",
              "2    1001\n",
              "1     668\n",
              "Name: difficulty_label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EkZ-3TZ5UBJ"
      },
      "source": [
        "def clean_sentence(question):\n",
        "  # print(question)\n",
        "  question = re.sub('<[^>]*>', ' ',question)\n",
        "  question = re.sub(' +', ' ', question)\n",
        "  question = re.sub('\\xa0','',question)\n",
        "  question = question.rstrip()\n",
        "  question = re.sub('nan','',question)\n",
        "  question = re.sub(u'\\u2004','',question)\n",
        "  question = re.sub(u'\\u2009','',question)\n",
        "\n",
        "  # question = question.decode(\"utf-8\")\n",
        "  # question = question.replace(u'\\u200\\d*','').encode(\"utf-8\")\n",
        "  question = re.sub('&nbsp','',question)\n",
        "  question = re.sub('&ndash','',question)\n",
        "  question = re.sub('\\r','',question)\n",
        "  question = re.sub('\\t','',question)\n",
        "  question = re.sub('\\n',' ',question)\n",
        "\n",
        "  question = re.sub('MathType@.*','',question)\n",
        "  question = re.sub('&thinsp','',question)\n",
        "  question = re.sub('&times','',question)\n",
        "  question = re.sub('\\u200b','',question)\n",
        "  question = re.sub('&rarr;;;','',question)\n",
        "\n",
        "  return question"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMCV9mxDnaK0",
        "outputId": "4395a3eb-ea05-4e67-fa33-0ca8c1a5f2bc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9exlBELH5oq9"
      },
      "source": [
        "!cp \"/content/drive/My Drive/research_skill_name_prediction/label_encoder_difficulty_Lstm\"  /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUqcGtXwBIyl"
      },
      "source": [
        "!cp \"/content/drive/MyDrive/research_skill_name_prediction/label_encoder_skill_lstm\" /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj-ow-6cqFyn"
      },
      "source": [
        "!cp -r \"/content/drive/MyDrive/research_skill_name_prediction/model_bert_multi_task_interactive_pre_trained_skill_bert_data_2\" /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cov2EsRThbfF"
      },
      "source": [
        "!cp -r \"/content/drive/MyDrive/research_skill_name_prediction/model_bert_skill_prediction_data_2\" /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYbSa7ZKAkfz",
        "outputId": "88005d75-501d-4c8e-cdb6-d423cdb0d5f3"
      },
      "source": [
        "import joblib\n",
        "LE_skill = joblib.load('label_encoder_skill_lstm')\n",
        "LE_skill.classes_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Analysing', 'Applying', 'Knowledge & understanding',\n",
              "       'Remembering', 'Understanding'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OBarOLBz2nO"
      },
      "source": [
        "def get_labels(prediction):\n",
        "    predicted_label =  LE.inverse_transform([prediction])\n",
        "    return predicted_label[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "XqWem79lbn1J",
        "outputId": "6f58538f-2391-4069-ef9d-dbb947c2b03e"
      },
      "source": [
        "final_data['difficulty_label'].value_counts().sort_values(ascending=False).plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc867437490>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxliBQEJ9eTG"
      },
      "source": [
        "val = pd.read_csv(\"/content/val_qdiff_data_2_soft_labeled.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "07eBaI9wA2hL",
        "outputId": "80c7d261-e26c-4ea2-bb8a-04ebb329b924"
      },
      "source": [
        "val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>DifficultyFromAnswerer</th>\n",
              "      <th>difficulty_label</th>\n",
              "      <th>question_answer</th>\n",
              "      <th>skill_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What are turtle eggs covered in when they incu...</td>\n",
              "      <td>mud or sand</td>\n",
              "      <td>hard</td>\n",
              "      <td>1</td>\n",
              "      <td>What are turtle eggs covered in when they incu...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is given for the number of native speakers?</td>\n",
              "      <td>No figure is given for the number of native sp...</td>\n",
              "      <td>hard</td>\n",
              "      <td>1</td>\n",
              "      <td>What is given for the number of native speaker...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How many long was Lincoln's formal education?</td>\n",
              "      <td>18 months</td>\n",
              "      <td>easy</td>\n",
              "      <td>0</td>\n",
              "      <td>How many long was Lincoln's formal education? ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>who was his mentor?</td>\n",
              "      <td>John 'Mad Jack' Fuller</td>\n",
              "      <td>medium</td>\n",
              "      <td>2</td>\n",
              "      <td>who was his mentor? John 'Mad Jack' Fuller</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Can black swans swim with only one leg?</td>\n",
              "      <td>yes</td>\n",
              "      <td>easy</td>\n",
              "      <td>0</td>\n",
              "      <td>Can black swans swim with only one leg? yes</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>Is Berlin the capital city of Germany?</td>\n",
              "      <td>Berlin is the capital city of Germany.</td>\n",
              "      <td>easy</td>\n",
              "      <td>0</td>\n",
              "      <td>Is Berlin the capital city of Germany? Berlin ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>Who did James Monroe live with in New York City?</td>\n",
              "      <td>His daughter Maria Hester Monroe Gouverneur</td>\n",
              "      <td>medium</td>\n",
              "      <td>2</td>\n",
              "      <td>Who did James Monroe live with in New York Cit...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>What is one of the challenges of re-establishi...</td>\n",
              "      <td>roadkill deaths</td>\n",
              "      <td>hard</td>\n",
              "      <td>1</td>\n",
              "      <td>What is one of the challenges of re-establishi...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>Is Santiago the national capital of a country?</td>\n",
              "      <td>Yes</td>\n",
              "      <td>easy</td>\n",
              "      <td>0</td>\n",
              "      <td>Is Santiago the national capital of a country?...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307</th>\n",
              "      <td>Why do some people believe that left-handed pe...</td>\n",
              "      <td>to standardise the instrument</td>\n",
              "      <td>hard</td>\n",
              "      <td>1</td>\n",
              "      <td>Why do some people believe that left-handed pe...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>308 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Question  ... skill_label\n",
              "0    What are turtle eggs covered in when they incu...  ...           2\n",
              "1     What is given for the number of native speakers?  ...           3\n",
              "2        How many long was Lincoln's formal education?  ...           3\n",
              "3                                  who was his mentor?  ...           3\n",
              "4              Can black swans swim with only one leg?  ...           3\n",
              "..                                                 ...  ...         ...\n",
              "303             Is Berlin the capital city of Germany?  ...           3\n",
              "304   Who did James Monroe live with in New York City?  ...           3\n",
              "305  What is one of the challenges of re-establishi...  ...           2\n",
              "306     Is Santiago the national capital of a country?  ...           3\n",
              "307  Why do some people believe that left-handed pe...  ...           4\n",
              "\n",
              "[308 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "g8tVsjiWj-cF",
        "outputId": "891d0b72-5b08-45c1-cea9-e9bf8c4db55e"
      },
      "source": [
        "test = pd.read_csv(\"/content/test_qdiff_data_2_soft_labeled.csv\")\n",
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>DifficultyFromAnswerer</th>\n",
              "      <th>difficulty_label</th>\n",
              "      <th>question_answer</th>\n",
              "      <th>skill_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How are western-style xylophones characterised?</td>\n",
              "      <td>by a bright, sharp tone and high register</td>\n",
              "      <td>medium</td>\n",
              "      <td>2</td>\n",
              "      <td>How are western-style xylophones characterised...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Is Nairobi the capital of Kenya?</td>\n",
              "      <td>Yes</td>\n",
              "      <td>easy</td>\n",
              "      <td>0</td>\n",
              "      <td>Is Nairobi the capital of Kenya? Yes</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How many sister cities does the City of Melbou...</td>\n",
              "      <td>six</td>\n",
              "      <td>medium</td>\n",
              "      <td>2</td>\n",
              "      <td>How many sister cities does the City of Melbou...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Is the electric eel a true eel?</td>\n",
              "      <td>No</td>\n",
              "      <td>easy</td>\n",
              "      <td>0</td>\n",
              "      <td>Is the electric eel a true eel? No</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Does Swedish use the perfect participle to for...</td>\n",
              "      <td>No.</td>\n",
              "      <td>easy</td>\n",
              "      <td>0</td>\n",
              "      <td>Does Swedish use the perfect participle to for...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>337</th>\n",
              "      <td>Where was there a vast swarm of butterflies?</td>\n",
              "      <td>In Kyoto there was a vast swarm of butterflies.</td>\n",
              "      <td>medium</td>\n",
              "      <td>2</td>\n",
              "      <td>Where was there a vast swarm of butterflies? I...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>338</th>\n",
              "      <td>What is the most common romanization standard ...</td>\n",
              "      <td>Hanyu Pinyin</td>\n",
              "      <td>medium</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the most common romanization standard ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>339</th>\n",
              "      <td>Is Jakarta the 12th largest city in the world?</td>\n",
              "      <td>yes</td>\n",
              "      <td>medium</td>\n",
              "      <td>2</td>\n",
              "      <td>Is Jakarta the 12th largest city in the world?...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340</th>\n",
              "      <td>What sort of turtles are ectothermic?</td>\n",
              "      <td>all of them</td>\n",
              "      <td>medium</td>\n",
              "      <td>2</td>\n",
              "      <td>What sort of turtles are ectothermic? all of them</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341</th>\n",
              "      <td>Was Gellu Naum the leader of the surrealist mo...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>easy</td>\n",
              "      <td>0</td>\n",
              "      <td>Was Gellu Naum the leader of the surrealist mo...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>342 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Question  ... skill_label\n",
              "0      How are western-style xylophones characterised?  ...           2\n",
              "1                     Is Nairobi the capital of Kenya?  ...           3\n",
              "2    How many sister cities does the City of Melbou...  ...           3\n",
              "3                      Is the electric eel a true eel?  ...           3\n",
              "4    Does Swedish use the perfect participle to for...  ...           3\n",
              "..                                                 ...  ...         ...\n",
              "337       Where was there a vast swarm of butterflies?  ...           3\n",
              "338  What is the most common romanization standard ...  ...           3\n",
              "339     Is Jakarta the 12th largest city in the world?  ...           2\n",
              "340              What sort of turtles are ectothermic?  ...           2\n",
              "341  Was Gellu Naum the leader of the surrealist mo...  ...           3\n",
              "\n",
              "[342 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bovSLwB26TRn",
        "outputId": "445b514a-c69c-41f6-c2b8-04581cf1a3f7"
      },
      "source": [
        "test[\"question_answer\"].values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['How are western-style xylophones characterised? by a bright, sharp tone and high register',\n",
              "       'Is Nairobi the capital of Kenya? Yes',\n",
              "       'How many sister cities does the City of Melbourne have? six',\n",
              "       'Is the electric eel a true eel? No',\n",
              "       'Does Swedish use the perfect participle to form the present perfect tense? No.',\n",
              "       'Do the different species of zebras interbreed? no',\n",
              "       'What are the reasons for hunting wild ducks? Meat, eggs, and feathers',\n",
              "       'Does Romania share the same language with Moldova? Practically',\n",
              "       'Which guitars use three single-coil pickups? Fender Stratocaster type guitars.',\n",
              "       'How long does it take for the panda cubs skin to turn gray? One to two weeks',\n",
              "       'Which temperature scale did Celsius propose? Celcius',\n",
              "       'Where is Finland located? Northern Europe',\n",
              "       'Is the capital city Oslo? No',\n",
              "       'How many species of otter are there? 13',\n",
              "       \"What's the timber of ancient cimbals like? disfluent like that of small hand-bells or of the notes of the keyed harmonica\",\n",
              "       'Is University of Dhaka the largest public university in Dhaka? Yes',\n",
              "       'Is the Adephaga suborder larger than the Polyphaga suborder? yes',\n",
              "       'Are Sports in Indonesia generally male-orientated? yes',\n",
              "       \"What company administers Leichtenstein's railways? Austrian Federal Railways\",\n",
              "       'When do African elephants lie down? when they are sick or wounded',\n",
              "       'Does Modern Standard Arabic continue to evolve like other languages? yes',\n",
              "       'When did Roosevelt die? On January 6, 1919, Roosevelt died in his sleep.',\n",
              "       'What does the word duck mean? It is the common name for a number of species in the Anatidae family of birds.',\n",
              "       'Did Lincoln beat John C. Breckinridge in the 1860 election? Yes.',\n",
              "       'Was Lee Kuan Yew a successful leader of Singapore? yes',\n",
              "       'Where was Volta born? Como, Italy',\n",
              "       'Is Singapore located at the southern tip of the Korean Penisula? no',\n",
              "       'Was Coolidge the thirteenth President of the United States? Yes',\n",
              "       'Was Celsius born in Uppsala in Sweden? Yes',\n",
              "       'Are Testudines the crown group of the superorder Chelonia? Yes',\n",
              "       'What is the current estimated population of Nairobi? About 3 million',\n",
              "       'Does Romania border Hungary? Yes.',\n",
              "       'How do eels begin life? As flat and transparent larvae, called leptocephali',\n",
              "       'What is the range of lifespans of the octopus? The octopus has a short lifespan.',\n",
              "       'Is the president elected by popular vote? Yes.',\n",
              "       'What areas can giraffes inhabit? savannas, grasslands, or open woodlands',\n",
              "       'What happened in 1833? blah blah blah',\n",
              "       'Are many words describing the navy , types of ships , and other objects or activities on the water of dutch origin ? yes',\n",
              "       'When did Alessandro Volta improve  and popularize the electrophorus? Alessandro Volta improved and popularized the electrophorus in 1775.',\n",
              "       \"When was Liechtenstein's current constitution adopted? October 1921\",\n",
              "       'Name an animal that is growing in number due to recent conservation efforts Golden Eagle',\n",
              "       'What bordered by Saudi? Qatar',\n",
              "       'What became one of the most important commercial and military centres of the British Empire? Singapore',\n",
              "       'Are penguins astonishingly agile? In the water they are.',\n",
              "       'How many provinces and territories does Canada have? Ten provinces and three territories',\n",
              "       'Are pocket trumpets compact B trumpets? yes',\n",
              "       'What is the smallest species of fox? the Fennec Fox',\n",
              "       'Do all ants build nests? No, not all ants build nests.',\n",
              "       'Did France cede nearly all of its colonies in Europe in 1763? yes',\n",
              "       \"Did Grover Cleveland support women's suffrage? no\",\n",
              "       \"How can a flute's volume be increased? a flute's volume can generally be increased by making its resonator and tone holes larger\",\n",
              "       'Could Malay have originated from Sumatra island? Yes.',\n",
              "       'Is the leopard solitary? Yes',\n",
              "       \"How many Eagle Scouts were involved in Ford's funeral procession? 400\",\n",
              "       'When did Lincoln begin his political career? 1832.',\n",
              "       'How many children did Grover Cleveland have? 5',\n",
              "       'Is a polar bear at high risk of extinction? yes',\n",
              "       'What is Anders Celsius`s last name? Celsius',\n",
              "       'How many strings does a violin usually have? 4',\n",
              "       'The Savings and Loans Bank was founded, as was the first cotton-weaving mill in what year? 1861',\n",
              "       'What is the largest religious group in Canada? According to 2001 census, 77.1% of Canadians identified as being Christians; of this, Catholics make up the largest group (43.6% of Canadians). The largest Protestant denomination is the United Church of Canada; about 16.5% of Canadians declare no religious affiliation, and the remaining 6.3% were affiliated with religions other than Christianity, of which the largest is Islam numbering 1.9%, followed by Judaism: 1.1%. ',\n",
              "       'Does the de Young museum house the Asian Art Museum yes',\n",
              "       'Is romania -LRB- , -RRB- a country in southeastern europe? Yes',\n",
              "       'When do wolves molt? Late Spring or Early Summer',\n",
              "       'Is it not also one of the two official languages of the Yanbian Korean Autonomous Prefecture in China? Yes.',\n",
              "       'How many Swedish speakers were reported in Canada in 2001? There are 16,915 reported Swedish speakers in Canada.',\n",
              "       'Did James Monroe fight in the Continental Army? Yes',\n",
              "       'Is there a way to approximate the age of a turtle? Yes',\n",
              "       \"What is the city's population? 1.6 million\",\n",
              "       'What is another term for Korean adjectives? Adjectives are also known as \"descriptive verbs\" or \"stative verbs\".',\n",
              "       'In what year did the Spanish establish a fort at the Golden Gate and a mission named for Francis of Assisi on the site? In 1776, the Spanish established a fort at the Golden Gate and a mission named for Francis of Assisi on the site.',\n",
              "       'What year did Coolidge open his own law office? 1898',\n",
              "       'Was Calvin Coolidge Republican? Yes',\n",
              "       'Is it true that thermometer had 100 for the freezing point? Yes',\n",
              "       \"When did Charles-Augustin de Coulomb join his father's family in Montpeillier? From 1757 to 1759 he joined his father's family in Montpellier.\",\n",
              "       'Who did Alessandro Volta marry? Alessandro Volta married Teresa Peregrini.',\n",
              "       'Is octopus a common food in Mediterranean cuisine as well as Portuguese cuisine? Yes',\n",
              "       'Where was Isaac Newton born? At Woolsthorpe Manor in Woosthorpe-by-Colsterworth.',\n",
              "       'Does Liechtenstein have an army? No.',\n",
              "       'How many species of zebra are there? Three',\n",
              "       'What is the second main orchestral use of cymbals? The suspended cymbal is the second main orchestral use of symbals.',\n",
              "       \"What is Canada's national unemployment rate? In October 2007, Canada's national unemployment rate is 5.9%.\",\n",
              "       'How many arms does an octopus have? An octopus has four pairs of arms.',\n",
              "       'Is the Giant Panda an endangered species? yes',\n",
              "       'Is it true that the ideas of the Enlightenment shaped the development of the city? Yes.',\n",
              "       \"What is polar bear's skin color? white or cream\",\n",
              "       'Are Indian concert flutes available in standard pitches? Yes',\n",
              "       'Where was the League of Nations created? Paris',\n",
              "       'Were the koalas of South Australia largely exterminated during the early part of the 20th century, but the state has since been repopulated with Victorian stock? The koalas of South Australia were largely exterminated during the early part of the 20th century, but the state has since been repopulated with Victorian stock.',\n",
              "       'Did Volta marry before he became professor of experimental physics at the University of Pavia? No.',\n",
              "       'Do linguists often view Chinese as a language family? Yes, linguists often view Chinese as a language family.',\n",
              "       'In fact, was Avogadro `s  famous  1811  paper written in French . ) Yes',\n",
              "       'Was he a member of the Royal Superior Council on Public Instruction? Yes,  Avogadro was a member of the Royal Superior Council on Public Instruction.',\n",
              "       \"Does Indonesia have the world's hightest level of biodiversity? No\",\n",
              "       'Who discovered benzene? Michael Faraday',\n",
              "       'Is aquatic respiration in Australian freshwater turtles being studied? yes',\n",
              "       'How are Isabelline penguins different from most penguins? Because they are born with brown rather than black plumage.',\n",
              "       'Was Adams an opponent of the Stamp Act? yes',\n",
              "       'Is the main sport in Uruguay football ? Yes',\n",
              "       'Does Vietnamese have a large number of vowels? Yes, Vietnamese has a comparatively large number of vowels.',\n",
              "       'Are trumpets constructed of brass? Yes',\n",
              "       'What sort of cats are solitary? Leopards',\n",
              "       'From what type of Cymbals can a expert player obtain an enormous dynamic range? An expert player can obtain an enormous dynamic range from crash cymbals.',\n",
              "       'How is the climate in the city? The city is hot and humid.',\n",
              "       'What do river otters eat? River otters eat a variety of fish and shellfish, as well as small land mammals and birds.',\n",
              "       'Did Coolidge meet and marry Grace Anna Goodhue? yes',\n",
              "       'Where did Wilson attend law school? Wilson attended law school at University of Virginia',\n",
              "       'What is the MRT? Mass Rapid Transit system',\n",
              "       \"Wasn't Leonardo da Vinci born on April 15? Yes, Leonardo da Vinci was born on April 15.\",\n",
              "       'Where are bullet ants located? Bullet ants are located in Central and South America.',\n",
              "       'Is Romania a secular state? Yes',\n",
              "       'Was Tesla regarded as a mad scientist? yes',\n",
              "       'Does every drumhead make the same sound? no',\n",
              "       'What type of current did Tesla invent? AC',\n",
              "       'Does San Francisco have a high percentage of gay and lesbian individuals? Yes, according to the 2005 American Community Survey, San Francisco has the highest percentage of gay and lesbian individuals of any of the 50 largest U.S. cities, at 15.4%.',\n",
              "       'Where does air pollution in Beijing come from? surrounding cities and provinces',\n",
              "       'Four years after opening his shop , Watt began what? Watt began to experiment with steam after his friend, Professor John Robison, called his attention to it.',\n",
              "       'Why did Cleveland want to hide his cancer surgery from the public? because of the financial depression of the country',\n",
              "       'Which property did James Monroe sell in 1817? Monroe Hill on the grounds of the University of Virginia.',\n",
              "       'How old was Celsius when he died? 42',\n",
              "       'Are cougars larger than jaguars? no',\n",
              "       'What animal attracts the most humor and silliness? the duck',\n",
              "       'What are the three heaviest cats in the world? tiger, lion, and jaguar',\n",
              "       'Did Canadian soldiers win the Battle of Vimy Ridge in 1917? Yes',\n",
              "       'Was Isaac Newton religious? Yes, he was highly religious, though an unorthodox Christian.',\n",
              "       'Do kangaroos have many natural predators? No',\n",
              "       'Who did Ford nominate for Vice President? Bob Dole',\n",
              "       'Hassan Massoudy is a master of what genre? Arabic calligraphy',\n",
              "       'Is it true that he published his invention of the Voltaic pile battery? Yes',\n",
              "       'Does the koala fill the same ecological role as the sloth of South America? The koala fills the same ecological role as the sloth of South America.',\n",
              "       'Why do wolves howl? Howling helps pack members keep in touch, allowing them to communicate effectively in thickly forested areas or over great distances. Howling also helps to call pack members to a specific location. Howling can also serve as a declaration of territory, as shown in a dominant wolf&apos;s tendency to respond to a human imitation of a \"rival\" wolf in an area the wolf considers its own. ',\n",
              "       'Do most Japanese people employ politeness? yes',\n",
              "       'Is fifty percent or more of Korean vocabulary of Chinese origin? Yes',\n",
              "       \"What are the names of a piano's pedals? The names of a piano's pedals are una corda, sostenuto, and damper.\",\n",
              "       'What is the smallest suborder of turtles? Pleurodira',\n",
              "       \"Is Uruguay 's oldest church in San Carlos , Maldonado ? Yes\",\n",
              "       'Is Liechtenstein the smallest German-speaking country in the world? Yes',\n",
              "       'Have managed populations of European honey bees experienced substantial declines? yes',\n",
              "       'Have cymbals been used historically to suggest bacchanal? Yes',\n",
              "       'What is the life expectancy for men in Finland? 75 years',\n",
              "       \"Is Adams' birthplace part of a national park? yes\",\n",
              "       'Are wolves built for stamina? Yes',\n",
              "       'Are the largest turtles aquatic? yes',\n",
              "       'Is the largest living species the emperor penguin -LRB- aptenodytes forsteri -RRB-? Yes',\n",
              "       'How many children did Avogadro have? six',\n",
              "       'Did ants evolve from wasp-like ancestors in the mid-Cretaceous period between 110 and 130 million years ago and diversified after the rise of flowering plants? yes',\n",
              "       'Where do sea otters live? Pacific coast of North America',\n",
              "       'Were trumpet players heavily guarded? yes',\n",
              "       'Copenhagen is the capital of what country? Denmark',\n",
              "       'What was Amedeo Avogadro`s profession? professor of physics',\n",
              "       'Where was Grant born? A log cabin in Point Pleasant, Clermont County, Ohio',\n",
              "       'Does the mother care for the young? No',\n",
              "       'What trumpet was the first to be allowed in the Christian Church? Slide trumpets',\n",
              "       \"The John Adams Library , housed at the Boston Public Library , contains what? Adams's personal collection of more than 3,500 volumes\",\n",
              "       'Is Ford related with the assassination of John F. Kennedy? Yes',\n",
              "       'What principles did Newton explain for mechanics? In mechanics, Newton enunciated the principles of conservation of momentum and angular momentum',\n",
              "       'When was Charles-Augustin de Coulomb permanently stationed in Paris? Yes',\n",
              "       'How tall were the tallest prehistoric penguins? as tall as an adult human',\n",
              "       'What is the mean level of mercury in American lobsters? 0.31 ppm',\n",
              "       'Where does the word \"violin\" come from? the Middle Latin word vitula, meaning \"stringed instrument\"',\n",
              "       'Did he suffer from anxiety and increasingly frequent bouts of mental illness throughout his life, and died largely unknown, at the age of 37, from a self-inflicted gunshot wound? Yes.',\n",
              "       \"What is now part of Adams National Historical Park? John Adams' birthplace\",\n",
              "       \"What is the earliest historical reference in Europe? Arnold Schlick's Spiegel der Orgelmacher und Organisten\",\n",
              "       'What religions are found in Uruguay? Roman Catholic, Protestant, Jewish',\n",
              "       'Who appointed Harlan Fiske Stone to the Supreme Court? Coolidge',\n",
              "       'What is responsible for converting the hydrogen byproduct of fermentation into acetate? The digestive system of a kangaroo',\n",
              "       'Are Immature sea turtles not cared for by the adults ? yes',\n",
              "       \"Who is the mayor of Ottawa? Larry O'Brien\",\n",
              "       'What are the names of the two zoos in Berlin? The two zoos in Berlin are the Zoologischer Garten Berlin and the Tierpark Friedrichsfelde.',\n",
              "       'Had Monroe racked up many debts during his years of public life ? yes',\n",
              "       'Was Abraham Lincoln the first President of the United States? No',\n",
              "       'Was The SI  unit  of charge , the  coulomb , named after him? yes',\n",
              "       'Did the Dutch build the Elmina Castle? No',\n",
              "       \"Who helped to fund Roosevelt's African safari? Financed by Andrew Carnegie and his own proposed writings\",\n",
              "       \"What are the elephant's ears important for? temperature regulation\",\n",
              "       'Are hutongs disappearing? yes',\n",
              "       'Did John Adams support the Stamp Act of 1765? No',\n",
              "       'Is Vietnamese the mother tongue of the Vietnamese people? Yes',\n",
              "       'Is it the smallest and highest-pitched member of the violin family of string instruments, which also includes the viola and cello? Yes, it is the smallest and highest-pitched member of the violin family of string instruments, which also includes the viola and cello.',\n",
              "       'Are tigers solitary animals? Yes',\n",
              "       'What religion did Isaac Newton follow? he never made a public declaration of his private faith',\n",
              "       'Who frequented the circle of the British-Australian artist John Peter Russell? Van Gogh',\n",
              "       'Do both sexes of giraffe have horns? yes',\n",
              "       'What is the mean level of mercury in American lobsters? 0.31 ppm',\n",
              "       'Does Uruguay have cold summers? no',\n",
              "       'Where was James Monroe born? Westmoreland County, Virginia',\n",
              "       \"Did Monroe' wedding happen at the Trinity Church in New York? Yes\",\n",
              "       'Was Volta made a count in 1810? No.',\n",
              "       'Is the syntax of German different with different rules? yes',\n",
              "       \"Was Isaac Newton educated at The King's Schol, Grantham? yes\",\n",
              "       \"How many Eagle Scouts were involved in Ford's funeral procession? About 400\",\n",
              "       'Are they easily identified by their elbowed antennae and a distinctive node-like structure that forms a slender waist? Yes, they are easily identified by their elbowed antennae and a distinctive node-like structure that forms a slender waist.',\n",
              "       \"Did Cartier not use the word ` Canada ' to refer to not only that village , but the entire area subject to Donnacona , Chief at Stadacona ? yes\",\n",
              "       'Was watt a fellow of the Royal Society of Edinburgh and the Royal Society of London? Yes.',\n",
              "       'Is the violin shaped like an hourglass? Yes.',\n",
              "       'Can polar bears be seen under infrared photography? Polar bears are nearly invisible under infrared photography.',\n",
              "       'Is Jakarta a city Yes',\n",
              "       'Is Finnish a member of the Baltic-Finnic subgroup of the Uralic languages? Yes',\n",
              "       'Where is old Ghana in relation to present Ghana? 500 miles north',\n",
              "       \"Has Indonesia the world 's largest Muslim population ? yes\",\n",
              "       'Does the octopus have a hard beak? Yes, the octopus has a hard beak.',\n",
              "       'Is the study of beetles called coleopterology , and its practitioners are coleopterists ? Yes.',\n",
              "       'What is the bridge used for? The transfer of string vibrations.',\n",
              "       'Is James Monrow the fifth president of US? Yes',\n",
              "       'Where is Charles-Augustin de Coulomb from? France',\n",
              "       \"Are Gray Wolves native to North America? No. Current theory suggests that it's from Eurasia\",\n",
              "       'Are there a large number of Jews living in Egypt today? No',\n",
              "       'Are all dialects of Korean similar to each other? Yes',\n",
              "       'When is the first record of S08_settlement in Singapore? second century AD',\n",
              "       'Where are the Western Arabic numerals used? present-day North Africa',\n",
              "       'When did Charles-Augustin de Coulomb retire to a small estate he possessed at Blois? Charles-Augustin de Coulomb retired to a small estate he possessed at Blois on the outbreak of the revolution in 1789.',\n",
              "       'Was Alessandro Volta a professor of chemistry? Alessandro Volta was not a professor of chemistry.',\n",
              "       'What is the SI unit measuring magnetic flux density or magnetic induction? the tesla',\n",
              "       'Where do sea turtles lay their eggs? Holes Dug into the Mud or Sand',\n",
              "       'Is Liechtenstein heavily urbanized? No',\n",
              "       \"Where was much of Montreal's industry during the late 19th and early-to-mid 20th century? The Sud-Ouest borough was home to much of the city's industry during the late 19th and early-to-mid 20th century. \",\n",
              "       'When was the Six Day War? 1967',\n",
              "       'Who determined the dependence of the boiling of water with atmospheric pressure? Anders Celsius',\n",
              "       'How do the Java and Bali use xylophones? In gamelan ensembles',\n",
              "       'How many civilians died in the 1998 U.S. embassy bombing? Over two hundred',\n",
              "       'What are violins made of? different types of wood',\n",
              "       'When was the An Shi Rebellion launched? in 755 AD',\n",
              "       \"Is the leopard -LRB- panthera pardus -RRB- an old world mammal of the felidae family and the smallest of the four (`` ` big cats ('' ' of the genus panthera , along with the tiger , lion , and jaguar? Yes\",\n",
              "       \"Was Henri Becquerel first in his family to occupy the physics chair at the Museum National d'Histoire Naturelle? No\",\n",
              "       \"Is Indonesia the world's largest archipelagic state? yes\",\n",
              "       'Where does the German President live? The German President lives west of the center, Schloss Bellevue.',\n",
              "       'Where are the Western Arabic numerals used? North Africa',\n",
              "       'What allows a duck to filter water out of the side of their beaks and keep food inside? Tiny rows of plates called lamellae',\n",
              "       \"What would a tiger do when seized by a crocodile? strike at the reptile's eyes with its paws\",\n",
              "       'How many years ago was the Luther Bible by Martin Luther printed? 475',\n",
              "       'What happens when mothers lose a chick? They sometimes attempt to \"steal\" another chick.',\n",
              "       'Who were the Orkhon inscriptions built for? The Orkhon inscriptions were erected in honour of the prince Kul Tigin and his brother Emperor Bilge Khan.',\n",
              "       'Has the terrain in the city been artificially raised? yes',\n",
              "       'What do river otters eat? a variety of fish and shellfish, as well as small land mammals and birds',\n",
              "       'What prompted the city to upgrade its building codes The threat of major earthquakes',\n",
              "       'Why is the giant otter becoming increasingly rare? poaching, habitat loss, and the use of mercury in illegal alluvial gold mining',\n",
              "       \"What have become flippers, useless for flight in the air? Penguins' wings\",\n",
              "       'Why does the cornet have a slightly mellower tone than the trumpet? because it has conical bores',\n",
              "       'Approximately how many species of Testudines are alive today? 300',\n",
              "       'Are otters playful animals? yes',\n",
              "       'Did lincoln have 18 months of schooling? Yes',\n",
              "       'Who heavily influenced the architecture and culture of Montevideo? European immigrants',\n",
              "       'What was the Faraday effect first called? diamagnetism',\n",
              "       'Does it have a border with Norway? Yes',\n",
              "       'Is an official language of Canada German? No.',\n",
              "       'What is also the distance that Antarctic tourists are told to keep from penguins? 3 meters',\n",
              "       'Did Lincoln ever represent Alton & Sangamon Railroad? Yes',\n",
              "       \"What are some of the cougar's primary food sources? ungulates such as deer, elk, and bighorn sheep, as well as domestic cattle, horses, and sheep\",\n",
              "       \"Is Melbourne home to Australia's busiest seaport? Yes\",\n",
              "       'Did Bartolomeo Cristofori invent the modern piano? Yes',\n",
              "       'Where is the Park of the Reserve located? Near the downtown area.',\n",
              "       'What did Anders Celsius determine about the boiling of water? dependence with atmospheric pressure',\n",
              "       'What city in the UK has been subjected to bouts of terrorism? London has been subjected to bouts of terrorism.',\n",
              "       'What foods do pandas eat? bamboo, honeys, eggs, fish, yams, shrub leaves, oranges, and bananas',\n",
              "       'When did Adams graduate from college? 1755.',\n",
              "       'Can the origins of cymbals be traced back to prehistoric times? yes',\n",
              "       'Which type of beetle is a pest of potato plants? Colorado potato beetle',\n",
              "       'Is there a way to approximate the age of a turtle? yes',\n",
              "       'What trumpet was the first to be allowed in the Christian Church? slide trumpets',\n",
              "       'What is the battery made by Alessandro Volta credited as? the first electrochemical cell',\n",
              "       'Is it a disadvantage for something to be unsafe to handle? yes',\n",
              "       'The ideas of the Enlightenment shaped the development of what? the city, Lima',\n",
              "       'Has the terrain in the city been artificially raised? Yes.',\n",
              "       'Is the SI unit for radioactivity named after him? Yes',\n",
              "       'Was the Italian 10.000 lira banknote created before the euro? yes',\n",
              "       'How many times has Uruguay won the World Cup? Twice. ',\n",
              "       'Where was Isaac Newton born? Woolsthorpe Manor in Woolsthorpe-by-Colsterworth',\n",
              "       'Was Gerald Ford the 38th President of the United States? yes',\n",
              "       'When was the pan flute spread to other parts of Europe? After the 7th century BC',\n",
              "       'Who was President when Wilson finished Congressional Government? Grover Cleveland',\n",
              "       'Is the ant a marsupial? no',\n",
              "       'What happened in 1860? Vincent van Gogh attended the Zundert village school from 1860.',\n",
              "       'Was Grover Cleveland the twenty-seventh president of the United States? No.',\n",
              "       'With what party did Adams run for presidency? The Federalist Party',\n",
              "       'What are the differences between English and Swedish pronouns? Swedish pronouns are basically the same as those of English but distinguish two genders and have an additional object form, derived from the old dative form, as well as a distinct genitive case.',\n",
              "       'Was John Calvin Coolidge Jr. was born in Las Vegas? No',\n",
              "       'When did Isaac Newton discover the generalized binomial theorem? In 1665.',\n",
              "       'What field did Woodrow Wilson leave law practice to study? history and political science',\n",
              "       'Is the standard of living in San Franciscio high? Yes',\n",
              "       \"What is the name of the largest church in Montreal? Saint Joseph's Oratory is the largest church in Montreal.\",\n",
              "       'Are the strings of a classical lyre made of gut? Yes',\n",
              "       'Where did the xylophone originate? Indonesia',\n",
              "       \"Is it advantageous for a grand piano's metal plate to be quite massive? It is advantageous for the plate to be quite massive.\",\n",
              "       'Where is Melbourne situated? boundary of the very hot inland areas and the cold southern ocean',\n",
              "       'How many countries in Europe are bigger than Romania?   eleven',\n",
              "       'Where did he serve two terms? the Church of Scotland',\n",
              "       'What fictional stories include a main character named Santiago? Interview with the Vampire, The Alchemist, and others',\n",
              "       'What is the sustain pedal called? damper pedal',\n",
              "       'What do beetles eat? Some are generalists, eating both plants and animals. Other beetles are highly specialised in their diet.',\n",
              "       'Was Thedore Roosevelt  a member of the Republican Party? Yes',\n",
              "       'Give an example of the ten Beta World Cities.  San Trancisco',\n",
              "       'When was Coolidge born? Plymouth, Windsor County, Vermont',\n",
              "       'Is an acoustic guitar dependent on an external device? No.',\n",
              "       'Is Golden Gate Park the largest city park yes',\n",
              "       'Is a bee an insect? yes',\n",
              "       'What was Michael Faraday`s profession? chemist and physicist',\n",
              "       'Does Qatar rank as the eighth richest country in the world per capita? No.',\n",
              "       'Oxygen is what? One kind of gas obtained via a tracheal system.',\n",
              "       \"Who were the midnight judges? They were a series of judges, so called because most of them were formally appointed days before Adams' presidential term expired\",\n",
              "       'Is polar bear a mammal? Yes',\n",
              "       'What is a hybrid animal resulting from a union between a leopard and a puma? a pumapard',\n",
              "       'Does Theodore Roosevelt have a brother? Yes',\n",
              "       'What food gave Isaac Newton clues to his theory of gravity? apple',\n",
              "       'What is a colectivo? Automobiles that renders express service on some major roads of the Lima Metropolitan Area.',\n",
              "       'Did he experiment with individual cells? Yes',\n",
              "       'Is Malay an agglutinative language? Yes.',\n",
              "       'How old is the oldest known representation of a guitar-like intrument being played? 3,300 years old',\n",
              "       \"Did Johann Josef Loschmidt first calculate the value of Avogadro's number? yes\",\n",
              "       \"How does a Mallard's tongue work? It uses short spikes to push struggling prey and other food down its throat\",\n",
              "       'What is the basic word order in Malay? Subject Object Verb.',\n",
              "       'What is the Faraday effect? The Faraday effect is the phenomenon that the plane of polarisation of linearly polarised light can be rotated by the application of an external magnetic field aligned in the direction the light is moving.',\n",
              "       'What is the official language of Turkey? Turkish.',\n",
              "       \"What was Grant's political affiliation? Republican\",\n",
              "       'Who did Newton see as the master creator? God',\n",
              "       'Around how many recognized octopus species are there? There are around 300 recognized octopus species.',\n",
              "       'What is the caridoid escape reaction? Swimming backwards quickly by curling and uncurling their abdomen.',\n",
              "       'What is the middle pedal called on grand pianos? the sostenuto pedal.',\n",
              "       'Was Malay language written using Pallava? Yes',\n",
              "       'Why are otters vulnerable to prey depletion? Prey-dependence',\n",
              "       'What religions are found in Uruguay? Roman Catholic, Protestant, Jewish, and nonprofessing.',\n",
              "       \"Is English Ghana's official language? yes\",\n",
              "       \"In what language was his 1811 paper published? Avogadro's 1811 paper was published in French.\",\n",
              "       'Does the de Young museum house the Asian Art Museum No',\n",
              "       'Are violas and cellos in the same family of instruments as violins? yes',\n",
              "       'Is a guitar an instrument? yes',\n",
              "       'What are some common predators of ducks? Pike, crocodilians, herons, hawks and eagles.',\n",
              "       'Did Grant & Perkins not sell harnesses , saddles , and other leather goods and purchase hides from farmers in the prosperous Galena area ? they did',\n",
              "       'Was his 1800  paper written in French? Yes',\n",
              "       'When was his last painting for the Post published? 1963',\n",
              "       \"Where did Coolidge's grandfather had government offices? Plymouth\",\n",
              "       'Where is the word \"swan\" derived from? Old English swan.',\n",
              "       'How many legs do lobsters have? 10',\n",
              "       'Are more residents employed by small businesses than in 1977? No',\n",
              "       'Was the SI unit of charge named after Charles-Augustin de Coulomb? Yes, the SI unit of charge, the coulomb, was named after him.',\n",
              "       'Copenhagen is ranked number one worldwide for which things? Most Livable City, Location Ranking Survey',\n",
              "       'What happened in 1810? Volta was made a count by Napoleon.',\n",
              "       'What kind of piano did Irving Berlin play? transposing piano',\n",
              "       'Where was there a vast swarm of butterflies? In Kyoto there was a vast swarm of butterflies.',\n",
              "       'What is the most common romanization standard for Standard Mandarin today? Hanyu Pinyin',\n",
              "       'Is Jakarta the 12th largest city in the world? yes',\n",
              "       'What sort of turtles are ectothermic? all of them',\n",
              "       'Was Gellu Naum the leader of the surrealist movement in Romania ? Yes'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "P8xfcPLU5sR5",
        "outputId": "1f0206df-f77d-4654-cc15-ad9c082cca17"
      },
      "source": [
        "\n",
        "import re\n",
        "\n",
        "test[\"question_answer\"] = test[\"question_answer\"].apply(lambda x : clean_sentence(x))\n",
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>DifficultyFromAnswerer</th>\n",
              "      <th>difficulty_label</th>\n",
              "      <th>question_answer</th>\n",
              "      <th>skill_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How are western-style xylophones characterised?</td>\n",
              "      <td>by a bright, sharp tone and high register</td>\n",
              "      <td>medium</td>\n",
              "      <td>2</td>\n",
              "      <td>How are western-style xylophones characterised...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Is Nairobi the capital of Kenya?</td>\n",
              "      <td>Yes</td>\n",
              "      <td>easy</td>\n",
              "      <td>0</td>\n",
              "      <td>Is Nairobi the capital of Kenya? Yes</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How many sister cities does the City of Melbou...</td>\n",
              "      <td>six</td>\n",
              "      <td>medium</td>\n",
              "      <td>2</td>\n",
              "      <td>How many sister cities does the City of Melbou...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Is the electric eel a true eel?</td>\n",
              "      <td>No</td>\n",
              "      <td>easy</td>\n",
              "      <td>0</td>\n",
              "      <td>Is the electric eel a true eel? No</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Does Swedish use the perfect participle to for...</td>\n",
              "      <td>No.</td>\n",
              "      <td>easy</td>\n",
              "      <td>0</td>\n",
              "      <td>Does Swedish use the perfect participle to for...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>337</th>\n",
              "      <td>Where was there a vast swarm of butterflies?</td>\n",
              "      <td>In Kyoto there was a vast swarm of butterflies.</td>\n",
              "      <td>medium</td>\n",
              "      <td>2</td>\n",
              "      <td>Where was there a vast swarm of butterflies? I...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>338</th>\n",
              "      <td>What is the most common romanization standard ...</td>\n",
              "      <td>Hanyu Pinyin</td>\n",
              "      <td>medium</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the most common romanization standard ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>339</th>\n",
              "      <td>Is Jakarta the 12th largest city in the world?</td>\n",
              "      <td>yes</td>\n",
              "      <td>medium</td>\n",
              "      <td>2</td>\n",
              "      <td>Is Jakarta the 12th largest city in the world?...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340</th>\n",
              "      <td>What sort of turtles are ectothermic?</td>\n",
              "      <td>all of them</td>\n",
              "      <td>medium</td>\n",
              "      <td>2</td>\n",
              "      <td>What sort of turtles are ectothermic? all of them</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341</th>\n",
              "      <td>Was Gellu Naum the leader of the surrealist mo...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>easy</td>\n",
              "      <td>0</td>\n",
              "      <td>Was Gellu Naum the leader of the surrealist mo...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>342 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Question  ... skill_label\n",
              "0      How are western-style xylophones characterised?  ...           2\n",
              "1                     Is Nairobi the capital of Kenya?  ...           3\n",
              "2    How many sister cities does the City of Melbou...  ...           3\n",
              "3                      Is the electric eel a true eel?  ...           3\n",
              "4    Does Swedish use the perfect participle to for...  ...           3\n",
              "..                                                 ...  ...         ...\n",
              "337       Where was there a vast swarm of butterflies?  ...           3\n",
              "338  What is the most common romanization standard ...  ...           3\n",
              "339     Is Jakarta the 12th largest city in the world?  ...           2\n",
              "340              What sort of turtles are ectothermic?  ...           2\n",
              "341  Was Gellu Naum the leader of the surrealist mo...  ...           3\n",
              "\n",
              "[342 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuvNfYNjcJw8"
      },
      "source": [
        "val = val.dropna(subset=[\"question_answer\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOkwP1-lcKA-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQ_zCeR06Z4P",
        "outputId": "8c92e70d-3f5f-4e4c-a8a8-c0db5654c8e1"
      },
      "source": [
        "test[\"question_answer\"].values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['How are western-style xylophones characterised? by a bright, sharp tone and high register',\n",
              "       'Is Nairobi the capital of Kenya? Yes',\n",
              "       'How many sister cities does the City of Melbourne have? six',\n",
              "       'Is the electric eel a true eel? No',\n",
              "       'Does Swedish use the perfect participle to form the present perfect tense? No.',\n",
              "       'Do the different species of zebras interbreed? no',\n",
              "       'What are the reasons for hunting wild ducks? Meat, eggs, and feathers',\n",
              "       'Does Romania share the same language with Moldova? Practically',\n",
              "       'Which guitars use three single-coil pickups? Fender Stratocaster type guitars.',\n",
              "       'How long does it take for the panda cubs skin to turn gray? One to two weeks',\n",
              "       'Which temperature scale did Celsius propose? Celcius',\n",
              "       'Where is Finland located? Northern Europe',\n",
              "       'Is the capital city Oslo? No',\n",
              "       'How many species of otter are there? 13',\n",
              "       \"What's the timber of ancient cimbals like? disfluent like that of small hand-bells or of the notes of the keyed harmonica\",\n",
              "       'Is University of Dhaka the largest public university in Dhaka? Yes',\n",
              "       'Is the Adephaga suborder larger than the Polyphaga suborder? yes',\n",
              "       'Are Sports in Indonesia generally male-orientated? yes',\n",
              "       \"What company administers Leichtenstein's railways? Austrian Federal Railways\",\n",
              "       'When do African elephants lie down? when they are sick or wounded',\n",
              "       'Does Modern Standard Arabic continue to evolve like other languages? yes',\n",
              "       'When did Roosevelt die? On January 6, 1919, Roosevelt died in his sleep.',\n",
              "       'What does the word duck mean? It is the common name for a number of species in the Anatidae family of birds.',\n",
              "       'Did Lincoln beat John C. Breckinridge in the 1860 election? Yes.',\n",
              "       'Was Lee Kuan Yew a successful leader of Singapore? yes',\n",
              "       'Where was Volta born? Como, Italy',\n",
              "       'Is Singapore located at the southern tip of the Korean Penisula? no',\n",
              "       'Was Coolidge the thirteenth President of the United States? Yes',\n",
              "       'Was Celsius born in Uppsala in Sweden? Yes',\n",
              "       'Are Testudines the crown group of the superorder Chelonia? Yes',\n",
              "       'What is the current estimated population of Nairobi? About 3 million',\n",
              "       'Does Romania border Hungary? Yes.',\n",
              "       'How do eels begin life? As flat and transparent larvae, called leptocephali',\n",
              "       'What is the range of lifespans of the octopus? The octopus has a short lifespan.',\n",
              "       'Is the president elected by popular vote? Yes.',\n",
              "       'What areas can giraffes inhabit? savannas, grasslands, or open woodlands',\n",
              "       'What happened in 1833? blah blah blah',\n",
              "       'Are many words describing the navy , types of ships , and other objects or activities on the water of dutch origin ? yes',\n",
              "       'When did Alessandro Volta improve and popularize the electrophorus? Alessandro Volta improved and popularized the electrophorus in 1775.',\n",
              "       \"When was Liechtenstein's current constitution adopted? October 1921\",\n",
              "       'Name an animal that is growing in number due to recent conservation efforts Golden Eagle',\n",
              "       'What bordered by Saudi? Qatar',\n",
              "       'What became one of the most important commercial and military centres of the British Empire? Singapore',\n",
              "       'Are penguins astonishingly agile? In the water they are.',\n",
              "       'How many provinces and territories does Canada have? Ten provinces and three territories',\n",
              "       'Are pocket trumpets compact B trumpets? yes',\n",
              "       'What is the smallest species of fox? the Fennec Fox',\n",
              "       'Do all ants build nests? No, not all ants build nests.',\n",
              "       'Did France cede nearly all of its colonies in Europe in 1763? yes',\n",
              "       \"Did Grover Cleveland support women's suffrage? no\",\n",
              "       \"How can a flute's volume be increased? a flute's volume can generally be increased by making its resonator and tone holes larger\",\n",
              "       'Could Malay have originated from Sumatra island? Yes.',\n",
              "       'Is the leopard solitary? Yes',\n",
              "       \"How many Eagle Scouts were involved in Ford's funeral procession? 400\",\n",
              "       'When did Lincoln begin his political career? 1832.',\n",
              "       'How many children did Grover Cleveland have? 5',\n",
              "       'Is a polar bear at high risk of extinction? yes',\n",
              "       'What is Anders Celsius`s last name? Celsius',\n",
              "       'How many strings does a violin usually have? 4',\n",
              "       'The Savings and Loans Bank was founded, as was the first cotton-weaving mill in what year? 1861',\n",
              "       'What is the largest religious group in Canada? According to 2001 census, 77.1% of Canadians identified as being Christians; of this, Catholics make up the largest group (43.6% of Canadians). The largest Protestant denomination is the United Church of Canada; about 16.5% of Canadians declare no religious affiliation, and the remaining 6.3% were affiliated with religions other than Christianity, of which the largest is Islam numbering 1.9%, followed by Judaism: 1.1%.',\n",
              "       'Does the de Young museum house the Asian Art Museum yes',\n",
              "       'Is romania -LRB- , -RRB- a country in southeastern europe? Yes',\n",
              "       'When do wolves molt? Late Spring or Early Summer',\n",
              "       'Is it not also one of the two official languages of the Yanbian Korean Autonomous Prefecture in China? Yes.',\n",
              "       'How many Swedish speakers were reported in Canada in 2001? There are 16,915 reported Swedish speakers in Canada.',\n",
              "       'Did James Monroe fight in the Continental Army? Yes',\n",
              "       'Is there a way to approximate the age of a turtle? Yes',\n",
              "       \"What is the city's population? 1.6 million\",\n",
              "       'What is another term for Korean adjectives? Adjectives are also known as \"descriptive verbs\" or \"stative verbs\".',\n",
              "       'In what year did the Spanish establish a fort at the Golden Gate and a mission named for Francis of Assisi on the site? In 1776, the Spanish established a fort at the Golden Gate and a mission named for Francis of Assisi on the site.',\n",
              "       'What year did Coolidge open his own law office? 1898',\n",
              "       'Was Calvin Coolidge Republican? Yes',\n",
              "       'Is it true that thermometer had 100 for the freezing point? Yes',\n",
              "       \"When did Charles-Augustin de Coulomb join his father's family in Montpeillier? From 1757 to 1759 he joined his father's family in Montpellier.\",\n",
              "       'Who did Alessandro Volta marry? Alessandro Volta married Teresa Peregrini.',\n",
              "       'Is octopus a common food in Mediterranean cuisine as well as Portuguese cuisine? Yes',\n",
              "       'Where was Isaac Newton born? At Woolsthorpe Manor in Woosthorpe-by-Colsterworth.',\n",
              "       'Does Liechtenstein have an army? No.',\n",
              "       'How many species of zebra are there? Three',\n",
              "       'What is the second main orchestral use of cymbals? The suspended cymbal is the second main orchestral use of symbals.',\n",
              "       \"What is Canada's national unemployment rate? In October 2007, Canada's national unemployment rate is 5.9%.\",\n",
              "       'How many arms does an octopus have? An octopus has four pairs of arms.',\n",
              "       'Is the Giant Panda an endangered species? yes',\n",
              "       'Is it true that the ideas of the Enlightenment shaped the development of the city? Yes.',\n",
              "       \"What is polar bear's skin color? white or cream\",\n",
              "       'Are Indian concert flutes available in standard pitches? Yes',\n",
              "       'Where was the League of Nations created? Paris',\n",
              "       'Were the koalas of South Australia largely exterminated during the early part of the 20th century, but the state has since been repopulated with Victorian stock? The koalas of South Australia were largely exterminated during the early part of the 20th century, but the state has since been repopulated with Victorian stock.',\n",
              "       'Did Volta marry before he became professor of experimental physics at the University of Pavia? No.',\n",
              "       'Do linguists often view Chinese as a language family? Yes, linguists often view Chinese as a language family.',\n",
              "       'In fact, was Avogadro `s famous 1811 paper written in French . ) Yes',\n",
              "       'Was he a member of the Royal Superior Council on Public Instruction? Yes, Avogadro was a member of the Royal Superior Council on Public Instruction.',\n",
              "       \"Does Indonesia have the world's hightest level of biodiversity? No\",\n",
              "       'Who discovered benzene? Michael Faraday',\n",
              "       'Is aquatic respiration in Australian freshwater turtles being studied? yes',\n",
              "       'How are Isabelline penguins different from most penguins? Because they are born with brown rather than black plumage.',\n",
              "       'Was Adams an opponent of the Stamp Act? yes',\n",
              "       'Is the main sport in Uruguay football ? Yes',\n",
              "       'Does Vietnamese have a large number of vowels? Yes, Vietnamese has a comparatively large number of vowels.',\n",
              "       'Are trumpets constructed of brass? Yes',\n",
              "       'What sort of cats are solitary? Leopards',\n",
              "       'From what type of Cymbals can a expert player obtain an enormous dynamic range? An expert player can obtain an enormous dynamic range from crash cymbals.',\n",
              "       'How is the climate in the city? The city is hot and humid.',\n",
              "       'What do river otters eat? River otters eat a variety of fish and shellfish, as well as small land mammals and birds.',\n",
              "       'Did Coolidge meet and marry Grace Anna Goodhue? yes',\n",
              "       'Where did Wilson attend law school? Wilson attended law school at University of Virginia',\n",
              "       'What is the MRT? Mass Rapid Transit system',\n",
              "       \"Wasn't Leonardo da Vinci born on April 15? Yes, Leonardo da Vinci was born on April 15.\",\n",
              "       'Where are bullet ants located? Bullet ants are located in Central and South America.',\n",
              "       'Is Romania a secular state? Yes',\n",
              "       'Was Tesla regarded as a mad scientist? yes',\n",
              "       'Does every drumhead make the same sound? no',\n",
              "       'What type of current did Tesla invent? AC',\n",
              "       'Does San Francisco have a high percentage of gay and lesbian individuals? Yes, according to the 2005 American Community Survey, San Francisco has the highest percentage of gay and lesbian individuals of any of the 50 largest U.S. cities, at 15.4%.',\n",
              "       'Where does air pollution in Beijing come from? surrounding cities and provinces',\n",
              "       'Four years after opening his shop , Watt began what? Watt began to experiment with steam after his friend, Professor John Robison, called his attention to it.',\n",
              "       'Why did Cleveland want to hide his cancer surgery from the public? because of the ficial depression of the country',\n",
              "       'Which property did James Monroe sell in 1817? Monroe Hill on the grounds of the University of Virginia.',\n",
              "       'How old was Celsius when he died? 42',\n",
              "       'Are cougars larger than jaguars? no',\n",
              "       'What animal attracts the most humor and silliness? the duck',\n",
              "       'What are the three heaviest cats in the world? tiger, lion, and jaguar',\n",
              "       'Did Canadian soldiers win the Battle of Vimy Ridge in 1917? Yes',\n",
              "       'Was Isaac Newton religious? Yes, he was highly religious, though an unorthodox Christian.',\n",
              "       'Do kangaroos have many natural predators? No',\n",
              "       'Who did Ford nominate for Vice President? Bob Dole',\n",
              "       'Hassan Massoudy is a master of what genre? Arabic calligraphy',\n",
              "       'Is it true that he published his invention of the Voltaic pile battery? Yes',\n",
              "       'Does the koala fill the same ecological role as the sloth of South America? The koala fills the same ecological role as the sloth of South America.',\n",
              "       'Why do wolves howl? Howling helps pack members keep in touch, allowing them to communicate effectively in thickly forested areas or over great distances. Howling also helps to call pack members to a specific location. Howling can also serve as a declaration of territory, as shown in a domit wolf&apos;s tendency to respond to a human imitation of a \"rival\" wolf in an area the wolf considers its own.',\n",
              "       'Do most Japanese people employ politeness? yes',\n",
              "       'Is fifty percent or more of Korean vocabulary of Chinese origin? Yes',\n",
              "       \"What are the names of a piano's pedals? The names of a piano's pedals are una corda, sostenuto, and damper.\",\n",
              "       'What is the smallest suborder of turtles? Pleurodira',\n",
              "       \"Is Uruguay 's oldest church in San Carlos , Maldonado ? Yes\",\n",
              "       'Is Liechtenstein the smallest German-speaking country in the world? Yes',\n",
              "       'Have managed populations of European honey bees experienced substantial declines? yes',\n",
              "       'Have cymbals been used historically to suggest bacchanal? Yes',\n",
              "       'What is the life expectancy for men in Finland? 75 years',\n",
              "       \"Is Adams' birthplace part of a national park? yes\",\n",
              "       'Are wolves built for stamina? Yes',\n",
              "       'Are the largest turtles aquatic? yes',\n",
              "       'Is the largest living species the emperor penguin -LRB- aptenodytes forsteri -RRB-? Yes',\n",
              "       'How many children did Avogadro have? six',\n",
              "       'Did ants evolve from wasp-like ancestors in the mid-Cretaceous period between 110 and 130 million years ago and diversified after the rise of flowering plants? yes',\n",
              "       'Where do sea otters live? Pacific coast of North America',\n",
              "       'Were trumpet players heavily guarded? yes',\n",
              "       'Copenhagen is the capital of what country? Denmark',\n",
              "       'What was Amedeo Avogadro`s profession? professor of physics',\n",
              "       'Where was Grant born? A log cabin in Point Pleasant, Clermont County, Ohio',\n",
              "       'Does the mother care for the young? No',\n",
              "       'What trumpet was the first to be allowed in the Christian Church? Slide trumpets',\n",
              "       \"The John Adams Library , housed at the Boston Public Library , contains what? Adams's personal collection of more than 3,500 volumes\",\n",
              "       'Is Ford related with the assassination of John F. Kennedy? Yes',\n",
              "       'What principles did Newton explain for mechanics? In mechanics, Newton enunciated the principles of conservation of momentum and angular momentum',\n",
              "       'When was Charles-Augustin de Coulomb permanently stationed in Paris? Yes',\n",
              "       'How tall were the tallest prehistoric penguins? as tall as an adult human',\n",
              "       'What is the mean level of mercury in American lobsters? 0.31 ppm',\n",
              "       'Where does the word \"violin\" come from? the Middle Latin word vitula, meaning \"stringed instrument\"',\n",
              "       'Did he suffer from anxiety and increasingly frequent bouts of mental illness throughout his life, and died largely unknown, at the age of 37, from a self-inflicted gunshot wound? Yes.',\n",
              "       \"What is now part of Adams National Historical Park? John Adams' birthplace\",\n",
              "       \"What is the earliest historical reference in Europe? Arnold Schlick's Spiegel der Orgelmacher und Organisten\",\n",
              "       'What religions are found in Uruguay? Roman Catholic, Protestant, Jewish',\n",
              "       'Who appointed Harlan Fiske Stone to the Supreme Court? Coolidge',\n",
              "       'What is responsible for converting the hydrogen byproduct of fermentation into acetate? The digestive system of a kangaroo',\n",
              "       'Are Immature sea turtles not cared for by the adults ? yes',\n",
              "       \"Who is the mayor of Ottawa? Larry O'Brien\",\n",
              "       'What are the names of the two zoos in Berlin? The two zoos in Berlin are the Zoologischer Garten Berlin and the Tierpark Friedrichsfelde.',\n",
              "       'Had Monroe racked up many debts during his years of public life ? yes',\n",
              "       'Was Abraham Lincoln the first President of the United States? No',\n",
              "       'Was The SI unit of charge , the coulomb , named after him? yes',\n",
              "       'Did the Dutch build the Elmina Castle? No',\n",
              "       \"Who helped to fund Roosevelt's African safari? Ficed by Andrew Carnegie and his own proposed writings\",\n",
              "       \"What are the elephant's ears important for? temperature regulation\",\n",
              "       'Are hutongs disappearing? yes',\n",
              "       'Did John Adams support the Stamp Act of 1765? No',\n",
              "       'Is Vietnamese the mother tongue of the Vietnamese people? Yes',\n",
              "       'Is it the smallest and highest-pitched member of the violin family of string instruments, which also includes the viola and cello? Yes, it is the smallest and highest-pitched member of the violin family of string instruments, which also includes the viola and cello.',\n",
              "       'Are tigers solitary animals? Yes',\n",
              "       'What religion did Isaac Newton follow? he never made a public declaration of his private faith',\n",
              "       'Who frequented the circle of the British-Australian artist John Peter Russell? Van Gogh',\n",
              "       'Do both sexes of giraffe have horns? yes',\n",
              "       'What is the mean level of mercury in American lobsters? 0.31 ppm',\n",
              "       'Does Uruguay have cold summers? no',\n",
              "       'Where was James Monroe born? Westmoreland County, Virginia',\n",
              "       \"Did Monroe' wedding happen at the Trinity Church in New York? Yes\",\n",
              "       'Was Volta made a count in 1810? No.',\n",
              "       'Is the syntax of German different with different rules? yes',\n",
              "       \"Was Isaac Newton educated at The King's Schol, Grantham? yes\",\n",
              "       \"How many Eagle Scouts were involved in Ford's funeral procession? About 400\",\n",
              "       'Are they easily identified by their elbowed antennae and a distinctive node-like structure that forms a slender waist? Yes, they are easily identified by their elbowed antennae and a distinctive node-like structure that forms a slender waist.',\n",
              "       \"Did Cartier not use the word ` Canada ' to refer to not only that village , but the entire area subject to Donnacona , Chief at Stadacona ? yes\",\n",
              "       'Was watt a fellow of the Royal Society of Edinburgh and the Royal Society of London? Yes.',\n",
              "       'Is the violin shaped like an hourglass? Yes.',\n",
              "       'Can polar bears be seen under infrared photography? Polar bears are nearly invisible under infrared photography.',\n",
              "       'Is Jakarta a city Yes',\n",
              "       'Is Finnish a member of the Baltic-Finnic subgroup of the Uralic languages? Yes',\n",
              "       'Where is old Ghana in relation to present Ghana? 500 miles north',\n",
              "       \"Has Indonesia the world 's largest Muslim population ? yes\",\n",
              "       'Does the octopus have a hard beak? Yes, the octopus has a hard beak.',\n",
              "       'Is the study of beetles called coleopterology , and its practitioners are coleopterists ? Yes.',\n",
              "       'What is the bridge used for? The transfer of string vibrations.',\n",
              "       'Is James Monrow the fifth president of US? Yes',\n",
              "       'Where is Charles-Augustin de Coulomb from? France',\n",
              "       \"Are Gray Wolves native to North America? No. Current theory suggests that it's from Eurasia\",\n",
              "       'Are there a large number of Jews living in Egypt today? No',\n",
              "       'Are all dialects of Korean similar to each other? Yes',\n",
              "       'When is the first record of S08_settlement in Singapore? second century AD',\n",
              "       'Where are the Western Arabic numerals used? present-day North Africa',\n",
              "       'When did Charles-Augustin de Coulomb retire to a small estate he possessed at Blois? Charles-Augustin de Coulomb retired to a small estate he possessed at Blois on the outbreak of the revolution in 1789.',\n",
              "       'Was Alessandro Volta a professor of chemistry? Alessandro Volta was not a professor of chemistry.',\n",
              "       'What is the SI unit measuring magnetic flux density or magnetic induction? the tesla',\n",
              "       'Where do sea turtles lay their eggs? Holes Dug into the Mud or Sand',\n",
              "       'Is Liechtenstein heavily urbanized? No',\n",
              "       \"Where was much of Montreal's industry during the late 19th and early-to-mid 20th century? The Sud-Ouest borough was home to much of the city's industry during the late 19th and early-to-mid 20th century.\",\n",
              "       'When was the Six Day War? 1967',\n",
              "       'Who determined the dependence of the boiling of water with atmospheric pressure? Anders Celsius',\n",
              "       'How do the Java and Bali use xylophones? In gamelan ensembles',\n",
              "       'How many civilians died in the 1998 U.S. embassy bombing? Over two hundred',\n",
              "       'What are violins made of? different types of wood',\n",
              "       'When was the An Shi Rebellion launched? in 755 AD',\n",
              "       \"Is the leopard -LRB- panthera pardus -RRB- an old world mammal of the felidae family and the smallest of the four (`` ` big cats ('' ' of the genus panthera , along with the tiger , lion , and jaguar? Yes\",\n",
              "       \"Was Henri Becquerel first in his family to occupy the physics chair at the Museum National d'Histoire Naturelle? No\",\n",
              "       \"Is Indonesia the world's largest archipelagic state? yes\",\n",
              "       'Where does the German President live? The German President lives west of the center, Schloss Bellevue.',\n",
              "       'Where are the Western Arabic numerals used? North Africa',\n",
              "       'What allows a duck to filter water out of the side of their beaks and keep food inside? Tiny rows of plates called lamellae',\n",
              "       \"What would a tiger do when seized by a crocodile? strike at the reptile's eyes with its paws\",\n",
              "       'How many years ago was the Luther Bible by Martin Luther printed? 475',\n",
              "       'What happens when mothers lose a chick? They sometimes attempt to \"steal\" another chick.',\n",
              "       'Who were the Orkhon inscriptions built for? The Orkhon inscriptions were erected in honour of the prince Kul Tigin and his brother Emperor Bilge Khan.',\n",
              "       'Has the terrain in the city been artificially raised? yes',\n",
              "       'What do river otters eat? a variety of fish and shellfish, as well as small land mammals and birds',\n",
              "       'What prompted the city to upgrade its building codes The threat of major earthquakes',\n",
              "       'Why is the giant otter becoming increasingly rare? poaching, habitat loss, and the use of mercury in illegal alluvial gold mining',\n",
              "       \"What have become flippers, useless for flight in the air? Penguins' wings\",\n",
              "       'Why does the cornet have a slightly mellower tone than the trumpet? because it has conical bores',\n",
              "       'Approximately how many species of Testudines are alive today? 300',\n",
              "       'Are otters playful animals? yes',\n",
              "       'Did lincoln have 18 months of schooling? Yes',\n",
              "       'Who heavily influenced the architecture and culture of Montevideo? European immigrants',\n",
              "       'What was the Faraday effect first called? diamagnetism',\n",
              "       'Does it have a border with Norway? Yes',\n",
              "       'Is an official language of Canada German? No.',\n",
              "       'What is also the distance that Antarctic tourists are told to keep from penguins? 3 meters',\n",
              "       'Did Lincoln ever represent Alton & Sangamon Railroad? Yes',\n",
              "       \"What are some of the cougar's primary food sources? ungulates such as deer, elk, and bighorn sheep, as well as domestic cattle, horses, and sheep\",\n",
              "       \"Is Melbourne home to Australia's busiest seaport? Yes\",\n",
              "       'Did Bartolomeo Cristofori invent the modern piano? Yes',\n",
              "       'Where is the Park of the Reserve located? Near the downtown area.',\n",
              "       'What did Anders Celsius determine about the boiling of water? dependence with atmospheric pressure',\n",
              "       'What city in the UK has been subjected to bouts of terrorism? London has been subjected to bouts of terrorism.',\n",
              "       'What foods do pandas eat? bamboo, honeys, eggs, fish, yams, shrub leaves, oranges, and baas',\n",
              "       'When did Adams graduate from college? 1755.',\n",
              "       'Can the origins of cymbals be traced back to prehistoric times? yes',\n",
              "       'Which type of beetle is a pest of potato plants? Colorado potato beetle',\n",
              "       'Is there a way to approximate the age of a turtle? yes',\n",
              "       'What trumpet was the first to be allowed in the Christian Church? slide trumpets',\n",
              "       'What is the battery made by Alessandro Volta credited as? the first electrochemical cell',\n",
              "       'Is it a disadvantage for something to be unsafe to handle? yes',\n",
              "       'The ideas of the Enlightenment shaped the development of what? the city, Lima',\n",
              "       'Has the terrain in the city been artificially raised? Yes.',\n",
              "       'Is the SI unit for radioactivity named after him? Yes',\n",
              "       'Was the Italian 10.000 lira banknote created before the euro? yes',\n",
              "       'How many times has Uruguay won the World Cup? Twice.',\n",
              "       'Where was Isaac Newton born? Woolsthorpe Manor in Woolsthorpe-by-Colsterworth',\n",
              "       'Was Gerald Ford the 38th President of the United States? yes',\n",
              "       'When was the pan flute spread to other parts of Europe? After the 7th century BC',\n",
              "       'Who was President when Wilson finished Congressional Government? Grover Cleveland',\n",
              "       'Is the ant a marsupial? no',\n",
              "       'What happened in 1860? Vincent van Gogh attended the Zundert village school from 1860.',\n",
              "       'Was Grover Cleveland the twenty-seventh president of the United States? No.',\n",
              "       'With what party did Adams run for presidency? The Federalist Party',\n",
              "       'What are the differences between English and Swedish pronouns? Swedish pronouns are basically the same as those of English but distinguish two genders and have an additional object form, derived from the old dative form, as well as a distinct genitive case.',\n",
              "       'Was John Calvin Coolidge Jr. was born in Las Vegas? No',\n",
              "       'When did Isaac Newton discover the generalized binomial theorem? In 1665.',\n",
              "       'What field did Woodrow Wilson leave law practice to study? history and political science',\n",
              "       'Is the standard of living in San Franciscio high? Yes',\n",
              "       \"What is the name of the largest church in Montreal? Saint Joseph's Oratory is the largest church in Montreal.\",\n",
              "       'Are the strings of a classical lyre made of gut? Yes',\n",
              "       'Where did the xylophone originate? Indonesia',\n",
              "       \"Is it advantageous for a grand piano's metal plate to be quite massive? It is advantageous for the plate to be quite massive.\",\n",
              "       'Where is Melbourne situated? boundary of the very hot inland areas and the cold southern ocean',\n",
              "       'How many countries in Europe are bigger than Romania? eleven',\n",
              "       'Where did he serve two terms? the Church of Scotland',\n",
              "       'What fictional stories include a main character named Santiago? Interview with the Vampire, The Alchemist, and others',\n",
              "       'What is the sustain pedal called? damper pedal',\n",
              "       'What do beetles eat? Some are generalists, eating both plants and animals. Other beetles are highly specialised in their diet.',\n",
              "       'Was Thedore Roosevelt a member of the Republican Party? Yes',\n",
              "       'Give an example of the ten Beta World Cities. San Trancisco',\n",
              "       'When was Coolidge born? Plymouth, Windsor County, Vermont',\n",
              "       'Is an acoustic guitar dependent on an external device? No.',\n",
              "       'Is Golden Gate Park the largest city park yes',\n",
              "       'Is a bee an insect? yes',\n",
              "       'What was Michael Faraday`s profession? chemist and physicist',\n",
              "       'Does Qatar rank as the eighth richest country in the world per capita? No.',\n",
              "       'Oxygen is what? One kind of gas obtained via a tracheal system.',\n",
              "       \"Who were the midnight judges? They were a series of judges, so called because most of them were formally appointed days before Adams' presidential term expired\",\n",
              "       'Is polar bear a mammal? Yes',\n",
              "       'What is a hybrid animal resulting from a union between a leopard and a puma? a pumapard',\n",
              "       'Does Theodore Roosevelt have a brother? Yes',\n",
              "       'What food gave Isaac Newton clues to his theory of gravity? apple',\n",
              "       'What is a colectivo? Automobiles that renders express service on some major roads of the Lima Metropolitan Area.',\n",
              "       'Did he experiment with individual cells? Yes',\n",
              "       'Is Malay an agglutinative language? Yes.',\n",
              "       'How old is the oldest known representation of a guitar-like intrument being played? 3,300 years old',\n",
              "       \"Did Johann Josef Loschmidt first calculate the value of Avogadro's number? yes\",\n",
              "       \"How does a Mallard's tongue work? It uses short spikes to push struggling prey and other food down its throat\",\n",
              "       'What is the basic word order in Malay? Subject Object Verb.',\n",
              "       'What is the Faraday effect? The Faraday effect is the phenomenon that the plane of polarisation of linearly polarised light can be rotated by the application of an external magnetic field aligned in the direction the light is moving.',\n",
              "       'What is the official language of Turkey? Turkish.',\n",
              "       \"What was Grant's political affiliation? Republican\",\n",
              "       'Who did Newton see as the master creator? God',\n",
              "       'Around how many recognized octopus species are there? There are around 300 recognized octopus species.',\n",
              "       'What is the caridoid escape reaction? Swimming backwards quickly by curling and uncurling their abdomen.',\n",
              "       'What is the middle pedal called on grand pianos? the sostenuto pedal.',\n",
              "       'Was Malay language written using Pallava? Yes',\n",
              "       'Why are otters vulnerable to prey depletion? Prey-dependence',\n",
              "       'What religions are found in Uruguay? Roman Catholic, Protestant, Jewish, and nonprofessing.',\n",
              "       \"Is English Ghana's official language? yes\",\n",
              "       \"In what language was his 1811 paper published? Avogadro's 1811 paper was published in French.\",\n",
              "       'Does the de Young museum house the Asian Art Museum No',\n",
              "       'Are violas and cellos in the same family of instruments as violins? yes',\n",
              "       'Is a guitar an instrument? yes',\n",
              "       'What are some common predators of ducks? Pike, crocodilians, herons, hawks and eagles.',\n",
              "       'Did Grant & Perkins not sell harnesses , saddles , and other leather goods and purchase hides from farmers in the prosperous Galena area ? they did',\n",
              "       'Was his 1800 paper written in French? Yes',\n",
              "       'When was his last painting for the Post published? 1963',\n",
              "       \"Where did Coolidge's grandfather had government offices? Plymouth\",\n",
              "       'Where is the word \"swan\" derived from? Old English swan.',\n",
              "       'How many legs do lobsters have? 10',\n",
              "       'Are more residents employed by small businesses than in 1977? No',\n",
              "       'Was the SI unit of charge named after Charles-Augustin de Coulomb? Yes, the SI unit of charge, the coulomb, was named after him.',\n",
              "       'Copenhagen is ranked number one worldwide for which things? Most Livable City, Location Ranking Survey',\n",
              "       'What happened in 1810? Volta was made a count by Napoleon.',\n",
              "       'What kind of piano did Irving Berlin play? transposing piano',\n",
              "       'Where was there a vast swarm of butterflies? In Kyoto there was a vast swarm of butterflies.',\n",
              "       'What is the most common romanization standard for Standard Mandarin today? Hanyu Pinyin',\n",
              "       'Is Jakarta the 12th largest city in the world? yes',\n",
              "       'What sort of turtles are ectothermic? all of them',\n",
              "       'Was Gellu Naum the leader of the surrealist movement in Romania ? Yes'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "2163f0d34482460096bd3247a6057f8b",
            "b55ff6dfe2d948bd85f36e8a5848b451",
            "1f2c696376c845388b8f59ac455c6484",
            "52fff86ba05c4ac489f5a0384be31d6d",
            "52ec394c33ab4d47b60a0fd396091016",
            "413147f0bf5947c7afb0a9f6d78bbb71",
            "0920603cf12b406da50cfabf26167cd4",
            "ac3d2ed6b2654b109f09d850497fe444",
            "cc05be07421e454d9ecad268f1e919b4",
            "5e2dedab978b4938a937e1438cf51c30",
            "d25a95295f4742b5b7aa31a212f9f558"
          ]
        },
        "id": "FIrS5sxE3kgk",
        "outputId": "94ff2be8-95bf-4e9f-bcdf-8d61ec5a8000"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2163f0d34482460096bd3247a6057f8b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp64MkNB3kg1"
      },
      "source": [
        "def get_labels(prediction):\n",
        "    predicted_label =  LE.inverse_transform([prediction])\n",
        "    return predicted_label[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uPgTmJPS3kg4",
        "outputId": "f6024cd7-b368-470f-e23f-52cb91b40061"
      },
      "source": [
        "import joblib\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "LE = LabelEncoder()\n",
        "LE = joblib.load('label_encoder_difficulty_Lstm')\n",
        "\n",
        "get_labels(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Difficult'"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "I_UpqLMG3kg9",
        "outputId": "7f9a1be3-ef21-4aad-85ff-1bfecd4ba0c5"
      },
      "source": [
        "final_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>DifficultyFromAnswerer</th>\n",
              "      <th>question_answer</th>\n",
              "      <th>difficulty_label</th>\n",
              "      <th>skill_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Is the dialect spoken in Jeju located in fact ...</td>\n",
              "      <td>The dialect spoken in Jeju is in fact classifi...</td>\n",
              "      <td>hard</td>\n",
              "      <td>Is the dialect spoken in Jeju located in fact ...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What cello manufacturer should I buy from if I...</td>\n",
              "      <td>Luis &amp; Clark</td>\n",
              "      <td>hard</td>\n",
              "      <td>What cello manufacturer should I buy from if I...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Does it have a border with Norway?</td>\n",
              "      <td>yes</td>\n",
              "      <td>medium</td>\n",
              "      <td>Does it have a border with Norway? yes</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How many people use the bus network daily?</td>\n",
              "      <td>More than 2.78 million people.</td>\n",
              "      <td>easy</td>\n",
              "      <td>How many people use the bus network daily? Mor...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Who founded Montevideo?</td>\n",
              "      <td>The Spanish.</td>\n",
              "      <td>medium</td>\n",
              "      <td>Who founded Montevideo? The Spanish.</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2763</th>\n",
              "      <td>Did he become a professor before the revolutio...</td>\n",
              "      <td>yes</td>\n",
              "      <td>hard</td>\n",
              "      <td>Did he become a professor before the revolutio...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2764</th>\n",
              "      <td>Does Vietnamese borrow from Latin and Greek?</td>\n",
              "      <td>No, Vietnamese does not borrow from Latin and ...</td>\n",
              "      <td>medium</td>\n",
              "      <td>Does Vietnamese borrow from Latin and Greek? N...</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2765</th>\n",
              "      <td>Where is San Francisco?</td>\n",
              "      <td>San Francisco is in California.</td>\n",
              "      <td>medium</td>\n",
              "      <td>Where is San Francisco? San Francisco is in Ca...</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2766</th>\n",
              "      <td>What is the primary item in an otter's diet?</td>\n",
              "      <td>fish</td>\n",
              "      <td>medium</td>\n",
              "      <td>What is the primary item in an otter's diet? fish</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2767</th>\n",
              "      <td>Where are turtle eggs layed?</td>\n",
              "      <td>Turtles lay eggs on land.</td>\n",
              "      <td>hard</td>\n",
              "      <td>Where are turtle eggs layed? Turtles lay eggs ...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2768 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Question  ... skill_label\n",
              "0     Is the dialect spoken in Jeju located in fact ...  ...           3\n",
              "1     What cello manufacturer should I buy from if I...  ...           3\n",
              "2                    Does it have a border with Norway?  ...           2\n",
              "3            How many people use the bus network daily?  ...           2\n",
              "4                               Who founded Montevideo?  ...           2\n",
              "...                                                 ...  ...         ...\n",
              "2763  Did he become a professor before the revolutio...  ...           3\n",
              "2764       Does Vietnamese borrow from Latin and Greek?  ...           3\n",
              "2765                            Where is San Francisco?  ...           3\n",
              "2766       What is the primary item in an otter's diet?  ...           2\n",
              "2767                       Where are turtle eggs layed?  ...           3\n",
              "\n",
              "[2768 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHdVe13Fr3vt"
      },
      "source": [
        "new_data = final_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkyM7gqv3khI"
      },
      "source": [
        "question_answer = new_data[\"question_answer\"].values\n",
        "categories = new_data[\"difficulty_label\"].values\n",
        "skill_category = new_data[\"skill_label\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ndpw0p1SBUoZ",
        "outputId": "ee18b17f-7229-471a-e4f6-422c81046cd9"
      },
      "source": [
        "question_answer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Is the dialect spoken in Jeju located in fact classified as a different language by all Korean linguists? The dialect spoken in Jeju is in fact classified as a different language by some Korean linguists.',\n",
              "       'What cello manufacturer should I buy from if I want to play outside? Luis & Clark',\n",
              "       'Does it have a border with Norway? yes', ...,\n",
              "       'Where is San Francisco? San Francisco is in California.',\n",
              "       \"What is the primary item in an otter's diet? fish\",\n",
              "       'Where are turtle eggs layed? Turtles lay eggs on land.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "tFkS_H_83khL",
        "outputId": "e29a3a45-5147-47e7-ba69-197d2586b276"
      },
      "source": [
        "question_answer[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Is the dialect spoken in Jeju located in fact classified as a different language by all Korean linguists? The dialect spoken in Jeju is in fact classified as a different language by some Korean linguists.'"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ian7gSDE3khR",
        "outputId": "4a41d56d-faef-475d-df73-b2bf52e7c5e2"
      },
      "source": [
        "len(categories)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2768"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_ZeuHc63khU",
        "outputId": "86c01496-80ae-4fed-93d5-c6176f916cec"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in question_answer:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', question_answer[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  Is the dialect spoken in Jeju located in fact classified as a different language by all Korean linguists? The dialect spoken in Jeju is in fact classified as a different language by some Korean linguists.\n",
            "Token IDs: tensor([  101,  2003,  1996,  9329,  5287,  1999, 15333,  9103,  2284,  1999,\n",
            "         2755,  6219,  2004,  1037,  2367,  2653,  2011,  2035,  4759, 22978,\n",
            "         2015,  1029,  1996,  9329,  5287,  1999, 15333,  9103,  2003,  1999,\n",
            "         2755,  6219,  2004,  1037,  2367,  2653,  2011,  2070,  4759, 22978,\n",
            "         2015,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVGvVZb13kha",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cffc316c-8427-42e4-bcee-c4d7e0ffe477"
      },
      "source": [
        "print('Original: ', len(question_answer[1]))\n",
        "print('Token IDs:', len(input_ids[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  81\n",
            "Token IDs: 128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nmRiaBbA9OH"
      },
      "source": [
        "val_text = val[\"question_answer\"].values\n",
        "val_labels = val[\"difficulty_label\"].values\n",
        "val_skill_labels = val[\"skill_label\"].values\n",
        "test_text = test[\"question_answer\"].values\n",
        "test_labels = test[\"difficulty_label\"].values\n",
        "test_skill_labels = test[\"skill_label\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-s_H1WdyvCw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e44ba24-89fc-4478-e554-424a1419aa26"
      },
      "source": [
        "test_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 2, 0, 0, 0, 1, 2, 1, 2, 2, 1, 0, 0, 1, 1, 1, 0, 2, 2, 0, 2,\n",
              "       1, 1, 1, 2, 0, 0, 0, 0, 2, 2, 2, 0, 0, 2, 1, 0, 1, 2, 1, 2, 2, 0,\n",
              "       2, 0, 2, 2, 0, 2, 2, 1, 0, 2, 2, 1, 0, 0, 2, 0, 1, 0, 0, 2, 0, 2,\n",
              "       0, 0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 0, 0, 0, 0, 2,\n",
              "       0, 1, 0, 0, 0, 2, 2, 0, 1, 0, 0, 0, 0, 1, 1, 2, 2, 0, 2, 2, 0, 2,\n",
              "       0, 0, 0, 1, 0, 2, 2, 1, 1, 1, 1, 2, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
              "       0, 1, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0, 0, 1, 0, 2, 2, 2,\n",
              "       2, 2, 0, 1, 2, 2, 0, 2, 2, 2, 1, 1, 2, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
              "       0, 0, 0, 0, 1, 2, 0, 2, 2, 2, 1, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0,\n",
              "       2, 0, 0, 2, 1, 0, 2, 1, 1, 0, 0, 2, 2, 0, 2, 2, 0, 0, 2, 2, 2, 1,\n",
              "       2, 2, 0, 1, 2, 1, 2, 1, 2, 1, 2, 1, 0, 0, 1, 2, 2, 1, 0, 0, 0, 1,\n",
              "       2, 0, 0, 2, 0, 2, 0, 0, 2, 1, 1, 2, 2, 0, 2, 0, 2, 2, 1, 2, 2, 2,\n",
              "       0, 1, 2, 0, 1, 1, 2, 2, 0, 2, 1, 0, 2, 1, 0, 1, 1, 2, 0, 1, 1, 1,\n",
              "       1, 2, 1, 0, 2, 0, 0, 2, 0, 1, 0, 1, 1, 0, 2, 0, 1, 2, 0, 0, 1, 0,\n",
              "       1, 2, 1, 1, 1, 2, 2, 1, 2, 0, 2, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 2,\n",
              "       2, 2, 1, 0, 1, 1, 2, 2, 2, 2, 2, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF-mKCC1CUjD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e49d89d7-1a35-4640-9b9e-6d9e7789d76d"
      },
      "source": [
        "val_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 2, 0, 0, 1, 2, 2, 0, 2, 0, 1, 0, 0, 0, 0, 2, 2, 2, 0, 0,\n",
              "       2, 1, 1, 0, 1, 2, 2, 1, 1, 0, 1, 2, 1, 1, 0, 0, 0, 1, 1, 2, 2, 0,\n",
              "       1, 0, 1, 2, 0, 0, 0, 2, 0, 2, 0, 2, 0, 1, 0, 1, 0, 0, 2, 2, 1, 1,\n",
              "       2, 1, 0, 1, 2, 0, 2, 2, 2, 1, 2, 2, 1, 2, 1, 1, 0, 2, 0, 1, 0, 0,\n",
              "       1, 2, 2, 0, 0, 0, 2, 2, 1, 1, 0, 0, 1, 0, 2, 0, 1, 0, 2, 0, 0, 2,\n",
              "       2, 1, 2, 2, 0, 1, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0,\n",
              "       0, 1, 0, 2, 0, 1, 2, 1, 0, 1, 2, 2, 2, 2, 1, 2, 1, 0, 1, 2, 0, 0,\n",
              "       1, 0, 2, 0, 2, 2, 0, 0, 1, 1, 2, 1, 1, 0, 2, 2, 0, 1, 1, 2, 0, 0,\n",
              "       0, 1, 2, 2, 2, 1, 0, 1, 2, 2, 0, 0, 1, 0, 2, 2, 1, 0, 0, 0, 1, 2,\n",
              "       1, 2, 1, 1, 2, 0, 1, 2, 0, 1, 1, 2, 1, 2, 0, 0, 1, 0, 0, 2, 1, 0,\n",
              "       0, 0, 0, 0, 0, 2, 0, 1, 0, 2, 2, 2, 1, 2, 1, 1, 0, 1, 0, 2, 1, 1,\n",
              "       0, 2, 0, 0, 0, 1, 2, 0, 1, 0, 0, 2, 1, 2, 0, 1, 2, 0, 0, 0, 0, 0,\n",
              "       0, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 0,\n",
              "       0, 0, 2, 2, 0, 0, 1, 1, 2, 1, 1, 2, 1, 2, 0, 0, 0, 2, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOQuDahhAzOO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fe30bfb-9eb1-44a3-d0d1-ee698fc1ee81"
      },
      "source": [
        "val_input_ids = []\n",
        "val_attention_masks = []\n",
        "\n",
        "for sent in val_text:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    val_input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    val_attention_masks.append(encoded_dict['attention_mask'])\n",
        "# Convert the lists into tensors.\n",
        "val_input_ids = torch.cat(val_input_ids, dim=0)\n",
        "val_attention_masks = torch.cat(val_attention_masks, dim=0)\n",
        "\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', val_text[0])\n",
        "print('Token IDs:', val_attention_masks[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  What are turtle eggs covered in when they incubate? mud or sand\n",
            "Token IDs: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Siskea7qDLUG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecbc4a2f-4e9c-4ffd-8fea-14c5ac6001d7"
      },
      "source": [
        "print('Original: ', val_text[1])\n",
        "print('Token IDs:', val_input_ids[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  What is given for the number of native speakers? No figure is given for the number of native speakers.\n",
            "Token IDs: tensor([ 101, 2054, 2003, 2445, 2005, 1996, 2193, 1997, 3128, 7492, 1029, 2053,\n",
            "        3275, 2003, 2445, 2005, 1996, 2193, 1997, 3128, 7492, 1012,  102,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irMTimjf3khd"
      },
      "source": [
        "labels = torch.tensor(categories)\n",
        "skill_category = torch.tensor(skill_category)\n",
        "val_labels = torch.tensor(val_labels)\n",
        "val_skill_labels = torch.tensor(val_skill_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdOgWP_LKTHi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6b5330e-d036-4da7-d35f-a6d9f2c5ec95"
      },
      "source": [
        "val_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 0, 2, 0, 0, 1, 2, 2, 0, 2, 0, 1, 0, 0, 0, 0, 2, 2, 2, 0, 0, 2, 1,\n",
              "        1, 0, 1, 2, 2, 1, 1, 0, 1, 2, 1, 1, 0, 0, 0, 1, 1, 2, 2, 0, 1, 0, 1, 2,\n",
              "        0, 0, 0, 2, 0, 2, 0, 2, 0, 1, 0, 1, 0, 0, 2, 2, 1, 1, 2, 1, 0, 1, 2, 0,\n",
              "        2, 2, 2, 1, 2, 2, 1, 2, 1, 1, 0, 2, 0, 1, 0, 0, 1, 2, 2, 0, 0, 0, 2, 2,\n",
              "        1, 1, 0, 0, 1, 0, 2, 0, 1, 0, 2, 0, 0, 2, 2, 1, 2, 2, 0, 1, 0, 0, 2, 0,\n",
              "        0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 1, 0, 2, 0, 1, 2, 1, 0, 1, 2, 2,\n",
              "        2, 2, 1, 2, 1, 0, 1, 2, 0, 0, 1, 0, 2, 0, 2, 2, 0, 0, 1, 1, 2, 1, 1, 0,\n",
              "        2, 2, 0, 1, 1, 2, 0, 0, 0, 1, 2, 2, 2, 1, 0, 1, 2, 2, 0, 0, 1, 0, 2, 2,\n",
              "        1, 0, 0, 0, 1, 2, 1, 2, 1, 1, 2, 0, 1, 2, 0, 1, 1, 2, 1, 2, 0, 0, 1, 0,\n",
              "        0, 2, 1, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 2, 2, 2, 1, 2, 1, 1, 0, 1, 0, 2,\n",
              "        1, 1, 0, 2, 0, 0, 0, 1, 2, 0, 1, 0, 0, 2, 1, 2, 0, 1, 2, 0, 0, 0, 0, 0,\n",
              "        0, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0,\n",
              "        2, 2, 0, 0, 1, 1, 2, 1, 1, 2, 1, 2, 0, 0, 0, 2, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJJ0I8Ud3khf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "63434d32-17c2-4300-e392-1b584b319ddc"
      },
      "source": [
        "get_labels(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Easy'"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1ZAbQRfiG63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "507f130f-5d67-4b6f-f949-b6f440c7e620"
      },
      "source": [
        "len(set(final_data[\"question_answer\"].values).intersection(val[\"question_answer\"].values))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNDW74Ny3khj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf531796-564c-47fd-c794-7d9fbd425ae3"
      },
      "source": [
        "num_classes = len(list(set(categories)))\n",
        "list(set(categories))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOBErYPYEUrl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "433a80ad-31bc-457f-f5ed-ab8af9de60f9"
      },
      "source": [
        "skill_label_count = len(list(set(new_data[\"skill_label\"].values)))\n",
        "skill_label_count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYFIJaRPE20c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41636722-03ac-4e1e-ca3e-41feec55c06b"
      },
      "source": [
        "list(set(new_data[\"skill_label\"].values))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmaLk5Ab3khl"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "# train_poincare_tensor = torch.tensor(poincare_embeddings_final,dtype=torch.float)\n",
        "# difficulty_tensor = torch.tensor(difficulty_level_vectors,dtype=torch.float)\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels,skill_category)\n",
        "val_dataset = TensorDataset(val_input_ids, val_attention_masks,val_labels,val_skill_labels) \n",
        "# Create a 90-10train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "# train_size = int(0.90 * len(dataset))\n",
        "# val_size = len(dataset) - train_size\n",
        "\n",
        "# # Divide the dataset by randomly selecting samples.\n",
        "# train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# print('{:>5,} training samples'.format(train_size))\n",
        "# # print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_lTinod3kho"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size = 32\n",
        "train_dataloader = DataLoader(\n",
        "            dataset,  # The training samples.\n",
        "            sampler = RandomSampler(dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), \n",
        "            batch_size = batch_size \n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2tmAMlw3khr"
      },
      "source": [
        "from transformers import BertModel, AdamW, BertConfig\n",
        "\n",
        "# # Loads BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# model = BertModel.from_pretrained(\n",
        "#     \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "# )\n",
        "\n",
        "# # Tell pytorch to run this model on the GPU.\n",
        "# model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkDmTZhVChN6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7436287e-a1e5-42be-a9c3-3dd50733cb1e"
      },
      "source": [
        "set(test[\"question_answer\"].values).intersection(set(final_data[\"question_answer\"].values))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Approximately how many species of Testudines are alive today? 300',\n",
              " 'Are all dialects of Korean similar to each other? Yes',\n",
              " 'Are pocket trumpets compact B trumpets? yes',\n",
              " 'Are wolves built for stamina? Yes',\n",
              " 'Around how many recognized octopus species are there? There are around 300 recognized octopus species.',\n",
              " 'Copenhagen is the capital of what country? Denmark',\n",
              " 'Did Lincoln ever represent Alton & Sangamon Railroad? Yes',\n",
              " \"Did Monroe' wedding happen at the Trinity Church in New York? Yes\",\n",
              " 'Do linguists often view Chinese as a language family? Yes, linguists often view Chinese as a language family.',\n",
              " 'Does Modern Standard Arabic continue to evolve like other languages? yes',\n",
              " 'Does Theodore Roosevelt have a brother? Yes',\n",
              " 'Does every drumhead make the same sound? no',\n",
              " 'Does the octopus have a hard beak? Yes, the octopus has a hard beak.',\n",
              " 'Have cymbals been used historically to suggest bacchanal? Yes',\n",
              " 'How many children did Avogadro have? six',\n",
              " 'How many species of otter are there? 13',\n",
              " 'How old is the oldest known representation of a guitar-like intrument being played? 3,300 years old',\n",
              " 'How old was Celsius when he died? 42',\n",
              " \"Is English Ghana's official language? yes\",\n",
              " 'Is Liechtenstein heavily urbanized? No',\n",
              " 'Is Liechtenstein the smallest German-speaking country in the world? Yes',\n",
              " 'Is it a disadvantage for something to be unsafe to handle? yes',\n",
              " 'Is polar bear a mammal? Yes',\n",
              " 'Is the SI unit for radioactivity named after him? Yes',\n",
              " 'Was Abraham Lincoln the first President of the United States? No',\n",
              " 'Was Grover Cleveland the twenty-seventh president of the United States? No.',\n",
              " \"Was Henri Becquerel first in his family to occupy the physics chair at the Museum National d'Histoire Naturelle? No\",\n",
              " \"Was Isaac Newton educated at The King's Schol, Grantham? yes\",\n",
              " 'Was the Italian 10.000 lira banknote created before the euro? yes',\n",
              " 'Were trumpet players heavily guarded? yes',\n",
              " \"What are the elephant's ears important for? temperature regulation\",\n",
              " \"What company administers Leichtenstein's railways? Austrian Federal Railways\",\n",
              " 'What do river otters eat? a variety of fish and shellfish, as well as small land mammals and birds',\n",
              " 'What is the life expectancy for men in Finland? 75 years',\n",
              " 'What is the most common romanization standard for Standard Mandarin today? Hanyu Pinyin',\n",
              " 'What is the smallest suborder of turtles? Pleurodira',\n",
              " \"What was Grant's political affiliation? Republican\",\n",
              " 'What year did Coolidge open his own law office? 1898',\n",
              " 'When did Isaac Newton discover the generalized binomial theorem? In 1665.',\n",
              " 'When did Roosevelt die? On January 6, 1919, Roosevelt died in his sleep.',\n",
              " 'When was the Six Day War? 1967',\n",
              " 'Where is Finland located? Northern Europe',\n",
              " 'Where was Isaac Newton born? Woolsthorpe Manor in Woolsthorpe-by-Colsterworth',\n",
              " 'Where was James Monroe born? Westmoreland County, Virginia',\n",
              " \"Where was much of Montreal's industry during the late 19th and early-to-mid 20th century? The Sud-Ouest borough was home to much of the city's industry during the late 19th and early-to-mid 20th century.\",\n",
              " 'Where was the League of Nations created? Paris',\n",
              " 'Which type of beetle is a pest of potato plants? Colorado potato beetle',\n",
              " 'Who appointed Harlan Fiske Stone to the Supreme Court? Coolidge',\n",
              " \"Who is the mayor of Ottawa? Larry O'Brien\",\n",
              " 'Who was President when Wilson finished Congressional Government? Grover Cleveland',\n",
              " 'With what party did Adams run for presidency? The Federalist Party'}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AX-SagSE8CS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa14ce40-13e9-406f-f75a-f94b011c8657"
      },
      "source": [
        "num_classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHmQK0OP9mv-"
      },
      "source": [
        "from torch import nn\n",
        "# for plottign attentions\n",
        "class MultiClassClassifier(nn.Module):\n",
        "    def __init__(self, bert_model_path, labels_count,skill_label_count, hidden_dim=768, mlp_dim=500, extras_dim=140, dropout=0.1, freeze_bert=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(bert_model_path,output_hidden_states=True,output_attentions=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim , mlp_dim),\n",
        "            nn.ReLU(),\n",
        "            # nn.Linear(mlp_dim, mlp_dim),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(mlp_dim, mlp_dim),\n",
        "            # nn.ReLU(),            \n",
        "            nn.Linear(mlp_dim, labels_count)\n",
        "        )\n",
        "        self.mlp2 = nn.Sequential(\n",
        "            nn.Linear(hidden_dim , mlp_dim),\n",
        "            nn.ReLU(),         \n",
        "            nn.Linear(mlp_dim, skill_label_count)\n",
        "        )\n",
        "        # self.softmax = nn.LogSoftmax(dim=1)\n",
        "        if freeze_bert:\n",
        "            print(\"Freezing layers\")\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, tokens, masks):\n",
        "        _, pooled_output,hidden_states,attentions = self.bert(tokens, attention_mask=masks)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        concat_output = dropout_output\n",
        "        mlp_output = self.mlp(concat_output)\n",
        "        skill_output = self.mlp2(concat_output)\n",
        "        # proba = self.sigmoid(mlp_output)\n",
        "        # proba = self.softmax(mlp_output)\n",
        "\n",
        "        return mlp_output,skill_output,attentions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ9_trOX96Tv"
      },
      "source": [
        "from torch import nn\n",
        "class SkillClassifier(nn.Module):\n",
        "    def __init__(self, bert_model_path, labels_count, hidden_dim=768, mlp_dim=500, extras_dim=140, dropout=0.1, freeze_bert=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(bert_model_path,output_hidden_states=True,output_attentions=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim , mlp_dim),\n",
        "            nn.ReLU(),\n",
        "            # nn.Linear(mlp_dim, mlp_dim),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(mlp_dim, mlp_dim),\n",
        "            # nn.ReLU(),            \n",
        "            nn.Linear(mlp_dim, 5)\n",
        "        )\n",
        "        # self.softmax = nn.LogSoftmax(dim=1)\n",
        "        if freeze_bert:\n",
        "            print(\"Freezing layers\")\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, tokens, masks):\n",
        "        _, pooled_output,_,_ = self.bert(tokens, attention_mask=masks)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        concat_output = dropout_output\n",
        "        mlp_output = self.mlp(concat_output)\n",
        "        # proba = self.sigmoid(mlp_output)\n",
        "        # proba = self.softmax(mlp_output)\n",
        "\n",
        "        return mlp_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uqkkw379_WB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8709f741370f4b32aca425b6c186ae4d",
            "e0e14c1d03f8485c8f764c1d8b758e0c",
            "e3b9cd4386b54073a8c47166e86e880f",
            "333531fbe35542c882a74e695bef1598",
            "027f5922a1cc414da45a7fdcbd8b34a2",
            "9804fc777e4941168e16798870d9d9df",
            "f0200f499c644d26b3ed405c920e5e7b",
            "38bfa6161042464987f31e02e710d212",
            "d0d8d89ad70b4b789bd61a85e210e2c0",
            "7ede42df5f19469ebba6feae6502b2f3",
            "10c313b910bb4e98b69e7f095bad84c7",
            "f92017a763f34f39a999a4e4384627bf",
            "a89bfc8c32a8414bbc945c437d9fcc86",
            "74627ed667d94325bc86fc2bf45f07a7",
            "15e8893cb9df4c00aacb26f51ce1edd4",
            "0045e9039cd447629b136c0e0f18acf8",
            "034831822daa4e00b3e98128c85f44dc",
            "eb07c3c0b5284342a0ea791098953630",
            "3a6189c72f204ec3853827ab8df865ac",
            "d31e916ce5e2451aa91c7ebf98771cb6",
            "be816c6fc2d54c1b8f051d3760d958de",
            "ee11cb95d4d1404890d58f2b9c3aac01"
          ]
        },
        "outputId": "f01daec9-6762-45d2-b4b1-ca2f3cab9651"
      },
      "source": [
        "skill_model = SkillClassifier('bert-base-uncased',num_classes, 768,500,140,dropout=0.1,freeze_bert=False)\n",
        "skill_model.load_state_dict(torch.load(\"/content/model_bert_skill_prediction_data_2/model_weights\"))\n",
        "skill_model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8709f741370f4b32aca425b6c186ae4d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f92017a763f34f39a999a4e4384627bf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SkillClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (mlp): Sequential(\n",
              "    (0): Linear(in_features=768, out_features=500, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=500, out_features=5, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAgBxwiDbcIj"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "  def __init__(self,vector_1_dim,vector_2_dim):\n",
        "    super(Attention, self).__init__()\n",
        "    self.Weights = nn.Parameter(torch.rand(vector_2_dim,vector_1_dim))\n",
        "    self.bias = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "  def forward(self,vector_1,vector_2):\n",
        "    #(batch_size,vector_2_dim,vector_1_dim)\n",
        "    weights = self.Weights.repeat(vector_2.size(0),1,1)\n",
        "    vector_1 = vector_1.unsqueeze(-1)  # (batch_size,vector_2_dim,vector_1_dim)\n",
        "    weights = weights.matmul(vector_1) # results in (batch_size,vector_2_dim,1)\n",
        "    weights = weights.repeat(vector_2.size(1),1,1,1).transpose(0,1)\n",
        "    vector_2 = vector_2.unsqueeze(-2)\n",
        "    attention_weights = torch.tanh(vector_2.matmul(weights).squeeze() + self.bias) # batch_size, vector_2_dim.size(0)\n",
        "    if len(attention_weights.shape) ==1:\n",
        "      attention_weights = attention_weights.squeeze()\n",
        "      attention_weights = attention_weights.reshape(1,-1)\n",
        "    attention_weights = attention_weights.squeeze()\n",
        "    # print(\"torch.exp(attention_weights)\",torch.exp(attention_weights).shape,attention_weights.shape,torch.exp(attention_weights).sum(dim=1).shape)\n",
        "    attention_weights = torch.exp(attention_weights)/ torch.exp(attention_weights).sum(dim=1,keepdim=True)\n",
        "\n",
        "    return attention_weights\n",
        "\n",
        "# bloom interactive attention\n",
        "class MultiClassClassifier(nn.Module):\n",
        "    def __init__(self, bert_model_path, labels_count,skill_label_count, hidden_dim=768, mlp_dim=500, extras_dim=140, dropout=0.1, freeze_bert=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(bert_model_path,output_hidden_states=True,output_attentions=True)\n",
        "\n",
        "        self.skill_bert = skill_model\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.bloom_attention = Attention(768, 768)\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim , mlp_dim),\n",
        "            nn.ReLU(),\n",
        "            # nn.Linear(mlp_dim, mlp_dim),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(mlp_dim, mlp_dim),\n",
        "            # nn.ReLU(),            \n",
        "            nn.Linear(mlp_dim, labels_count)\n",
        "        )\n",
        "        self.mlp2 = nn.Sequential(  \n",
        "            nn.Linear(hidden_dim , mlp_dim),\n",
        "            nn.ReLU(),         \n",
        "            nn.Linear(mlp_dim, skill_label_count)\n",
        "        )\n",
        "        # self.softmax = nn.LogSoftmax(dim=1)\n",
        "        if freeze_bert:\n",
        "            print(\"Freezing layers\")\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, tokens, masks):\n",
        "        _, pooled_output,hidden_states,attentions = self.bert(tokens, attention_mask=masks)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        concat_output = dropout_output\n",
        "\n",
        "        # mlp_output = self.mlp(concat_output)\n",
        "        skill_output_probas = self.skill_bert(tokens,masks)\n",
        "        skill_output = torch.argmax(skill_output_probas,axis=1).cpu().numpy()\n",
        "        skill_output = LE_skill.inverse_transform(skill_output)\n",
        "        skill_input_ids = []\n",
        "        skill_attention_masks = []\n",
        "        for skill_text in skill_output:\n",
        "          encoded_skill_output = tokenizer.encode_plus(\n",
        "                          skill_text,                      # Sentence to encode.\n",
        "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                          max_length = 128,           # Pad & truncate all sentences.\n",
        "                          pad_to_max_length = True,\n",
        "                          truncation=True,\n",
        "                          return_attention_mask = True,   # Construct attn. masks.\n",
        "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                    )\n",
        "          skill_input_ids.append(encoded_skill_output['input_ids'])\n",
        "          skill_attention_masks.append(encoded_skill_output['attention_mask'])\n",
        "        skill_input_ids = torch.cat(skill_input_ids,dim=0).cuda()\n",
        "        skill_attention_masks = torch.cat(skill_attention_masks,dim=0).cuda()\n",
        "        _,_,hidden_states_skill,_ = self.skill_bert.bert(skill_input_ids,skill_attention_masks)\n",
        "\n",
        "        skill_hidden_averaged =  torch.sum(hidden_states_skill[12],dim=1)/hidden_states_skill[12].shape[1]\n",
        "\n",
        "        bloom_attention_weights = self.bloom_attention(skill_hidden_averaged, hidden_states[12])\n",
        "\n",
        "        bloom_attention_weights = bloom_attention_weights.unsqueeze(-2)\n",
        "        # print(\"context_attention_weights\",context_attention_weights.shape,context_out.shape)\n",
        "        input_attended_vector = bloom_attention_weights.matmul(hidden_states[12]).squeeze()\n",
        "\n",
        "        mlp_output = self.mlp(input_attended_vector)\n",
        "\n",
        "        # print(\"bloom attention weights\", bloom_attention_weights.shape)\n",
        "        # print(\"_hidden_states\",hidden_states_skill[12].shape, hidden_states[12].shape,skill_hidden_averaged.shape)\n",
        "\n",
        "        # proba = self.sigmoid(mlp_output)\n",
        "        # proba = self.softmax(mlp_output)\n",
        "\n",
        "        return mlp_output,skill_output_probas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGU0MvlQ97pt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7433d36e-c0ab-4dd2-f59b-0557ed1081dc"
      },
      "source": [
        "model = MultiClassClassifier('bert-base-uncased',num_classes, skill_label_count,768,500,140,dropout=0.1,freeze_bert=False)\n",
        "# model.load_state_dict(torch.load(\"model_bert_multi_task_interactive_pre_trained_skill_bert/model_weights\"))\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiClassClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (skill_bert): SkillClassifier(\n",
              "    (bert): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (token_type_embeddings): Embedding(2, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (pooler): BertPooler(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (activation): Tanh()\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (mlp): Sequential(\n",
              "      (0): Linear(in_features=768, out_features=500, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=500, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (bloom_attention): Attention()\n",
              "  (mlp): Sequential(\n",
              "    (0): Linear(in_features=768, out_features=500, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=500, out_features=3, bias=True)\n",
              "  )\n",
              "  (mlp2): Sequential(\n",
              "    (0): Linear(in_features=768, out_features=500, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=500, out_features=5, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awQ2Y9Jb3kht"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ys-M4-e3khv"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "\n",
        "epochs = 20\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EenVUl0iDyc1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrYqErOD3khx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7200ec17-d588-4708-e648-502cf4fa7f97"
      },
      "source": [
        "len(train_dataloader) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWVSE9LM3kh0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04e462a7-f4e0-4e5c-afdd-d2509a462835"
      },
      "source": [
        "1935 * 32"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61920"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcvxVVi63kh3"
      },
      "source": [
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUw3zm6g3kh5"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta6zfUTa3kh7"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFq9gd5kQSHb"
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-rKyCrwE7N4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8835c144-51a3-4aea-8bee-eb3bbce59b66"
      },
      "source": [
        "# model.to(device)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiClassClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (skill_bert): SkillClassifier(\n",
              "    (bert): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (token_type_embeddings): Embedding(2, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (pooler): BertPooler(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (activation): Tanh()\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (mlp): Sequential(\n",
              "      (0): Linear(in_features=768, out_features=500, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=500, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (bloom_attention): Attention()\n",
              "  (mlp): Sequential(\n",
              "    (0): Linear(in_features=768, out_features=500, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=500, out_features=3, bias=True)\n",
              "  )\n",
              "  (mlp2): Sequential(\n",
              "    (0): Linear(in_features=768, out_features=500, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=500, out_features=5, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NuM6yRptFtS"
      },
      "source": [
        "for param in model.bert.encoder.layer[0:5].parameters():\n",
        "    param.requires_grad=False\n",
        "for param in model.bert.embeddings.parameters():\n",
        "    param.requires_grad=False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t85MA9XN9eVH"
      },
      "source": [
        "for param in model.skill_bert.bert.encoder.layer.parameters():\n",
        "    param.requires_grad=False\n",
        "for param in model.skill_bert.bert.embeddings.parameters():\n",
        "    param.requires_grad=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_nmuoSgQ5t3"
      },
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1rDO58zMfc8"
      },
      "source": [
        "loss_func = nn.CrossEntropyLoss()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNFL0393HQZc"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LhAy2hZ3kh9",
        "outputId": "f9d74be2-1e6f-4fc4-bfb3-b8710d365566"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "early_stopping = EarlyStopping(patience=2, verbose=True)\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_accuracy = 0\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questimport gensim.downloader as api\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "         \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        # b_poincare = batch[2].to(device)\n",
        "        # b_difficulty = batch[3].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        skill_labels = batch[3].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        probas, skill_probs = model(b_input_ids,b_input_mask)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        loss_1 = loss_func(probas, b_labels)\n",
        "        skill_loss = loss_func(skill_probs,skill_labels)\n",
        "        loss = loss_1 + skill_loss\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        # scheduler.step()\n",
        "        logits = probas.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        total_train_accuracy += flat_accuracy(logits, label_ids)\n",
        "    avg_train_accuracy = total_train_accuracy / len(train_dataloader)\n",
        "    print(\" Train Accuracy: {0:.2f}\".format(avg_train_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader) \n",
        "\n",
        "            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        # b_poincare = batch[2].to(device)\n",
        "        # b_difficulty = batch[3].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        skill_labels = batch[3].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "\n",
        "          logits, skill_logits = model(b_input_ids,b_input_mask)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        loss_1 = loss_func(logits, b_labels)\n",
        "        skill_loss = loss_func(skill_logits,skill_labels)\n",
        "        loss = loss_1 + skill_loss\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    early_stopping(avg_val_loss, model)\n",
        "    if early_stopping.early_stop:\n",
        "      print(\"Early stopping\")\n",
        "      break    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "    output_dir = 'model_bert_multi_task_interactive_pre_trained_skill_bert_data_2/'\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    print(\"Saving model to %s\" % output_dir)\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "    torch.save(model.state_dict(), os.path.join(output_dir, 'model_weights'))\n",
        "\n",
        "    !rm -rf \"/content/drive/My Drive/research_skill_name_prediction/model_bert_multi_task_interactive_pre_trained_skill_bert_data_2\"\n",
        "    !mv model_bert_multi_task_interactive_pre_trained_skill_bert_data_2 \"/content/drive/My Drive/research_skill_name_prediction/\"\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 20 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     87.    Elapsed: 0:01:14.\n",
            "  Batch    80  of     87.    Elapsed: 0:02:30.\n",
            " Train Accuracy: 0.64\n",
            "\n",
            "  Average training loss: 1.01\n",
            "  Training epcoh took: 0:02:42\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.64\n",
            "Validation loss decreased (inf --> 1.395207).  Saving model ...\n",
            "  Validation Loss: 1.40\n",
            "  Validation took: 0:00:16\n",
            "Saving model to model_bert_multi_task_interactive_pre_trained_skill_bert_data_2/\n",
            "\n",
            "======== Epoch 2 / 20 ========\n",
            "Training...\n",
            "  Batch    40  of     87.    Elapsed: 0:01:16.\n",
            "  Batch    80  of     87.    Elapsed: 0:02:31.\n",
            " Train Accuracy: 0.68\n",
            "\n",
            "  Average training loss: 0.91\n",
            "  Training epcoh took: 0:02:43\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.63\n",
            "EarlyStopping counter: 1 out of 2\n",
            "  Validation Loss: 1.44\n",
            "  Validation took: 0:00:13\n",
            "Saving model to model_bert_multi_task_interactive_pre_trained_skill_bert_data_2/\n",
            "\n",
            "======== Epoch 3 / 20 ========\n",
            "Training...\n",
            "  Batch    40  of     87.    Elapsed: 0:01:16.\n",
            "  Batch    80  of     87.    Elapsed: 0:02:32.\n",
            " Train Accuracy: 0.71\n",
            "\n",
            "  Average training loss: 0.87\n",
            "  Training epcoh took: 0:02:45\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.68\n",
            "Validation loss decreased (1.395207 --> 1.365191).  Saving model ...\n",
            "  Validation Loss: 1.37\n",
            "  Validation took: 0:00:17\n",
            "Saving model to model_bert_multi_task_interactive_pre_trained_skill_bert_data_2/\n",
            "\n",
            "======== Epoch 4 / 20 ========\n",
            "Training...\n",
            "  Batch    40  of     87.    Elapsed: 0:01:16.\n",
            "  Batch    80  of     87.    Elapsed: 0:02:32.\n",
            " Train Accuracy: 0.75\n",
            "\n",
            "  Average training loss: 0.79\n",
            "  Training epcoh took: 0:02:44\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.73\n",
            "Validation loss decreased (1.365191 --> 1.348533).  Saving model ...\n",
            "  Validation Loss: 1.35\n",
            "  Validation took: 0:00:16\n",
            "Saving model to model_bert_multi_task_interactive_pre_trained_skill_bert_data_2/\n",
            "\n",
            "======== Epoch 5 / 20 ========\n",
            "Training...\n",
            "  Batch    40  of     87.    Elapsed: 0:01:16.\n",
            "  Batch    80  of     87.    Elapsed: 0:02:32.\n",
            " Train Accuracy: 0.79\n",
            "\n",
            "  Average training loss: 0.69\n",
            "  Training epcoh took: 0:02:44\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.71\n",
            "EarlyStopping counter: 1 out of 2\n",
            "  Validation Loss: 1.38\n",
            "  Validation took: 0:00:13\n",
            "Saving model to model_bert_multi_task_interactive_pre_trained_skill_bert_data_2/\n",
            "\n",
            "======== Epoch 6 / 20 ========\n",
            "Training...\n",
            "  Batch    40  of     87.    Elapsed: 0:01:16.\n",
            "  Batch    80  of     87.    Elapsed: 0:02:32.\n",
            " Train Accuracy: 0.84\n",
            "\n",
            "  Average training loss: 0.57\n",
            "  Training epcoh took: 0:02:45\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.71\n",
            "EarlyStopping counter: 2 out of 2\n",
            "Early stopping\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:20:08 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "6RACcsko3kh_",
        "outputId": "e16f246f-6ee2-45b0-dc69-41930b98f999"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.01</td>\n",
              "      <td>1.40</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0:02:42</td>\n",
              "      <td>0:00:16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.91</td>\n",
              "      <td>1.44</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0:02:43</td>\n",
              "      <td>0:00:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.87</td>\n",
              "      <td>1.37</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0:02:45</td>\n",
              "      <td>0:00:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.79</td>\n",
              "      <td>1.35</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0:02:44</td>\n",
              "      <td>0:00:16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.69</td>\n",
              "      <td>1.38</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0:02:44</td>\n",
              "      <td>0:00:13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               1.01         1.40           0.64       0:02:42         0:00:16\n",
              "2               0.91         1.44           0.63       0:02:43         0:00:13\n",
              "3               0.87         1.37           0.68       0:02:45         0:00:17\n",
              "4               0.79         1.35           0.73       0:02:44         0:00:16\n",
              "5               0.69         1.38           0.71       0:02:44         0:00:13"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "o5TicdiP3kiC",
        "outputId": "5139f470-711e-4147-9588-801c81aa7a14"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbiTDpVv3kiF",
        "outputId": "a42bd2e2-3787-4a3d-cb64-7e0c326d029a"
      },
      "source": [
        "import os\n",
        "\n",
        "\n",
        "output_dir = 'model_bert_multi_task_interactive_pre_trained_skill_bert/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "\n",
        "# model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "# model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to model_bert_multi_task_interactive_pre_trained_skill_bert/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('model_bert_multi_task_interactive_pre_trained_skill_bert/vocab.txt',\n",
              " 'model_bert_multi_task_interactive_pre_trained_skill_bert/special_tokens_map.json',\n",
              " 'model_bert_multi_task_interactive_pre_trained_skill_bert/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq9ByBbSjJlx"
      },
      "source": [
        "  import json\n",
        "  torch.save(model.state_dict(), os.path.join(output_dir, 'model_weights'))\n",
        "  # with open(os.path.join(output_dir, 'model_config.json'), 'w') as f:\n",
        "  #     json.dump(model.config, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U2UQ29a3kiI"
      },
      "source": [
        "# !pip install joblib\n",
        "# import joblib\n",
        "# joblib.dump(LE, \"label_encoder_BLOOM_LATEST\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GFnEkPP3kiP"
      },
      "source": [
        "from google.colab import files\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpGY8vSDI6u4",
        "outputId": "7f319546-794d-44d5-cec8-c61277ff81fc"
      },
      "source": [
        "!zip -r model_bert_multi_task_interactive_pre_trained_skill_bert.zip model_bert_multi_task_interactive_pre_trained_skill_bert\n",
        "# files.download('model_bert_difficulty_prediction.zip')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: model_bert_multi_task_interactive_pre_trained_skill_bert/ (stored 0%)\n",
            "  adding: model_bert_multi_task_interactive_pre_trained_skill_bert/vocab.txt (deflated 53%)\n",
            "  adding: model_bert_multi_task_interactive_pre_trained_skill_bert/tokenizer_config.json (stored 0%)\n",
            "  adding: model_bert_multi_task_interactive_pre_trained_skill_bert/model_weights (deflated 7%)\n",
            "  adding: model_bert_multi_task_interactive_pre_trained_skill_bert/special_tokens_map.json (deflated 40%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvFDCDIxKDOf"
      },
      "source": [
        "# !zip -r label_encoder_BLOOM_LATEST.zip label_encoder_BLOOM_LATEST\n",
        "# files.download('label_encoder_BLOOM_LATEST.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "FcSwwzAFyE7S",
        "outputId": "4d2b6b90-5869-4131-fab6-ec23094356ad"
      },
      "source": [
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>DifficultyFromAnswerer</th>\n",
              "      <th>difficulty_label</th>\n",
              "      <th>question_answer</th>\n",
              "      <th>skill_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How are western-style xylophones characterised?</td>\n",
              "      <td>by a bright, sharp tone and high register</td>\n",
              "      <td>medium</td>\n",
              "      <td>2</td>\n",
              "      <td>How are western-style xylophones characterised...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Is Nairobi the capital of Kenya?</td>\n",
              "      <td>Yes</td>\n",
              "      <td>easy</td>\n",
              "      <td>0</td>\n",
              "      <td>Is Nairobi the capital of Kenya? Yes</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How many sister cities does the City of Melbou...</td>\n",
              "      <td>six</td>\n",
              "      <td>medium</td>\n",
              "      <td>2</td>\n",
              "      <td>How many sister cities does the City of Melbou...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Is the electric eel a true eel?</td>\n",
              "      <td>No</td>\n",
              "      <td>easy</td>\n",
              "      <td>0</td>\n",
              "      <td>Is the electric eel a true eel? No</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Does Swedish use the perfect participle to for...</td>\n",
              "      <td>No.</td>\n",
              "      <td>easy</td>\n",
              "      <td>0</td>\n",
              "      <td>Does Swedish use the perfect participle to for...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>337</th>\n",
              "      <td>Where was there a vast swarm of butterflies?</td>\n",
              "      <td>In Kyoto there was a vast swarm of butterflies.</td>\n",
              "      <td>medium</td>\n",
              "      <td>2</td>\n",
              "      <td>Where was there a vast swarm of butterflies? I...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>338</th>\n",
              "      <td>What is the most common romanization standard ...</td>\n",
              "      <td>Hanyu Pinyin</td>\n",
              "      <td>medium</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the most common romanization standard ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>339</th>\n",
              "      <td>Is Jakarta the 12th largest city in the world?</td>\n",
              "      <td>yes</td>\n",
              "      <td>medium</td>\n",
              "      <td>2</td>\n",
              "      <td>Is Jakarta the 12th largest city in the world?...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340</th>\n",
              "      <td>What sort of turtles are ectothermic?</td>\n",
              "      <td>all of them</td>\n",
              "      <td>medium</td>\n",
              "      <td>2</td>\n",
              "      <td>What sort of turtles are ectothermic? all of them</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341</th>\n",
              "      <td>Was Gellu Naum the leader of the surrealist mo...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>easy</td>\n",
              "      <td>0</td>\n",
              "      <td>Was Gellu Naum the leader of the surrealist mo...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>342 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Question  ... skill_label\n",
              "0      How are western-style xylophones characterised?  ...           2\n",
              "1                     Is Nairobi the capital of Kenya?  ...           3\n",
              "2    How many sister cities does the City of Melbou...  ...           3\n",
              "3                      Is the electric eel a true eel?  ...           3\n",
              "4    Does Swedish use the perfect participle to for...  ...           3\n",
              "..                                                 ...  ...         ...\n",
              "337       Where was there a vast swarm of butterflies?  ...           3\n",
              "338  What is the most common romanization standard ...  ...           3\n",
              "339     Is Jakarta the 12th largest city in the world?  ...           2\n",
              "340              What sort of turtles are ectothermic?  ...           2\n",
              "341  Was Gellu Naum the leader of the surrealist mo...  ...           3\n",
              "\n",
              "[342 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4178_yLFMWmx"
      },
      "source": [
        "test_features = test[\"question_answer\"].values\n",
        "test_labels = test[\"difficulty_label\"].values\n",
        "test_skill_labels = test[\"skill_label\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DggP9Sxdv_-l",
        "outputId": "60dbfc56-a00a-4218-afdf-04e21edf75a8"
      },
      "source": [
        "test_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 2, 0, 0, 0, 1, 2, 1, 2, 2, 1, 0, 0, 1, 1, 1, 0, 2, 2, 0, 2,\n",
              "       1, 1, 1, 2, 0, 0, 0, 0, 2, 2, 2, 0, 0, 2, 1, 0, 1, 2, 1, 2, 2, 0,\n",
              "       2, 0, 2, 2, 0, 2, 2, 1, 0, 2, 2, 1, 0, 0, 2, 0, 1, 0, 0, 2, 0, 2,\n",
              "       0, 0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 0, 0, 0, 0, 2,\n",
              "       0, 1, 0, 0, 0, 2, 2, 0, 1, 0, 0, 0, 0, 1, 1, 2, 2, 0, 2, 2, 0, 2,\n",
              "       0, 0, 0, 1, 0, 2, 2, 1, 1, 1, 1, 2, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
              "       0, 1, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0, 0, 1, 0, 2, 2, 2,\n",
              "       2, 2, 0, 1, 2, 2, 0, 2, 2, 2, 1, 1, 2, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
              "       0, 0, 0, 0, 1, 2, 0, 2, 2, 2, 1, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0,\n",
              "       2, 0, 0, 2, 1, 0, 2, 1, 1, 0, 0, 2, 2, 0, 2, 2, 0, 0, 2, 2, 2, 1,\n",
              "       2, 2, 0, 1, 2, 1, 2, 1, 2, 1, 2, 1, 0, 0, 1, 2, 2, 1, 0, 0, 0, 1,\n",
              "       2, 0, 0, 2, 0, 2, 0, 0, 2, 1, 1, 2, 2, 0, 2, 0, 2, 2, 1, 2, 2, 2,\n",
              "       0, 1, 2, 0, 1, 1, 2, 2, 0, 2, 1, 0, 2, 1, 0, 1, 1, 2, 0, 1, 1, 1,\n",
              "       1, 2, 1, 0, 2, 0, 0, 2, 0, 1, 0, 1, 1, 0, 2, 0, 1, 2, 0, 0, 1, 0,\n",
              "       1, 2, 1, 1, 1, 2, 2, 1, 2, 0, 2, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 2,\n",
              "       2, 2, 1, 0, 1, 1, 2, 2, 2, 2, 2, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZpmBJuIC2nM",
        "outputId": "fadb5353-055c-4605-a6f2-579f776a5254"
      },
      "source": [
        "test_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['How are western-style xylophones characterised? by a bright, sharp tone and high register',\n",
              "       'Is Nairobi the capital of Kenya? Yes',\n",
              "       'How many sister cities does the City of Melbourne have? six',\n",
              "       'Is the electric eel a true eel? No',\n",
              "       'Does Swedish use the perfect participle to form the present perfect tense? No.',\n",
              "       'Do the different species of zebras interbreed? no',\n",
              "       'What are the reasons for hunting wild ducks? Meat, eggs, and feathers',\n",
              "       'Does Romania share the same language with Moldova? Practically',\n",
              "       'Which guitars use three single-coil pickups? Fender Stratocaster type guitars.',\n",
              "       'How long does it take for the panda cubs skin to turn gray? One to two weeks',\n",
              "       'Which temperature scale did Celsius propose? Celcius',\n",
              "       'Where is Finland located? Northern Europe',\n",
              "       'Is the capital city Oslo? No',\n",
              "       'How many species of otter are there? 13',\n",
              "       \"What's the timber of ancient cimbals like? disfluent like that of small hand-bells or of the notes of the keyed harmonica\",\n",
              "       'Is University of Dhaka the largest public university in Dhaka? Yes',\n",
              "       'Is the Adephaga suborder larger than the Polyphaga suborder? yes',\n",
              "       'Are Sports in Indonesia generally male-orientated? yes',\n",
              "       \"What company administers Leichtenstein's railways? Austrian Federal Railways\",\n",
              "       'When do African elephants lie down? when they are sick or wounded',\n",
              "       'Does Modern Standard Arabic continue to evolve like other languages? yes',\n",
              "       'When did Roosevelt die? On January 6, 1919, Roosevelt died in his sleep.',\n",
              "       'What does the word duck mean? It is the common name for a number of species in the Anatidae family of birds.',\n",
              "       'Did Lincoln beat John C. Breckinridge in the 1860 election? Yes.',\n",
              "       'Was Lee Kuan Yew a successful leader of Singapore? yes',\n",
              "       'Where was Volta born? Como, Italy',\n",
              "       'Is Singapore located at the southern tip of the Korean Penisula? no',\n",
              "       'Was Coolidge the thirteenth President of the United States? Yes',\n",
              "       'Was Celsius born in Uppsala in Sweden? Yes',\n",
              "       'Are Testudines the crown group of the superorder Chelonia? Yes',\n",
              "       'What is the current estimated population of Nairobi? About 3 million',\n",
              "       'Does Romania border Hungary? Yes.',\n",
              "       'How do eels begin life? As flat and transparent larvae, called leptocephali',\n",
              "       'What is the range of lifespans of the octopus? The octopus has a short lifespan.',\n",
              "       'Is the president elected by popular vote? Yes.',\n",
              "       'What areas can giraffes inhabit? savannas, grasslands, or open woodlands',\n",
              "       'What happened in 1833? blah blah blah',\n",
              "       'Are many words describing the navy , types of ships , and other objects or activities on the water of dutch origin ? yes',\n",
              "       'When did Alessandro Volta improve and popularize the electrophorus? Alessandro Volta improved and popularized the electrophorus in 1775.',\n",
              "       \"When was Liechtenstein's current constitution adopted? October 1921\",\n",
              "       'Name an animal that is growing in number due to recent conservation efforts Golden Eagle',\n",
              "       'What bordered by Saudi? Qatar',\n",
              "       'What became one of the most important commercial and military centres of the British Empire? Singapore',\n",
              "       'Are penguins astonishingly agile? In the water they are.',\n",
              "       'How many provinces and territories does Canada have? Ten provinces and three territories',\n",
              "       'Are pocket trumpets compact B trumpets? yes',\n",
              "       'What is the smallest species of fox? the Fennec Fox',\n",
              "       'Do all ants build nests? No, not all ants build nests.',\n",
              "       'Did France cede nearly all of its colonies in Europe in 1763? yes',\n",
              "       \"Did Grover Cleveland support women's suffrage? no\",\n",
              "       \"How can a flute's volume be increased? a flute's volume can generally be increased by making its resonator and tone holes larger\",\n",
              "       'Could Malay have originated from Sumatra island? Yes.',\n",
              "       'Is the leopard solitary? Yes',\n",
              "       \"How many Eagle Scouts were involved in Ford's funeral procession? 400\",\n",
              "       'When did Lincoln begin his political career? 1832.',\n",
              "       'How many children did Grover Cleveland have? 5',\n",
              "       'Is a polar bear at high risk of extinction? yes',\n",
              "       'What is Anders Celsius`s last name? Celsius',\n",
              "       'How many strings does a violin usually have? 4',\n",
              "       'The Savings and Loans Bank was founded, as was the first cotton-weaving mill in what year? 1861',\n",
              "       'What is the largest religious group in Canada? According to 2001 census, 77.1% of Canadians identified as being Christians; of this, Catholics make up the largest group (43.6% of Canadians). The largest Protestant denomination is the United Church of Canada; about 16.5% of Canadians declare no religious affiliation, and the remaining 6.3% were affiliated with religions other than Christianity, of which the largest is Islam numbering 1.9%, followed by Judaism: 1.1%.',\n",
              "       'Does the de Young museum house the Asian Art Museum yes',\n",
              "       'Is romania -LRB- , -RRB- a country in southeastern europe? Yes',\n",
              "       'When do wolves molt? Late Spring or Early Summer',\n",
              "       'Is it not also one of the two official languages of the Yanbian Korean Autonomous Prefecture in China? Yes.',\n",
              "       'How many Swedish speakers were reported in Canada in 2001? There are 16,915 reported Swedish speakers in Canada.',\n",
              "       'Did James Monroe fight in the Continental Army? Yes',\n",
              "       'Is there a way to approximate the age of a turtle? Yes',\n",
              "       \"What is the city's population? 1.6 million\",\n",
              "       'What is another term for Korean adjectives? Adjectives are also known as \"descriptive verbs\" or \"stative verbs\".',\n",
              "       'In what year did the Spanish establish a fort at the Golden Gate and a mission named for Francis of Assisi on the site? In 1776, the Spanish established a fort at the Golden Gate and a mission named for Francis of Assisi on the site.',\n",
              "       'What year did Coolidge open his own law office? 1898',\n",
              "       'Was Calvin Coolidge Republican? Yes',\n",
              "       'Is it true that thermometer had 100 for the freezing point? Yes',\n",
              "       \"When did Charles-Augustin de Coulomb join his father's family in Montpeillier? From 1757 to 1759 he joined his father's family in Montpellier.\",\n",
              "       'Who did Alessandro Volta marry? Alessandro Volta married Teresa Peregrini.',\n",
              "       'Is octopus a common food in Mediterranean cuisine as well as Portuguese cuisine? Yes',\n",
              "       'Where was Isaac Newton born? At Woolsthorpe Manor in Woosthorpe-by-Colsterworth.',\n",
              "       'Does Liechtenstein have an army? No.',\n",
              "       'How many species of zebra are there? Three',\n",
              "       'What is the second main orchestral use of cymbals? The suspended cymbal is the second main orchestral use of symbals.',\n",
              "       \"What is Canada's national unemployment rate? In October 2007, Canada's national unemployment rate is 5.9%.\",\n",
              "       'How many arms does an octopus have? An octopus has four pairs of arms.',\n",
              "       'Is the Giant Panda an endangered species? yes',\n",
              "       'Is it true that the ideas of the Enlightenment shaped the development of the city? Yes.',\n",
              "       \"What is polar bear's skin color? white or cream\",\n",
              "       'Are Indian concert flutes available in standard pitches? Yes',\n",
              "       'Where was the League of Nations created? Paris',\n",
              "       'Were the koalas of South Australia largely exterminated during the early part of the 20th century, but the state has since been repopulated with Victorian stock? The koalas of South Australia were largely exterminated during the early part of the 20th century, but the state has since been repopulated with Victorian stock.',\n",
              "       'Did Volta marry before he became professor of experimental physics at the University of Pavia? No.',\n",
              "       'Do linguists often view Chinese as a language family? Yes, linguists often view Chinese as a language family.',\n",
              "       'In fact, was Avogadro `s famous 1811 paper written in French . ) Yes',\n",
              "       'Was he a member of the Royal Superior Council on Public Instruction? Yes, Avogadro was a member of the Royal Superior Council on Public Instruction.',\n",
              "       \"Does Indonesia have the world's hightest level of biodiversity? No\",\n",
              "       'Who discovered benzene? Michael Faraday',\n",
              "       'Is aquatic respiration in Australian freshwater turtles being studied? yes',\n",
              "       'How are Isabelline penguins different from most penguins? Because they are born with brown rather than black plumage.',\n",
              "       'Was Adams an opponent of the Stamp Act? yes',\n",
              "       'Is the main sport in Uruguay football ? Yes',\n",
              "       'Does Vietnamese have a large number of vowels? Yes, Vietnamese has a comparatively large number of vowels.',\n",
              "       'Are trumpets constructed of brass? Yes',\n",
              "       'What sort of cats are solitary? Leopards',\n",
              "       'From what type of Cymbals can a expert player obtain an enormous dynamic range? An expert player can obtain an enormous dynamic range from crash cymbals.',\n",
              "       'How is the climate in the city? The city is hot and humid.',\n",
              "       'What do river otters eat? River otters eat a variety of fish and shellfish, as well as small land mammals and birds.',\n",
              "       'Did Coolidge meet and marry Grace Anna Goodhue? yes',\n",
              "       'Where did Wilson attend law school? Wilson attended law school at University of Virginia',\n",
              "       'What is the MRT? Mass Rapid Transit system',\n",
              "       \"Wasn't Leonardo da Vinci born on April 15? Yes, Leonardo da Vinci was born on April 15.\",\n",
              "       'Where are bullet ants located? Bullet ants are located in Central and South America.',\n",
              "       'Is Romania a secular state? Yes',\n",
              "       'Was Tesla regarded as a mad scientist? yes',\n",
              "       'Does every drumhead make the same sound? no',\n",
              "       'What type of current did Tesla invent? AC',\n",
              "       'Does San Francisco have a high percentage of gay and lesbian individuals? Yes, according to the 2005 American Community Survey, San Francisco has the highest percentage of gay and lesbian individuals of any of the 50 largest U.S. cities, at 15.4%.',\n",
              "       'Where does air pollution in Beijing come from? surrounding cities and provinces',\n",
              "       'Four years after opening his shop , Watt began what? Watt began to experiment with steam after his friend, Professor John Robison, called his attention to it.',\n",
              "       'Why did Cleveland want to hide his cancer surgery from the public? because of the ficial depression of the country',\n",
              "       'Which property did James Monroe sell in 1817? Monroe Hill on the grounds of the University of Virginia.',\n",
              "       'How old was Celsius when he died? 42',\n",
              "       'Are cougars larger than jaguars? no',\n",
              "       'What animal attracts the most humor and silliness? the duck',\n",
              "       'What are the three heaviest cats in the world? tiger, lion, and jaguar',\n",
              "       'Did Canadian soldiers win the Battle of Vimy Ridge in 1917? Yes',\n",
              "       'Was Isaac Newton religious? Yes, he was highly religious, though an unorthodox Christian.',\n",
              "       'Do kangaroos have many natural predators? No',\n",
              "       'Who did Ford nominate for Vice President? Bob Dole',\n",
              "       'Hassan Massoudy is a master of what genre? Arabic calligraphy',\n",
              "       'Is it true that he published his invention of the Voltaic pile battery? Yes',\n",
              "       'Does the koala fill the same ecological role as the sloth of South America? The koala fills the same ecological role as the sloth of South America.',\n",
              "       'Why do wolves howl? Howling helps pack members keep in touch, allowing them to communicate effectively in thickly forested areas or over great distances. Howling also helps to call pack members to a specific location. Howling can also serve as a declaration of territory, as shown in a domit wolf&apos;s tendency to respond to a human imitation of a \"rival\" wolf in an area the wolf considers its own.',\n",
              "       'Do most Japanese people employ politeness? yes',\n",
              "       'Is fifty percent or more of Korean vocabulary of Chinese origin? Yes',\n",
              "       \"What are the names of a piano's pedals? The names of a piano's pedals are una corda, sostenuto, and damper.\",\n",
              "       'What is the smallest suborder of turtles? Pleurodira',\n",
              "       \"Is Uruguay 's oldest church in San Carlos , Maldonado ? Yes\",\n",
              "       'Is Liechtenstein the smallest German-speaking country in the world? Yes',\n",
              "       'Have managed populations of European honey bees experienced substantial declines? yes',\n",
              "       'Have cymbals been used historically to suggest bacchanal? Yes',\n",
              "       'What is the life expectancy for men in Finland? 75 years',\n",
              "       \"Is Adams' birthplace part of a national park? yes\",\n",
              "       'Are wolves built for stamina? Yes',\n",
              "       'Are the largest turtles aquatic? yes',\n",
              "       'Is the largest living species the emperor penguin -LRB- aptenodytes forsteri -RRB-? Yes',\n",
              "       'How many children did Avogadro have? six',\n",
              "       'Did ants evolve from wasp-like ancestors in the mid-Cretaceous period between 110 and 130 million years ago and diversified after the rise of flowering plants? yes',\n",
              "       'Where do sea otters live? Pacific coast of North America',\n",
              "       'Were trumpet players heavily guarded? yes',\n",
              "       'Copenhagen is the capital of what country? Denmark',\n",
              "       'What was Amedeo Avogadro`s profession? professor of physics',\n",
              "       'Where was Grant born? A log cabin in Point Pleasant, Clermont County, Ohio',\n",
              "       'Does the mother care for the young? No',\n",
              "       'What trumpet was the first to be allowed in the Christian Church? Slide trumpets',\n",
              "       \"The John Adams Library , housed at the Boston Public Library , contains what? Adams's personal collection of more than 3,500 volumes\",\n",
              "       'Is Ford related with the assassination of John F. Kennedy? Yes',\n",
              "       'What principles did Newton explain for mechanics? In mechanics, Newton enunciated the principles of conservation of momentum and angular momentum',\n",
              "       'When was Charles-Augustin de Coulomb permanently stationed in Paris? Yes',\n",
              "       'How tall were the tallest prehistoric penguins? as tall as an adult human',\n",
              "       'What is the mean level of mercury in American lobsters? 0.31 ppm',\n",
              "       'Where does the word \"violin\" come from? the Middle Latin word vitula, meaning \"stringed instrument\"',\n",
              "       'Did he suffer from anxiety and increasingly frequent bouts of mental illness throughout his life, and died largely unknown, at the age of 37, from a self-inflicted gunshot wound? Yes.',\n",
              "       \"What is now part of Adams National Historical Park? John Adams' birthplace\",\n",
              "       \"What is the earliest historical reference in Europe? Arnold Schlick's Spiegel der Orgelmacher und Organisten\",\n",
              "       'What religions are found in Uruguay? Roman Catholic, Protestant, Jewish',\n",
              "       'Who appointed Harlan Fiske Stone to the Supreme Court? Coolidge',\n",
              "       'What is responsible for converting the hydrogen byproduct of fermentation into acetate? The digestive system of a kangaroo',\n",
              "       'Are Immature sea turtles not cared for by the adults ? yes',\n",
              "       \"Who is the mayor of Ottawa? Larry O'Brien\",\n",
              "       'What are the names of the two zoos in Berlin? The two zoos in Berlin are the Zoologischer Garten Berlin and the Tierpark Friedrichsfelde.',\n",
              "       'Had Monroe racked up many debts during his years of public life ? yes',\n",
              "       'Was Abraham Lincoln the first President of the United States? No',\n",
              "       'Was The SI unit of charge , the coulomb , named after him? yes',\n",
              "       'Did the Dutch build the Elmina Castle? No',\n",
              "       \"Who helped to fund Roosevelt's African safari? Ficed by Andrew Carnegie and his own proposed writings\",\n",
              "       \"What are the elephant's ears important for? temperature regulation\",\n",
              "       'Are hutongs disappearing? yes',\n",
              "       'Did John Adams support the Stamp Act of 1765? No',\n",
              "       'Is Vietnamese the mother tongue of the Vietnamese people? Yes',\n",
              "       'Is it the smallest and highest-pitched member of the violin family of string instruments, which also includes the viola and cello? Yes, it is the smallest and highest-pitched member of the violin family of string instruments, which also includes the viola and cello.',\n",
              "       'Are tigers solitary animals? Yes',\n",
              "       'What religion did Isaac Newton follow? he never made a public declaration of his private faith',\n",
              "       'Who frequented the circle of the British-Australian artist John Peter Russell? Van Gogh',\n",
              "       'Do both sexes of giraffe have horns? yes',\n",
              "       'What is the mean level of mercury in American lobsters? 0.31 ppm',\n",
              "       'Does Uruguay have cold summers? no',\n",
              "       'Where was James Monroe born? Westmoreland County, Virginia',\n",
              "       \"Did Monroe' wedding happen at the Trinity Church in New York? Yes\",\n",
              "       'Was Volta made a count in 1810? No.',\n",
              "       'Is the syntax of German different with different rules? yes',\n",
              "       \"Was Isaac Newton educated at The King's Schol, Grantham? yes\",\n",
              "       \"How many Eagle Scouts were involved in Ford's funeral procession? About 400\",\n",
              "       'Are they easily identified by their elbowed antennae and a distinctive node-like structure that forms a slender waist? Yes, they are easily identified by their elbowed antennae and a distinctive node-like structure that forms a slender waist.',\n",
              "       \"Did Cartier not use the word ` Canada ' to refer to not only that village , but the entire area subject to Donnacona , Chief at Stadacona ? yes\",\n",
              "       'Was watt a fellow of the Royal Society of Edinburgh and the Royal Society of London? Yes.',\n",
              "       'Is the violin shaped like an hourglass? Yes.',\n",
              "       'Can polar bears be seen under infrared photography? Polar bears are nearly invisible under infrared photography.',\n",
              "       'Is Jakarta a city Yes',\n",
              "       'Is Finnish a member of the Baltic-Finnic subgroup of the Uralic languages? Yes',\n",
              "       'Where is old Ghana in relation to present Ghana? 500 miles north',\n",
              "       \"Has Indonesia the world 's largest Muslim population ? yes\",\n",
              "       'Does the octopus have a hard beak? Yes, the octopus has a hard beak.',\n",
              "       'Is the study of beetles called coleopterology , and its practitioners are coleopterists ? Yes.',\n",
              "       'What is the bridge used for? The transfer of string vibrations.',\n",
              "       'Is James Monrow the fifth president of US? Yes',\n",
              "       'Where is Charles-Augustin de Coulomb from? France',\n",
              "       \"Are Gray Wolves native to North America? No. Current theory suggests that it's from Eurasia\",\n",
              "       'Are there a large number of Jews living in Egypt today? No',\n",
              "       'Are all dialects of Korean similar to each other? Yes',\n",
              "       'When is the first record of S08_settlement in Singapore? second century AD',\n",
              "       'Where are the Western Arabic numerals used? present-day North Africa',\n",
              "       'When did Charles-Augustin de Coulomb retire to a small estate he possessed at Blois? Charles-Augustin de Coulomb retired to a small estate he possessed at Blois on the outbreak of the revolution in 1789.',\n",
              "       'Was Alessandro Volta a professor of chemistry? Alessandro Volta was not a professor of chemistry.',\n",
              "       'What is the SI unit measuring magnetic flux density or magnetic induction? the tesla',\n",
              "       'Where do sea turtles lay their eggs? Holes Dug into the Mud or Sand',\n",
              "       'Is Liechtenstein heavily urbanized? No',\n",
              "       \"Where was much of Montreal's industry during the late 19th and early-to-mid 20th century? The Sud-Ouest borough was home to much of the city's industry during the late 19th and early-to-mid 20th century.\",\n",
              "       'When was the Six Day War? 1967',\n",
              "       'Who determined the dependence of the boiling of water with atmospheric pressure? Anders Celsius',\n",
              "       'How do the Java and Bali use xylophones? In gamelan ensembles',\n",
              "       'How many civilians died in the 1998 U.S. embassy bombing? Over two hundred',\n",
              "       'What are violins made of? different types of wood',\n",
              "       'When was the An Shi Rebellion launched? in 755 AD',\n",
              "       \"Is the leopard -LRB- panthera pardus -RRB- an old world mammal of the felidae family and the smallest of the four (`` ` big cats ('' ' of the genus panthera , along with the tiger , lion , and jaguar? Yes\",\n",
              "       \"Was Henri Becquerel first in his family to occupy the physics chair at the Museum National d'Histoire Naturelle? No\",\n",
              "       \"Is Indonesia the world's largest archipelagic state? yes\",\n",
              "       'Where does the German President live? The German President lives west of the center, Schloss Bellevue.',\n",
              "       'Where are the Western Arabic numerals used? North Africa',\n",
              "       'What allows a duck to filter water out of the side of their beaks and keep food inside? Tiny rows of plates called lamellae',\n",
              "       \"What would a tiger do when seized by a crocodile? strike at the reptile's eyes with its paws\",\n",
              "       'How many years ago was the Luther Bible by Martin Luther printed? 475',\n",
              "       'What happens when mothers lose a chick? They sometimes attempt to \"steal\" another chick.',\n",
              "       'Who were the Orkhon inscriptions built for? The Orkhon inscriptions were erected in honour of the prince Kul Tigin and his brother Emperor Bilge Khan.',\n",
              "       'Has the terrain in the city been artificially raised? yes',\n",
              "       'What do river otters eat? a variety of fish and shellfish, as well as small land mammals and birds',\n",
              "       'What prompted the city to upgrade its building codes The threat of major earthquakes',\n",
              "       'Why is the giant otter becoming increasingly rare? poaching, habitat loss, and the use of mercury in illegal alluvial gold mining',\n",
              "       \"What have become flippers, useless for flight in the air? Penguins' wings\",\n",
              "       'Why does the cornet have a slightly mellower tone than the trumpet? because it has conical bores',\n",
              "       'Approximately how many species of Testudines are alive today? 300',\n",
              "       'Are otters playful animals? yes',\n",
              "       'Did lincoln have 18 months of schooling? Yes',\n",
              "       'Who heavily influenced the architecture and culture of Montevideo? European immigrants',\n",
              "       'What was the Faraday effect first called? diamagnetism',\n",
              "       'Does it have a border with Norway? Yes',\n",
              "       'Is an official language of Canada German? No.',\n",
              "       'What is also the distance that Antarctic tourists are told to keep from penguins? 3 meters',\n",
              "       'Did Lincoln ever represent Alton & Sangamon Railroad? Yes',\n",
              "       \"What are some of the cougar's primary food sources? ungulates such as deer, elk, and bighorn sheep, as well as domestic cattle, horses, and sheep\",\n",
              "       \"Is Melbourne home to Australia's busiest seaport? Yes\",\n",
              "       'Did Bartolomeo Cristofori invent the modern piano? Yes',\n",
              "       'Where is the Park of the Reserve located? Near the downtown area.',\n",
              "       'What did Anders Celsius determine about the boiling of water? dependence with atmospheric pressure',\n",
              "       'What city in the UK has been subjected to bouts of terrorism? London has been subjected to bouts of terrorism.',\n",
              "       'What foods do pandas eat? bamboo, honeys, eggs, fish, yams, shrub leaves, oranges, and baas',\n",
              "       'When did Adams graduate from college? 1755.',\n",
              "       'Can the origins of cymbals be traced back to prehistoric times? yes',\n",
              "       'Which type of beetle is a pest of potato plants? Colorado potato beetle',\n",
              "       'Is there a way to approximate the age of a turtle? yes',\n",
              "       'What trumpet was the first to be allowed in the Christian Church? slide trumpets',\n",
              "       'What is the battery made by Alessandro Volta credited as? the first electrochemical cell',\n",
              "       'Is it a disadvantage for something to be unsafe to handle? yes',\n",
              "       'The ideas of the Enlightenment shaped the development of what? the city, Lima',\n",
              "       'Has the terrain in the city been artificially raised? Yes.',\n",
              "       'Is the SI unit for radioactivity named after him? Yes',\n",
              "       'Was the Italian 10.000 lira banknote created before the euro? yes',\n",
              "       'How many times has Uruguay won the World Cup? Twice.',\n",
              "       'Where was Isaac Newton born? Woolsthorpe Manor in Woolsthorpe-by-Colsterworth',\n",
              "       'Was Gerald Ford the 38th President of the United States? yes',\n",
              "       'When was the pan flute spread to other parts of Europe? After the 7th century BC',\n",
              "       'Who was President when Wilson finished Congressional Government? Grover Cleveland',\n",
              "       'Is the ant a marsupial? no',\n",
              "       'What happened in 1860? Vincent van Gogh attended the Zundert village school from 1860.',\n",
              "       'Was Grover Cleveland the twenty-seventh president of the United States? No.',\n",
              "       'With what party did Adams run for presidency? The Federalist Party',\n",
              "       'What are the differences between English and Swedish pronouns? Swedish pronouns are basically the same as those of English but distinguish two genders and have an additional object form, derived from the old dative form, as well as a distinct genitive case.',\n",
              "       'Was John Calvin Coolidge Jr. was born in Las Vegas? No',\n",
              "       'When did Isaac Newton discover the generalized binomial theorem? In 1665.',\n",
              "       'What field did Woodrow Wilson leave law practice to study? history and political science',\n",
              "       'Is the standard of living in San Franciscio high? Yes',\n",
              "       \"What is the name of the largest church in Montreal? Saint Joseph's Oratory is the largest church in Montreal.\",\n",
              "       'Are the strings of a classical lyre made of gut? Yes',\n",
              "       'Where did the xylophone originate? Indonesia',\n",
              "       \"Is it advantageous for a grand piano's metal plate to be quite massive? It is advantageous for the plate to be quite massive.\",\n",
              "       'Where is Melbourne situated? boundary of the very hot inland areas and the cold southern ocean',\n",
              "       'How many countries in Europe are bigger than Romania? eleven',\n",
              "       'Where did he serve two terms? the Church of Scotland',\n",
              "       'What fictional stories include a main character named Santiago? Interview with the Vampire, The Alchemist, and others',\n",
              "       'What is the sustain pedal called? damper pedal',\n",
              "       'What do beetles eat? Some are generalists, eating both plants and animals. Other beetles are highly specialised in their diet.',\n",
              "       'Was Thedore Roosevelt a member of the Republican Party? Yes',\n",
              "       'Give an example of the ten Beta World Cities. San Trancisco',\n",
              "       'When was Coolidge born? Plymouth, Windsor County, Vermont',\n",
              "       'Is an acoustic guitar dependent on an external device? No.',\n",
              "       'Is Golden Gate Park the largest city park yes',\n",
              "       'Is a bee an insect? yes',\n",
              "       'What was Michael Faraday`s profession? chemist and physicist',\n",
              "       'Does Qatar rank as the eighth richest country in the world per capita? No.',\n",
              "       'Oxygen is what? One kind of gas obtained via a tracheal system.',\n",
              "       \"Who were the midnight judges? They were a series of judges, so called because most of them were formally appointed days before Adams' presidential term expired\",\n",
              "       'Is polar bear a mammal? Yes',\n",
              "       'What is a hybrid animal resulting from a union between a leopard and a puma? a pumapard',\n",
              "       'Does Theodore Roosevelt have a brother? Yes',\n",
              "       'What food gave Isaac Newton clues to his theory of gravity? apple',\n",
              "       'What is a colectivo? Automobiles that renders express service on some major roads of the Lima Metropolitan Area.',\n",
              "       'Did he experiment with individual cells? Yes',\n",
              "       'Is Malay an agglutinative language? Yes.',\n",
              "       'How old is the oldest known representation of a guitar-like intrument being played? 3,300 years old',\n",
              "       \"Did Johann Josef Loschmidt first calculate the value of Avogadro's number? yes\",\n",
              "       \"How does a Mallard's tongue work? It uses short spikes to push struggling prey and other food down its throat\",\n",
              "       'What is the basic word order in Malay? Subject Object Verb.',\n",
              "       'What is the Faraday effect? The Faraday effect is the phenomenon that the plane of polarisation of linearly polarised light can be rotated by the application of an external magnetic field aligned in the direction the light is moving.',\n",
              "       'What is the official language of Turkey? Turkish.',\n",
              "       \"What was Grant's political affiliation? Republican\",\n",
              "       'Who did Newton see as the master creator? God',\n",
              "       'Around how many recognized octopus species are there? There are around 300 recognized octopus species.',\n",
              "       'What is the caridoid escape reaction? Swimming backwards quickly by curling and uncurling their abdomen.',\n",
              "       'What is the middle pedal called on grand pianos? the sostenuto pedal.',\n",
              "       'Was Malay language written using Pallava? Yes',\n",
              "       'Why are otters vulnerable to prey depletion? Prey-dependence',\n",
              "       'What religions are found in Uruguay? Roman Catholic, Protestant, Jewish, and nonprofessing.',\n",
              "       \"Is English Ghana's official language? yes\",\n",
              "       \"In what language was his 1811 paper published? Avogadro's 1811 paper was published in French.\",\n",
              "       'Does the de Young museum house the Asian Art Museum No',\n",
              "       'Are violas and cellos in the same family of instruments as violins? yes',\n",
              "       'Is a guitar an instrument? yes',\n",
              "       'What are some common predators of ducks? Pike, crocodilians, herons, hawks and eagles.',\n",
              "       'Did Grant & Perkins not sell harnesses , saddles , and other leather goods and purchase hides from farmers in the prosperous Galena area ? they did',\n",
              "       'Was his 1800 paper written in French? Yes',\n",
              "       'When was his last painting for the Post published? 1963',\n",
              "       \"Where did Coolidge's grandfather had government offices? Plymouth\",\n",
              "       'Where is the word \"swan\" derived from? Old English swan.',\n",
              "       'How many legs do lobsters have? 10',\n",
              "       'Are more residents employed by small businesses than in 1977? No',\n",
              "       'Was the SI unit of charge named after Charles-Augustin de Coulomb? Yes, the SI unit of charge, the coulomb, was named after him.',\n",
              "       'Copenhagen is ranked number one worldwide for which things? Most Livable City, Location Ranking Survey',\n",
              "       'What happened in 1810? Volta was made a count by Napoleon.',\n",
              "       'What kind of piano did Irving Berlin play? transposing piano',\n",
              "       'Where was there a vast swarm of butterflies? In Kyoto there was a vast swarm of butterflies.',\n",
              "       'What is the most common romanization standard for Standard Mandarin today? Hanyu Pinyin',\n",
              "       'Is Jakarta the 12th largest city in the world? yes',\n",
              "       'What sort of turtles are ectothermic? all of them',\n",
              "       'Was Gellu Naum the leader of the surrealist movement in Romania ? Yes'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MlOvANUwprAw",
        "outputId": "ec819187-46ee-4208-974c-6cb35fbc8bfb"
      },
      "source": [
        "test_features[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'How are western-style xylophones characterised? by a bright, sharp tone and high register'"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-nCVhlaoXaXM",
        "outputId": "237bf9d4-cd0c-44d3-f6fa-37878878136a"
      },
      "source": [
        "test_features[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'How are western-style xylophones characterised? by a bright, sharp tone and high register'"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xncpeEmoGsB"
      },
      "source": [
        "# syllabus = get_syllabus(test_features.values)\n",
        "# poincare_emb_test = get_poincare_embeddings(syllabus)\n",
        "# # for i,oincare in enumerate(poincare_emb_test):\n",
        "# #   for x in oincare:\n",
        "# #     print(i)\n",
        "# #     print(oincare)\n",
        "# #     print(poincare_model.kv.get_vector(str(x)))\n",
        "\n",
        "# poincare_embedding_test =  [exponential_map(np.expand_dims( np.hstack(  [ poincare_model.kv.get_vector(str(x)) for x in taxonomy ] ),axis=0)) for taxonomy in poincare_emb_test ]\n",
        "# max_val = 0\n",
        "# max_emb =None\n",
        "# for embedding in poincare_embedding_test:\n",
        "#   val = embedding.shape[1]\n",
        "#   if val >max_val:\n",
        "#     max_val=val\n",
        "#     max_emb =embedding\n",
        "# max_val\n",
        "# concatenated_embedding = []\n",
        "# for embedding in poincare_embedding_test:\n",
        "#   if embedding.shape[1] < max_val:\n",
        "#     new_embedding = np.append(embedding, np.expand_dims(np.zeros(max_val-embedding.shape[1]),axis=0),axis=1)\n",
        "#   else:\n",
        "#     new_embedding = embedding\n",
        "#   concatenated_embedding.append(np.squeeze(new_embedding,axis=0))\n",
        "# poincare_embeddings_final = np.stack(concatenated_embedding, axis=0)\n",
        "# for feature_set in test_features:\n",
        "#   if feature_set[1]!=feature_set[1]: #to check for nan\n",
        "#     print(\"here\")\n",
        "#     feature_set[1] = \"unk\"\n",
        "#   else:\n",
        "#     feature_set[1]=feature_set[1].lower()\n",
        "# difficulty_level_vectors=[]\n",
        "# for feature_set in test_features:\n",
        "#   words = [word for word in feature_set[1].split(\" \")]\n",
        "#   if len(words) > 1:\n",
        "#     print(\"here\")\n",
        "#     difficulty_level_vectors.append(np.mean(wv[words],axis=0))\n",
        "#   else:\n",
        "#     difficulty_level_vectors.append(wv[words].squeeze(axis=0))\n",
        "# difficulty_level_vectors = np.array(difficulty_level_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qe4qYkV2C4fX",
        "outputId": "9e2969b9-9076-45dc-cbe8-a63769ea3d9b"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "for sent in test_features:\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "test_skill_labels = torch.tensor(test_skill_labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 34\n",
        "# test_poincare_tensor = torch.tensor(poincare_embeddings_final,dtype=torch.float)\n",
        "# print(test_poincare_tensor.shape)\n",
        "# difficulty_tensor = torch.tensor(difficulty_level_vectors,dtype=torch.float)\n",
        "# print(\"difficulty_tensor\",difficulty_tensor.shape)\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, test_labels,test_skill_labels)\n",
        "# Create the DataLoader.\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPCktQT9DVT4",
        "outputId": "de03da05-4127-48bd-bb62-3ff1b45b94d3"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions,skill_predictions , true_labels, true_skill_labels = [], [], [], []\n",
        "\n",
        "# Predict ea\n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels,skill_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  # print(\"b_input_ids\",b_input_ids.shape)\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs,skill_ouputs = model(b_input_ids,b_input_mask)\n",
        "\n",
        "  logits = outputs\n",
        "  skill_logits = skill_ouputs\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  skill_logits = skill_logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  skill_labels = skill_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  skill_predictions.append(skill_logits)\n",
        "  true_labels.append(label_ids)\n",
        "  true_skill_labels.append(skill_labels)\n",
        "\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 342 test sentences...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_WchmXtDspr"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (final_data.label.sum(), len(final_data.label), (final_data.label.sum() / len(final_data.label) * 100.0)))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vbdVvUXDxgf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2316c87e-5449-4a6b-f11d-ae96b434a80f"
      },
      "source": [
        "true_skill_labels[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 3, 3, 3, 3, 2, 3, 2, 2, 2, 3, 3, 2, 3, 3, 2, 2, 2, 3, 3, 3, 3,\n",
              "       4, 3, 3, 3, 2, 3, 3, 2, 3, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5BoY2hKGb7_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b201d34-30ac-4171-ca12-220841b518e3"
      },
      "source": [
        "import numpy as np\n",
        "pred =  np.argmax(predictions[0],axis=1).flatten()\n",
        "pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 2, 1, 0, 0, 1, 0, 2, 2, 2, 2, 0, 2, 1, 0, 1, 0, 2, 2, 0, 2,\n",
              "       2, 1, 1, 2, 0, 0, 0, 0, 1, 0, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPuK0-vzGp3R",
        "outputId": "406aa1be-a016-443e-d1cf-e6d9ce10a616"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5MKFS0iXm7l",
        "outputId": "7299d2e2-6fd1-44ef-e13c-0b360bb1eddd"
      },
      "source": [
        "import numpy as np\n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total MCC: 0.479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOTqUYPmEUCn",
        "outputId": "0e8bee38-28de-449d-98ca-79cfbbcd87af"
      },
      "source": [
        "flat_skill_predictions = np.concatenate(skill_predictions, axis=0)\n",
        "\n",
        "flat_skill_predictions = np.argmax(flat_skill_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_skill_labels = np.concatenate(true_skill_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_skill_labels, flat_skill_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total MCC: 0.637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EdmAmoA0Y4zS",
        "outputId": "a44d119f-b379-4b6d-a7df-bed68e70c1d7"
      },
      "source": [
        "question_answer[30]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Did Mainland Nova Scotia not come under British rule with the Treaty of Utrecht    (: ; ? no!'"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlqpVfk-NW_F"
      },
      "source": [
        "def accuracy_per_class(preds_flat, labels_flat):\n",
        "\n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {get_labels(label)}')\n",
        "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o29QuEYW-mzm",
        "outputId": "3c13d150-2bde-46b9-8e5b-0a9beedec0e9"
      },
      "source": [
        "accuracy_per_class(flat_predictions,flat_true_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class: 0\n",
            "Accuracy: 106/134\n",
            "\n",
            "Class: 1\n",
            "Accuracy: 50/85\n",
            "\n",
            "Class: 2\n",
            "Accuracy: 67/123\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed7_zfiDNaOv",
        "outputId": "972652e9-3d68-49f2-e510-4ba676ebcbb9"
      },
      "source": [
        "accuracy_per_class(flat_predictions,flat_true_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class: Difficult\n",
            "Accuracy: 106/134\n",
            "\n",
            "Class: Easy\n",
            "Accuracy: 50/85\n",
            "\n",
            "Class: Medium\n",
            "Accuracy: 67/123\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "4_vxvq7rHlgr",
        "outputId": "e13b9400-db28-41fa-dbf7-1c8a900ae7ce"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "plt.title('MCC Score per Batch')\n",
        "plt.ylabel('MCC Score (-1 to +1)')\n",
        "plt.xlabel('Batch #')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v48rDl4JHmhv",
        "outputId": "812f1be3-e6ea-4013-85c8-2527a62f5caf"
      },
      "source": [
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total MCC: 0.479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drJC0xYkHr_8",
        "outputId": "7e8380a5-75cb-4928-c869-29d9d6eb3cd9"
      },
      "source": [
        "print('Total MCC: %.3f' % mcc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total MCC: 0.247\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8K0OFM-c7Fv",
        "outputId": "5e07a411-faba-4431-e25a-599ed13945cd"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "#difficulty\n",
        "print(precision_recall_fscore_support(flat_true_labels, flat_predictions, average='micro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.652046783625731, 0.652046783625731, 0.652046783625731, None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44lMA088c7Fv",
        "outputId": "fc7bde57-c761-46d6-cc12-4d436f1ea3f7"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "#difficulty\n",
        "print(precision_recall_fscore_support(flat_true_labels, flat_predictions, average='macro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.641579548923942, 0.6413318391305072, 0.6370064910271096, None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ul7CnYqIYjmH",
        "outputId": "89285661-abbc-4768-9f18-62d3b985e9ab"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "#difficulty\n",
        "print(precision_recall_fscore_support(flat_true_labels, flat_predictions, average='weighted'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.6672877902080783, 0.652046783625731, 0.6557537026989007, None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBpMQFrz9Als",
        "outputId": "6898caaa-19ef-47e5-b8e9-474786be1ee7"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "#skill_name\n",
        "print(precision_recall_fscore_support(flat_true_skill_labels, flat_skill_predictions, average='micro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0.5012016604762946, 0.5012016604762946, 0.5012016604762946, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcaAMXG69Als",
        "outputId": "fa6f0113-3657-4681-9775-91960e20695d"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "#skill name\n",
        "print(precision_recall_fscore_support(flat_true_skill_labels, flat_skill_predictions, average='macro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0.4829542858816799, 0.4630626921284685, 0.4700329767990987, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zivypLKV9Als",
        "outputId": "62809433-2b0d-4334-a2bd-923f66e46211"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "#skill name\n",
        "print(precision_recall_fscore_support(flat_true_skill_labels, flat_skill_predictions, average='weighted'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0.4963391871168191, 0.5012016604762946, 0.4967305425385167, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFediYEjlKjX"
      },
      "source": [
        "def get_confusion_matrix(predicted,actual):\n",
        "    conf_matrix = np.zeros((5, 5))\n",
        "    for pred,act in zip(predicted,actual):\n",
        "        conf_matrix[act,pred]+=1\n",
        "    return conf_matrix\n",
        "        \n",
        "def get_TP(confusion_matrix,label):\n",
        "    tp = confusion_matrix[label][label]\n",
        "    return tp\n",
        "\n",
        "def get_FN(confusion_matrix,label):\n",
        "    row = confusion_matrix[label,]\n",
        "    row_truepositives = row[label]\n",
        "    fn = row.sum() - row_truepositives\n",
        "    return fn\n",
        "\n",
        "def get_FP(confusion_matrix,tag):\n",
        "    col = confusion_matrix[:,tag]\n",
        "    col_tp = col[tag]\n",
        "    #  sum of all values in column except tp\n",
        "    fp = col.sum() - col_tp\n",
        "    return fp\n",
        "def Precision(conf_matrix):\n",
        "    precision = 0.0\n",
        "    for label in [0,1,2,3,4]:\n",
        "        dividor= get_TP(conf_matrix,label)+get_FP(conf_matrix,label)\n",
        "        if dividor != 0.0:\n",
        "            precision += (get_TP(conf_matrix,label))/dividor\n",
        "    return (precision / 5)\n",
        "\n",
        "def Recall(conf_matrix):\n",
        "    recall = 0.0\n",
        "    for label in [0,1,2,3,4]:\n",
        "        dividor=get_TP(conf_matrix,label)+get_FN(conf_matrix,label)\n",
        "        if dividor != 0.0:\n",
        "            recall += (get_TP(conf_matrix,label))/dividor\n",
        "    return (recall / 5)\n",
        "\n",
        "def F1(precision,recall):\n",
        "    return (2*precision*recall)/(precision+recall)\n",
        "def accuracy_per_class(preds_flat, labels_flat):\n",
        "\n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label}')\n",
        "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n",
        "def print_metrics(predictions,test_labels):\n",
        "    conf_matrix = get_confusion_matrix(predictions,test_labels)\n",
        "    precision = Precision(conf_matrix)\n",
        "    recall = Recall(conf_matrix)\n",
        "    f1_score = F1(precision,recall)\n",
        "    print(\"Macro : Precision:{}, Recall: {}, F1: {}\".format(precision,recall,f1_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFEi23ejPfOm"
      },
      "source": [
        "def Precision_macro_weighted(conf_matrix,test_samples):\n",
        "    accum =0\n",
        "    label_wise_precision = dict()\n",
        "    for label in [0,1,2,3,4]:\n",
        "        true_sample = [sample for sample in test_samples if sample==label ]\n",
        "        if (get_TP(conf_matrix,label)+get_FP(conf_matrix,label))!=0:\n",
        "            accum+= float(len(true_sample)) *(get_TP(conf_matrix,label)/(get_TP(conf_matrix,label)+get_FP(conf_matrix,label)))\n",
        "            label_wise_precision[label] = get_TP(conf_matrix,label)/(get_TP(conf_matrix,label)+get_FP(conf_matrix,label))\n",
        "\n",
        "    \n",
        "    precision =  accum/len(test_samples)\n",
        "            \n",
        "    return precision\n",
        "\n",
        "\n",
        "def Recall_macro_weighted(conf_matrix,test_samples):\n",
        "    accum =0\n",
        "    label_wise_recall = dict()\n",
        "    for label in [0,1,2,3,4]:\n",
        "        true_sample = [sample for sample in test_samples if sample==label ]\n",
        "\n",
        "        if (get_TP(conf_matrix,label)+get_FN(conf_matrix,label))!=0:\n",
        "            accum+= float(len(true_sample)) * (get_TP(conf_matrix,label)/(get_TP(conf_matrix,label)+get_FN(conf_matrix,label)))\n",
        "            label_wise_recall[label] = get_TP(conf_matrix,label)/(get_TP(conf_matrix,label)+get_FN(conf_matrix,label))\n",
        "\n",
        "    \n",
        "    recall =  accum/len(test_samples)\n",
        "    return recall\n",
        "def print_weighted_metrics(predictions,test_labels):\n",
        "    conf_matrix = get_confusion_matrix(predictions,test_labels)\n",
        "    precision = Precision_macro_weighted(conf_matrix,test_labels)\n",
        "    recall = Recall_macro_weighted(conf_matrix,test_labels)\n",
        "    f1_score = F1(precision,recall)\n",
        "    print(\"Macro : Precision:{}, Recall: {}, F1: {}\".format(precision,recall,f1_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY18K7M6EV6F"
      },
      "source": [
        "def get_confusion_matrix(predicted,actual):\n",
        "    conf_matrix = np.zeros((3, 3))\n",
        "    for pred,act in zip(predicted,actual):\n",
        "        conf_matrix[act,pred]+=1\n",
        "    return conf_matrix\n",
        "        \n",
        "def get_TP(confusion_matrix,label):\n",
        "    tp = confusion_matrix[label][label]\n",
        "    return tp\n",
        "\n",
        "def get_FN(confusion_matrix,label):\n",
        "    row = confusion_matrix[label,]\n",
        "    row_truepositives = row[label]\n",
        "    fn = row.sum() - row_truepositives\n",
        "    return fn\n",
        "\n",
        "def get_FP(confusion_matrix,tag):\n",
        "    col = confusion_matrix[:,tag]\n",
        "    col_tp = col[tag]\n",
        "    #  sum of all values in column except tp\n",
        "    fp = col.sum() - col_tp\n",
        "    return fp\n",
        "def Precision(conf_matrix):\n",
        "    precision = 0.0\n",
        "    for label in [0,1,2]:\n",
        "        dividor= get_TP(conf_matrix,label)+get_FP(conf_matrix,label)\n",
        "        if dividor != 0.0:\n",
        "            precision += (get_TP(conf_matrix,label))/dividor\n",
        "    return (precision / 3)\n",
        "\n",
        "def Recall(conf_matrix):\n",
        "    recall = 0.0\n",
        "    for label in [0,1,2]:\n",
        "        dividor=get_TP(conf_matrix,label)+get_FN(conf_matrix,label)\n",
        "        if dividor != 0.0:\n",
        "            recall += (get_TP(conf_matrix,label))/dividor\n",
        "    return (recall / 3)\n",
        "\n",
        "def F1(precision,recall):\n",
        "    return (2*precision*recall)/(precision+recall)\n",
        "def accuracy_per_class(preds_flat, labels_flat):\n",
        "\n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label}')\n",
        "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n",
        "def print_metrics(predictions,test_labels):\n",
        "    conf_matrix = get_confusion_matrix(predictions,test_labels)\n",
        "    precision = Precision(conf_matrix)\n",
        "    recall = Recall(conf_matrix)\n",
        "    f1_score = F1(precision,recall)\n",
        "    print(\"Macro : Precision:{}, Recall: {}, F1: {}\".format(precision,recall,f1_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtXSpDmEEV6H"
      },
      "source": [
        "def Precision_macro_weighted(conf_matrix,test_samples):\n",
        "    accum =0\n",
        "    label_wise_precision = dict()\n",
        "    for label in [0,1,2]:\n",
        "        true_sample = [sample for sample in test_samples if sample==label ]\n",
        "        if (get_TP(conf_matrix,label)+get_FP(conf_matrix,label))!=0:\n",
        "            accum+= float(len(true_sample)) *(get_TP(conf_matrix,label)/(get_TP(conf_matrix,label)+get_FP(conf_matrix,label)))\n",
        "            label_wise_precision[label] = get_TP(conf_matrix,label)/(get_TP(conf_matrix,label)+get_FP(conf_matrix,label))\n",
        "\n",
        "    \n",
        "    precision =  accum/len(test_samples)\n",
        "            \n",
        "    return precision\n",
        "\n",
        "\n",
        "def Recall_macro_weighted(conf_matrix,test_samples):\n",
        "    accum =0\n",
        "    label_wise_recall = dict()\n",
        "    for label in [0,1,2]:\n",
        "        true_sample = [sample for sample in test_samples if sample==label ]\n",
        "\n",
        "        if (get_TP(conf_matrix,label)+get_FN(conf_matrix,label))!=0:\n",
        "            accum+= float(len(true_sample)) * (get_TP(conf_matrix,label)/(get_TP(conf_matrix,label)+get_FN(conf_matrix,label)))\n",
        "            label_wise_recall[label] = get_TP(conf_matrix,label)/(get_TP(conf_matrix,label)+get_FN(conf_matrix,label))\n",
        "\n",
        "    \n",
        "    recall =  accum/len(test_samples)\n",
        "    return recall\n",
        "def print_weighted_metrics(predictions,test_labels):\n",
        "    conf_matrix = get_confusion_matrix(predictions,test_labels)\n",
        "    precision = Precision_macro_weighted(conf_matrix,test_labels)\n",
        "    recall = Recall_macro_weighted(conf_matrix,test_labels)\n",
        "    f1_score = F1(precision,recall)\n",
        "    print(\"Macro : Precision:{}, Recall: {}, F1: {}\".format(precision,recall,f1_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbe2BbA4E20b",
        "outputId": "dbf0f26f-510f-4e0d-fbff-116ec8abbb3b"
      },
      "source": [
        "#difficuty macro\n",
        "print_metrics(flat_predictions,flat_true_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro : Precision:0.641579548923942, Recall: 0.6413318391305072, F1: 0.641455670112813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNp29QbiA1B8",
        "outputId": "e2896b38-889e-4df5-fab0-6dc3f5636b77"
      },
      "source": [
        "#difficulty\n",
        "print_weighted_metrics(flat_predictions,flat_true_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro : Precision:0.6672877902080783, Recall: 0.652046783625731, F1: 0.6595792545533745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hNCTTaiK9NU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a11bc6e-aa0b-406f-82d9-9eded7ed6535"
      },
      "source": [
        "#skill name\n",
        "print_metrics(flat_skill_predictions,flat_true_skill_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro : Precision:0.44999771470359706, Recall: 0.423681636020745, F1: 0.4364433423158034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PN7dldMoEMq0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ec979f5-c194-4cd2-9cf3-e97be70171b0"
      },
      "source": [
        "#skill name\n",
        "print_weighted_metrics(flat_skill_predictions,flat_true_skill_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro : Precision:0.8250412489318578, Recall: 0.8245614035087719, F1: 0.824801256430287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbxR7mbxBCBP"
      },
      "source": [
        "def accuracy_per_class(preds_flat, labels_flat):\n",
        "\n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {get_labels(label)}')\n",
        "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXoacYx9BD_v",
        "outputId": "d2fa2bee-e73a-4663-8aa1-3c2e55a1f30d"
      },
      "source": [
        "accuracy_per_class(flat_predictions,flat_true_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class: Difficult\n",
            "Accuracy: 106/134\n",
            "\n",
            "Class: Easy\n",
            "Accuracy: 50/85\n",
            "\n",
            "Class: Medium\n",
            "Accuracy: 67/123\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DaR_83RQ9Fp",
        "outputId": "8841a43d-581a-4c58-e649-63a32ed04d48"
      },
      "source": [
        "accuracy_per_class(flat_skill_predictions,flat_true_skill_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class: Analysing\n",
            "Accuracy: 125/404\n",
            "\n",
            "Class: Applying\n",
            "Accuracy: 150/602\n",
            "\n",
            "Class: Knowledge & understanding\n",
            "Accuracy: 613/933\n",
            "\n",
            "Class: Remembering\n",
            "Accuracy: 831/1356\n",
            "\n",
            "Class: Understanding\n",
            "Accuracy: 557/1282\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu6lbpuxxbxk"
      },
      "source": [
        "!cp -r /content/model_bert_multi_task_interactive_pre_trained_skill_bert.zip \"/content/drive/My Drive/research_skill_name_prediction/\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv242vUH68jm"
      },
      "source": [
        "!cp -r \"/content/drive/My Drive/research_skill_name_prediction/model_bert_multi_task_prediction.zip\" /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNaswzbJ7EOw",
        "outputId": "33fcba65-ff87-4bc7-88e8-1890bb03b6d8"
      },
      "source": [
        "!unzip model_bert_multi_task_prediction.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  model_bert_multi_task_prediction.zip\n",
            "   creating: model_bert_multi_task_prediction/\n",
            "  inflating: model_bert_multi_task_prediction/model_weights  \n",
            "  inflating: model_bert_multi_task_prediction/tokenizer_config.json  \n",
            "  inflating: model_bert_multi_task_prediction/special_tokens_map.json  \n",
            "  inflating: model_bert_multi_task_prediction/vocab.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSK1y-sQ8UAq"
      },
      "source": [
        "!cp -r /content/model_bert_multi_task_interactive_pre_trained_skill_bert \"/content/drive/My Drive/research_skill_name_prediction/\" "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}