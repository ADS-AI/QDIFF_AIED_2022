{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "skill_prediction__models_interactive_attention_vs_multi_task_stat_significance.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b4fefdd3feef4d9da28b750c9362ab02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_78338e8fdaf54b1da04005560027cec4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e53ca12e910a4e24b655ab5ac3d9e728",
              "IPY_MODEL_c7e746b726644268afc422b46c48533f",
              "IPY_MODEL_cedc65dad28d4c538269cb06b6ebb345"
            ]
          }
        },
        "78338e8fdaf54b1da04005560027cec4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e53ca12e910a4e24b655ab5ac3d9e728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_68874f9adb65444bbd8c33edc210e10b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8904917c076a4b6f9e815bb708529bbc"
          }
        },
        "c7e746b726644268afc422b46c48533f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fd70cdfd88ef4290bf1e11bcf105e3f3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c00f6a14c8e9413b82adbbdeb4368acb"
          }
        },
        "cedc65dad28d4c538269cb06b6ebb345": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e9379d247d9a4cd4a66762cfd6b882fb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.81MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d5146e35db0e41c88e6acb431cf429ef"
          }
        },
        "68874f9adb65444bbd8c33edc210e10b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8904917c076a4b6f9e815bb708529bbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fd70cdfd88ef4290bf1e11bcf105e3f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c00f6a14c8e9413b82adbbdeb4368acb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9379d247d9a4cd4a66762cfd6b882fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d5146e35db0e41c88e6acb431cf429ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e16d85e49b73429c82550e5562b95eb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_df3d2ab35868498bbae512db1f0f5f44",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_25d27ef2a6d14c299496ec86dc9f31bc",
              "IPY_MODEL_e9558975644c422382a0aed781e035c6",
              "IPY_MODEL_c0791b6a8fd447ada78584da000c25a7"
            ]
          }
        },
        "df3d2ab35868498bbae512db1f0f5f44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25d27ef2a6d14c299496ec86dc9f31bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d1843a669c6c442da707a946fa74fac5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f54b0e1d0e149308f1503c2bad3d7db"
          }
        },
        "e9558975644c422382a0aed781e035c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bde97c71bea54474adb0fb4143512cee",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a4ee5a1b95214e098ccb46e1be83b6a7"
          }
        },
        "c0791b6a8fd447ada78584da000c25a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_eb4e5c99bdcf4542a219e6d81a7bc276",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 8.32kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9a109cd521644699a1b0db5fbd0543f3"
          }
        },
        "d1843a669c6c442da707a946fa74fac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f54b0e1d0e149308f1503c2bad3d7db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bde97c71bea54474adb0fb4143512cee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a4ee5a1b95214e098ccb46e1be83b6a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eb4e5c99bdcf4542a219e6d81a7bc276": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9a109cd521644699a1b0db5fbd0543f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3109d2e2f8854aa4806a402440131b47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bdb233fdb48a4535975dca9350196890",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0dcf9426666c40d28b0a95f78560975b",
              "IPY_MODEL_7a21a23b3d564475acf6d4c08533ab72",
              "IPY_MODEL_d8aaf31477144a2ca9294e1794feaedd"
            ]
          }
        },
        "bdb233fdb48a4535975dca9350196890": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0dcf9426666c40d28b0a95f78560975b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c1f49f30560f46efaaecfa286324df63",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_33d9be8d2d624ed6877803914d7b64ff"
          }
        },
        "7a21a23b3d564475acf6d4c08533ab72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3cef861b6be449ad9bf3806f663afa44",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c6d7b6319f794fa0b09f27236c29f790"
          }
        },
        "d8aaf31477144a2ca9294e1794feaedd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4ac2fbe9d2c94a96b5fc2a8b48e770ea",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:12&lt;00:00, 34.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d70887e57dd945cf97357e4e7c93fc1a"
          }
        },
        "c1f49f30560f46efaaecfa286324df63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "33d9be8d2d624ed6877803914d7b64ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3cef861b6be449ad9bf3806f663afa44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c6d7b6319f794fa0b09f27236c29f790": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ac2fbe9d2c94a96b5fc2a8b48e770ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d70887e57dd945cf97357e4e7c93fc1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR9av2JU3kf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "993c3387-6664-4221-b30d-33f785676edd"
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "import torch\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXHEZXXXIrDD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dff3fb91-8789-40fd-eab2-d2328991e415"
      },
      "source": [
        "!pip install torchtext==0.3.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.3.1\n",
            "  Downloading torchtext-0.3.1-py3-none-any.whl (62 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▎                          | 10 kB 25.1 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 20 kB 19.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 30 kB 10.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 40 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 51 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 62 kB 803 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.3.1) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.3.1) (2.23.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.3.1) (1.10.0+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.3.1) (4.62.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.3.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.3.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.3.1) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.3.1) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.3.1) (3.10.0.2)\n",
            "Installing collected packages: torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.11.0\n",
            "    Uninstalling torchtext-0.11.0:\n",
            "      Successfully uninstalled torchtext-0.11.0\n",
            "Successfully installed torchtext-0.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATfPIQGkqp_u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "352f735a-1ca3-473d-ded1-efd2ce662a76"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzKeqoCs3kgA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22d06713-d24f-46c2-f150-1aaaa6cf6154"
      },
      "source": [
        "\n",
        "!pip install transformers==3.2.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==3.2.0\n",
            "  Downloading transformers-3.2.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 21.5 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█                               | 30 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 61 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |███                             | 92 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████                        | 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 266 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 276 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 286 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 296 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 307 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 317 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 327 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 337 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 348 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 358 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 368 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 378 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 389 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 399 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 409 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 419 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 430 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 440 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 450 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 460 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 471 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 481 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 491 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 501 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 512 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 522 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 532 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 542 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 552 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 563 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 573 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 583 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 593 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 604 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 614 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 624 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 634 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 645 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 655 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 665 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 675 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 686 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 696 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 706 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 716 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 727 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 737 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 747 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 757 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 768 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 778 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 788 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 798 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 808 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 819 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 829 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 839 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 849 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 860 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 870 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 880 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 890 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 901 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 911 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 921 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 931 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 942 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 952 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 962 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 972 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 983 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 993 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (1.19.5)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 38.7 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 51.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (2019.12.20)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "  Downloading tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 31.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (3.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (4.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.2.0) (3.0.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2.0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2.0) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.2.0) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.2.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.2.0) (1.15.0)\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.47 sentencepiece-0.1.96 tokenizers-0.8.1rc2 transformers-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsADhaO93kgD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "fff3e1c8-c6ed-45ee-e420-c0b930337b5b"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "final_data = pd.read_csv(\"train_skill_name_difficulty.csv\")\n",
        "final_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-771e2293-c21d-47e7-8e8f-23ba86a1b2eb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>board_syllabus</th>\n",
              "      <th>question_answer</th>\n",
              "      <th>skill_label</th>\n",
              "      <th>difficulty_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Raj English&gt;&gt;XII&gt;&gt;Biology&gt;&gt;Domestication, Cult...</td>\n",
              "      <td>Among the following, freshwater fish is rohu ...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Maharashtra New&gt;&gt;VI&gt;&gt;General Science&gt;&gt;Sound&gt;&gt;P...</td>\n",
              "      <td>Which of the following statement is true? Sou...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ICSE OLD&gt;&gt;XI&gt;&gt;Computer Science&gt;&gt;Functions&gt;&gt;Con...</td>\n",
              "      <td>The process of using multiple constructors wi...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CBSE&gt;&gt;VI&gt;&gt;Science&gt;&gt;Separation of Substances&gt;&gt;S...</td>\n",
              "      <td>Sieving is based on the difference in the siz...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AP&gt;&gt;X&gt;&gt;Biology&gt;&gt;Excretion - The Wastage Dispos...</td>\n",
              "      <td>The removal of toxic and unwanted waste subst...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39124</th>\n",
              "      <td>CAPS(South Africa)&gt;&gt;Grade 7&gt;&gt;Natural Sciences&gt;...</td>\n",
              "      <td>How heat loss problems are prevented by birds...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39125</th>\n",
              "      <td>CBSE&gt;&gt;X&gt;&gt;Science&gt;&gt;Metals and Non-Metal</td>\n",
              "      <td>Give reasons why copper is used to make hot w...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39126</th>\n",
              "      <td>CBSE&gt;&gt;VII&gt;&gt;Science&gt;&gt;Motion and Time</td>\n",
              "      <td>The horizontal line in the graph is denoted as...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39127</th>\n",
              "      <td>Tamil Nadu&gt;&gt;VI&gt;&gt;Science&gt;&gt;Term 1&gt;&gt;Physics&gt;&gt;Forc...</td>\n",
              "      <td>SI unit of force is newton The SI unit of for...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39128</th>\n",
              "      <td>Tamil Nadu&gt;&gt;VIII&gt;&gt;Science&gt;&gt;Term 1&gt;&gt;Physics&gt;&gt;Fo...</td>\n",
              "      <td>In machines sliding frictions is replaced to ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39129 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-771e2293-c21d-47e7-8e8f-23ba86a1b2eb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-771e2293-c21d-47e7-8e8f-23ba86a1b2eb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-771e2293-c21d-47e7-8e8f-23ba86a1b2eb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                          board_syllabus  ... difficulty_label\n",
              "0      Raj English>>XII>>Biology>>Domestication, Cult...  ...                0\n",
              "1      Maharashtra New>>VI>>General Science>>Sound>>P...  ...                2\n",
              "2      ICSE OLD>>XI>>Computer Science>>Functions>>Con...  ...                0\n",
              "3      CBSE>>VI>>Science>>Separation of Substances>>S...  ...                1\n",
              "4      AP>>X>>Biology>>Excretion - The Wastage Dispos...  ...                1\n",
              "...                                                  ...  ...              ...\n",
              "39124  CAPS(South Africa)>>Grade 7>>Natural Sciences>...  ...                1\n",
              "39125             CBSE>>X>>Science>>Metals and Non-Metal  ...                2\n",
              "39126                CBSE>>VII>>Science>>Motion and Time  ...                1\n",
              "39127  Tamil Nadu>>VI>>Science>>Term 1>>Physics>>Forc...  ...                2\n",
              "39128  Tamil Nadu>>VIII>>Science>>Term 1>>Physics>>Fo...  ...                1\n",
              "\n",
              "[39129 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0Ja4jiFhmdg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d3a6188-7582-47fd-ee25-49ae1bee1bc3"
      },
      "source": [
        "final_data[\"question_answer\"].values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' Among the following, freshwater fish is rohu Rohu is a fresh water fish. Other common freshwater fish are catla, common carp.',\n",
              "       ' Which of the following statement is true? Sound requires a medium for propagation. Sound travels through a medium (solid, liquid or gas). It cannot travel through vacuum.',\n",
              "       ' The process of using multiple constructors with the same name but with different parameters is known as: Constructor overloading Constructor overloading is a technique in Java in which a class can have any number of constructors that differ in parameter lists.',\n",
              "       ...,\n",
              "       'The horizontal line in the graph is denoted as the X-axis. The horizontal line points in the horizontal direction and is denoted as the X-axis in the graph.',\n",
              "       ' SI unit of force is newton The SI unit of force is Newton (N), named after famous scientist Isaac Newton who discovered force of gravitation.',\n",
              "       ' In machines sliding frictions is replaced to rolling by use of ball bearings Ball bearing roll to produce rolling;friction.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQhO6qqt6lge",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4d0ee59-1680-4209-d309-05157b0b5384"
      },
      "source": [
        "final_data['skill_label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    11376\n",
              "4    10707\n",
              "2     8619\n",
              "1     4997\n",
              "0     3430\n",
              "Name: skill_label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMBf0kH7TOyd"
      },
      "source": [
        "!cp \"/content/drive/My Drive/research_skill_name_prediction/label_encoder_skill_lstm\"  /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/My Drive/research_skill_name_prediction/label_encoder_difficulty_Lstm\"  /content"
      ],
      "metadata": {
        "id": "5DvYyS_vTZ3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlpZo0VvTSMb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeb65392-a8ed-4adc-e477-4e32d0b3335f"
      },
      "source": [
        "import joblib\n",
        "LE_skill = joblib.load(\"label_encoder_skill_lstm\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OBarOLBz2nO"
      },
      "source": [
        "def get_labels(prediction):\n",
        "    predicted_label =  LE.inverse_transform([prediction])\n",
        "    return predicted_label[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqWem79lbn1J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "ff2b3a85-41a6-4a39-a0f2-b3129d951f57"
      },
      "source": [
        "final_data['difficulty_label'].value_counts().sort_values(ascending=False).plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd3e60fef10>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxliBQEJ9eTG"
      },
      "source": [
        "val = pd.read_csv(\"val_skill_name_difficulty.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07eBaI9wA2hL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "8ea44c25-6d40-412f-80d9-5fe01a348ebb"
      },
      "source": [
        "val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0ca18a8d-e3d0-4d08-95a8-36d0625bb3d7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>board_syllabus</th>\n",
              "      <th>question_answer</th>\n",
              "      <th>skill_label</th>\n",
              "      <th>difficulty_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AP&gt;&gt;VII&gt;&gt;Science&gt;&gt;Animal Fibre&gt;&gt;Silk</td>\n",
              "      <td>Name the two types of protein from which silk...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Maharashtra New&gt;&gt;VIII&gt;&gt;General Science&gt;&gt;Man Ma...</td>\n",
              "      <td>Give reasons: (i) Thermocol is used for the p...</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CBSE&gt;&gt;VI&gt;&gt;Science&gt;&gt;Fun with Magnets&gt;&gt;Demagneti...</td>\n",
              "      <td>Identify the odd option. Rubbing a magnetic m...</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tamil Nadu&gt;&gt;VIII&gt;&gt;Science&gt;&gt;Term 1&gt;&gt;Physics&gt;&gt;Li...</td>\n",
              "      <td>Find the speed of light in glass of refractiv...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Raj English&gt;&gt;XII&gt;&gt;Biology&gt;&gt;Integumentary Syste...</td>\n",
              "      <td>Which of the following function is associated...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2055</th>\n",
              "      <td>CBSE&gt;&gt;XI&gt;&gt;Chemistry&gt;&gt;Chemistry : Part I&gt;&gt;Equil...</td>\n",
              "      <td>The solubility of A 2 X 3 is y mol.dm -3 . So...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2056</th>\n",
              "      <td>CBSE&gt;&gt;VI&gt;&gt;Computer Science&gt;&gt;Using Mail Merge&gt;&gt;...</td>\n",
              "      <td>To create an invitation letter, click on Mail...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2057</th>\n",
              "      <td>CBSE&gt;&gt;XII&gt;&gt;Physics&gt;&gt;Physics : Part - II&gt;&gt;Ray O...</td>\n",
              "      <td>Choose the correct option about the intensity...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2058</th>\n",
              "      <td>ICSE OLD&gt;&gt;VII&gt;&gt;Biology&gt;&gt;Organ System of Human ...</td>\n",
              "      <td>Which of the following instrument is used to ...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2059</th>\n",
              "      <td>CBSE&gt;&gt;X&gt;&gt;Science&gt;&gt;Carbon and its Compounds&gt;&gt;Al...</td>\n",
              "      <td>Identify the correct statement about allotrop...</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2060 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ca18a8d-e3d0-4d08-95a8-36d0625bb3d7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0ca18a8d-e3d0-4d08-95a8-36d0625bb3d7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0ca18a8d-e3d0-4d08-95a8-36d0625bb3d7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                         board_syllabus  ... difficulty_label\n",
              "0                  AP>>VII>>Science>>Animal Fibre>>Silk  ...                0\n",
              "1     Maharashtra New>>VIII>>General Science>>Man Ma...  ...                2\n",
              "2     CBSE>>VI>>Science>>Fun with Magnets>>Demagneti...  ...                2\n",
              "3     Tamil Nadu>>VIII>>Science>>Term 1>>Physics>>Li...  ...                0\n",
              "4     Raj English>>XII>>Biology>>Integumentary Syste...  ...                0\n",
              "...                                                 ...  ...              ...\n",
              "2055  CBSE>>XI>>Chemistry>>Chemistry : Part I>>Equil...  ...                0\n",
              "2056  CBSE>>VI>>Computer Science>>Using Mail Merge>>...  ...                1\n",
              "2057  CBSE>>XII>>Physics>>Physics : Part - II>>Ray O...  ...                0\n",
              "2058  ICSE OLD>>VII>>Biology>>Organ System of Human ...  ...                1\n",
              "2059  CBSE>>X>>Science>>Carbon and its Compounds>>Al...  ...                0\n",
              "\n",
              "[2060 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8tVsjiWj-cF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "d7d8c34f-adfb-45e1-de3e-367682d59773"
      },
      "source": [
        "test = pd.read_csv(\"test_skill_name_difficulty.csv\")\n",
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a3d4ec2d-b896-4613-8bd8-35c4bdaaa29c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>board_syllabus</th>\n",
              "      <th>question_answer</th>\n",
              "      <th>skill_label</th>\n",
              "      <th>difficulty_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CBSE&gt;&gt;Nursery&gt;&gt;Environmental Science&gt;&gt;Common V...</td>\n",
              "      <td>Write down the names of some common vegetable...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CBSE&gt;&gt;XII&gt;&gt;Physics&gt;&gt;Physics : Part - II&gt;&gt;Atoms</td>\n",
              "      <td>Name the series of hydrogen atom which lies i...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ICSE OLD&gt;&gt;XI&gt;&gt;Political Science&gt;&gt;State, Govern...</td>\n",
              "      <td>Which of the following is not the element of ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Maharashtra New&gt;&gt;VII&gt;&gt;General Science&gt;&gt;Static ...</td>\n",
              "      <td>The process of electrically charging an objec...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tamil Nadu&gt;&gt;IX&gt;&gt;Science&gt;&gt;Physics&gt;&gt;Measurement&gt;...</td>\n",
              "      <td>The mass of an object is measured in kilogram...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4572</th>\n",
              "      <td>ICSE OLD&gt;&gt;VIII&gt;&gt;Biology&gt;&gt;Nervous System And Se...</td>\n",
              "      <td>Which of the following is the first cranial n...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4573</th>\n",
              "      <td>CBSE&gt;&gt;VII&gt;&gt;Computer Science&gt;&gt;Advance features ...</td>\n",
              "      <td>To ungroup the worksheets: Right-click on any...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4574</th>\n",
              "      <td>CBSE&gt;&gt;VIII&gt;&gt;Science&gt;&gt;Chemical Effects of Elect...</td>\n",
              "      <td>After passing electricity through a solution ...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4575</th>\n",
              "      <td>CLSP&gt;&gt;Stage 9&gt;&gt;Science&gt;&gt;Chemistry&gt;&gt;Material pr...</td>\n",
              "      <td>Identify the scientists who gave the “plum-pu...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4576</th>\n",
              "      <td>AP&gt;&gt;VIII&gt;&gt;Physical Science&gt;&gt;Physical Science (...</td>\n",
              "      <td>What do you understand by the term static ele...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4577 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3d4ec2d-b896-4613-8bd8-35c4bdaaa29c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a3d4ec2d-b896-4613-8bd8-35c4bdaaa29c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a3d4ec2d-b896-4613-8bd8-35c4bdaaa29c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                         board_syllabus  ... difficulty_label\n",
              "0     CBSE>>Nursery>>Environmental Science>>Common V...  ...                2\n",
              "1        CBSE>>XII>>Physics>>Physics : Part - II>>Atoms  ...                1\n",
              "2     ICSE OLD>>XI>>Political Science>>State, Govern...  ...                0\n",
              "3     Maharashtra New>>VII>>General Science>>Static ...  ...                1\n",
              "4     Tamil Nadu>>IX>>Science>>Physics>>Measurement>...  ...                1\n",
              "...                                                 ...  ...              ...\n",
              "4572  ICSE OLD>>VIII>>Biology>>Nervous System And Se...  ...                1\n",
              "4573  CBSE>>VII>>Computer Science>>Advance features ...  ...                0\n",
              "4574  CBSE>>VIII>>Science>>Chemical Effects of Elect...  ...                2\n",
              "4575  CLSP>>Stage 9>>Science>>Chemistry>>Material pr...  ...                0\n",
              "4576  AP>>VIII>>Physical Science>>Physical Science (...  ...                1\n",
              "\n",
              "[4577 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIrS5sxE3kgk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "b4fefdd3feef4d9da28b750c9362ab02",
            "78338e8fdaf54b1da04005560027cec4",
            "e53ca12e910a4e24b655ab5ac3d9e728",
            "c7e746b726644268afc422b46c48533f",
            "cedc65dad28d4c538269cb06b6ebb345",
            "68874f9adb65444bbd8c33edc210e10b",
            "8904917c076a4b6f9e815bb708529bbc",
            "fd70cdfd88ef4290bf1e11bcf105e3f3",
            "c00f6a14c8e9413b82adbbdeb4368acb",
            "e9379d247d9a4cd4a66762cfd6b882fb",
            "d5146e35db0e41c88e6acb431cf429ef"
          ]
        },
        "outputId": "1a8121d4-a505-43ab-d2e3-daa434972ef8"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4fefdd3feef4d9da28b750c9362ab02",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp64MkNB3kg1"
      },
      "source": [
        "\n",
        "def get_labels(prediction):\n",
        "    predicted_label =  LE.inverse_transform([prediction])\n",
        "    return predicted_label[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPgTmJPS3kg4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "e645275e-2f7d-4def-a28e-a1696529c2e0"
      },
      "source": [
        "import joblib\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "LE = LabelEncoder()\n",
        "LE = joblib.load('label_encoder_difficulty_Lstm')\n",
        "\n",
        "get_labels(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Difficult'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_UpqLMG3kg9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "0d920dee-d2ac-4151-c355-194bfba61525"
      },
      "source": [
        "final_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a0b5a6d4-66a4-41dd-b33b-9237d2fe7f3f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>board_syllabus</th>\n",
              "      <th>question_answer</th>\n",
              "      <th>skill_label</th>\n",
              "      <th>difficulty_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Raj English&gt;&gt;XII&gt;&gt;Biology&gt;&gt;Domestication, Cult...</td>\n",
              "      <td>Among the following, freshwater fish is rohu ...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Maharashtra New&gt;&gt;VI&gt;&gt;General Science&gt;&gt;Sound&gt;&gt;P...</td>\n",
              "      <td>Which of the following statement is true? Sou...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ICSE OLD&gt;&gt;XI&gt;&gt;Computer Science&gt;&gt;Functions&gt;&gt;Con...</td>\n",
              "      <td>The process of using multiple constructors wi...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CBSE&gt;&gt;VI&gt;&gt;Science&gt;&gt;Separation of Substances&gt;&gt;S...</td>\n",
              "      <td>Sieving is based on the difference in the siz...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AP&gt;&gt;X&gt;&gt;Biology&gt;&gt;Excretion - The Wastage Dispos...</td>\n",
              "      <td>The removal of toxic and unwanted waste subst...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39124</th>\n",
              "      <td>CAPS(South Africa)&gt;&gt;Grade 7&gt;&gt;Natural Sciences&gt;...</td>\n",
              "      <td>How heat loss problems are prevented by birds...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39125</th>\n",
              "      <td>CBSE&gt;&gt;X&gt;&gt;Science&gt;&gt;Metals and Non-Metal</td>\n",
              "      <td>Give reasons why copper is used to make hot w...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39126</th>\n",
              "      <td>CBSE&gt;&gt;VII&gt;&gt;Science&gt;&gt;Motion and Time</td>\n",
              "      <td>The horizontal line in the graph is denoted as...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39127</th>\n",
              "      <td>Tamil Nadu&gt;&gt;VI&gt;&gt;Science&gt;&gt;Term 1&gt;&gt;Physics&gt;&gt;Forc...</td>\n",
              "      <td>SI unit of force is newton The SI unit of for...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39128</th>\n",
              "      <td>Tamil Nadu&gt;&gt;VIII&gt;&gt;Science&gt;&gt;Term 1&gt;&gt;Physics&gt;&gt;Fo...</td>\n",
              "      <td>In machines sliding frictions is replaced to ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39129 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0b5a6d4-66a4-41dd-b33b-9237d2fe7f3f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a0b5a6d4-66a4-41dd-b33b-9237d2fe7f3f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a0b5a6d4-66a4-41dd-b33b-9237d2fe7f3f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                          board_syllabus  ... difficulty_label\n",
              "0      Raj English>>XII>>Biology>>Domestication, Cult...  ...                0\n",
              "1      Maharashtra New>>VI>>General Science>>Sound>>P...  ...                2\n",
              "2      ICSE OLD>>XI>>Computer Science>>Functions>>Con...  ...                0\n",
              "3      CBSE>>VI>>Science>>Separation of Substances>>S...  ...                1\n",
              "4      AP>>X>>Biology>>Excretion - The Wastage Dispos...  ...                1\n",
              "...                                                  ...  ...              ...\n",
              "39124  CAPS(South Africa)>>Grade 7>>Natural Sciences>...  ...                1\n",
              "39125             CBSE>>X>>Science>>Metals and Non-Metal  ...                2\n",
              "39126                CBSE>>VII>>Science>>Motion and Time  ...                1\n",
              "39127  Tamil Nadu>>VI>>Science>>Term 1>>Physics>>Forc...  ...                2\n",
              "39128  Tamil Nadu>>VIII>>Science>>Term 1>>Physics>>Fo...  ...                1\n",
              "\n",
              "[39129 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHdVe13Fr3vt"
      },
      "source": [
        "new_data = final_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkyM7gqv3khI"
      },
      "source": [
        "question_answer = new_data[\"question_answer\"].values\n",
        "categories = new_data[\"difficulty_label\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ndpw0p1SBUoZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e614ba9f-1b67-43d9-e7c8-69de780fac4a"
      },
      "source": [
        "question_answer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' Among the following, freshwater fish is rohu Rohu is a fresh water fish. Other common freshwater fish are catla, common carp.',\n",
              "       ' Which of the following statement is true? Sound requires a medium for propagation. Sound travels through a medium (solid, liquid or gas). It cannot travel through vacuum.',\n",
              "       ' The process of using multiple constructors with the same name but with different parameters is known as: Constructor overloading Constructor overloading is a technique in Java in which a class can have any number of constructors that differ in parameter lists.',\n",
              "       ...,\n",
              "       'The horizontal line in the graph is denoted as the X-axis. The horizontal line points in the horizontal direction and is denoted as the X-axis in the graph.',\n",
              "       ' SI unit of force is newton The SI unit of force is Newton (N), named after famous scientist Isaac Newton who discovered force of gravitation.',\n",
              "       ' In machines sliding frictions is replaced to rolling by use of ball bearings Ball bearing roll to produce rolling;friction.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFkS_H_83khL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "09299e6c-ef85-4385-cf2f-df366adaf04b"
      },
      "source": [
        "question_answer[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' Among the following, freshwater fish is rohu Rohu is a fresh water fish. Other common freshwater fish are catla, common carp.'"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ian7gSDE3khR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "651abfda-4a84-4875-ad2e-33373582c042"
      },
      "source": [
        "len(categories)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39129"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_ZeuHc63khU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "add00f8a-ddbf-4e01-9369-08431b251a31"
      },
      "source": [
        "import torch\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in question_answer:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', question_answer[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:   Among the following, freshwater fish is rohu Rohu is a fresh water fish. Other common freshwater fish are catla, common carp.\n",
            "Token IDs: tensor([  101,  2426,  1996,  2206,  1010, 12573,  3869,  2003, 20996,  6979,\n",
            "        20996,  6979,  2003,  1037,  4840,  2300,  3869,  1012,  2060,  2691,\n",
            "        12573,  3869,  2024,  4937,  2721,  1010,  2691, 29267,  1012,   102,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVGvVZb13kha",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f9bbf3f-c7d2-4f9c-8d86-f20f10aa5aeb"
      },
      "source": [
        "print('Original: ', len(question_answer[1]))\n",
        "print('Token IDs:', len(input_ids[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  171\n",
            "Token IDs: 128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nmRiaBbA9OH"
      },
      "source": [
        "val_text = val[\"question_answer\"].values\n",
        "val_labels = val[\"difficulty_label\"].values\n",
        "test_text = test[\"question_answer\"].values\n",
        "test_labels = test[\"difficulty_label\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-s_H1WdyvCw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7ee55b4-33cb-4422-973b-39d65700b89e"
      },
      "source": [
        "test_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 0, ..., 2, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF-mKCC1CUjD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de5f0998-c7ff-4162-8463-fcd3fa2d909f"
      },
      "source": [
        "val_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 2, ..., 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOQuDahhAzOO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbd5caca-d6e7-48b1-e8a7-e0e640c800dd"
      },
      "source": [
        "val_input_ids = []\n",
        "val_attention_masks = []\n",
        "\n",
        "for sent in val_text:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    val_input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    val_attention_masks.append(encoded_dict['attention_mask'])\n",
        "# Convert the lists into tensors.\n",
        "val_input_ids = torch.cat(val_input_ids, dim=0)\n",
        "val_attention_masks = torch.cat(val_attention_masks, dim=0)\n",
        "\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', val_text[0])\n",
        "print('Token IDs:', val_attention_masks[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:   Name the two types of protein from which silk is made. Sericin and fibroin \n",
            "Token IDs: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Siskea7qDLUG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0eaab05-9d30-4371-f8f2-85eee5760b67"
      },
      "source": [
        "print('Original: ', val_text[1])\n",
        "print('Token IDs:', val_input_ids[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:   Give reasons: (i) Thermocol is used for the packing of delicate items. (ii) Name two diseases that may develop in people working in thermocol industries. (i) Thermocol is a good shock-absorber, therefore, it is used for packing of delicate items. (ii) People working in thermocol industries may suffer from blood cancer such as leukemia and lymphoma or have problems in eyes and respiratory system. \n",
            "Token IDs: tensor([  101,  2507,  4436,  1024,  1006,  1045,  1007,  1996, 10867, 24163,\n",
            "         2140,  2003,  2109,  2005,  1996, 14743,  1997, 10059,  5167,  1012,\n",
            "         1006,  2462,  1007,  2171,  2048,  7870,  2008,  2089,  4503,  1999,\n",
            "         2111,  2551,  1999,  1996, 10867, 24163,  2140,  6088,  1012,  1006,\n",
            "         1045,  1007,  1996, 10867, 24163,  2140,  2003,  1037,  2204,  5213,\n",
            "         1011, 16888,  2121,  1010,  3568,  1010,  2009,  2003,  2109,  2005,\n",
            "        14743,  1997, 10059,  5167,  1012,  1006,  2462,  1007,  2111,  2551,\n",
            "         1999,  1996, 10867, 24163,  2140,  6088,  2089,  9015,  2013,  2668,\n",
            "         4456,  2107,  2004, 25468,  1998,  1048, 24335,  8458,  9626,  2030,\n",
            "         2031,  3471,  1999,  2159,  1998, 16464,  2291,  1012,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irMTimjf3khd"
      },
      "source": [
        "labels = torch.tensor(categories)\n",
        "val_labels = torch.tensor(val_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdOgWP_LKTHi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a9f1785-1f61-4d9a-f172-f93c3f1c171f"
      },
      "source": [
        "val_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 2, 2,  ..., 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJJ0I8Ud3khf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cdba5d94-b8ed-4ee6-e3f6-26d09960d52f"
      },
      "source": [
        "get_labels(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Easy'"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1ZAbQRfiG63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2bd63e5-d2af-4d3a-f91f-970e65fcd8af"
      },
      "source": [
        "len(set(final_data[\"question_answer\"].values).intersection(val[\"question_answer\"].values))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNDW74Ny3khj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04a5b5dd-f288-48a3-e805-fd57f9f71d3c"
      },
      "source": [
        "num_classes = len(list(set(categories)))\n",
        "list(set(categories))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmaLk5Ab3khl"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "# train_poincare_tensor = torch.tensor(poincare_embeddings_final,dtype=torch.float)\n",
        "# difficulty_tensor = torch.tensor(difficulty_level_vectors,dtype=torch.float)\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "val_dataset = TensorDataset(val_input_ids, val_attention_masks,val_labels) \n",
        "# Create a 90-10train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "# train_size = int(0.90 * len(dataset))\n",
        "# val_size = len(dataset) - train_size\n",
        "\n",
        "# # Divide the dataset by randomly selecting samples.\n",
        "# train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# print('{:>5,} training samples'.format(train_size))\n",
        "# # print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_lTinod3kho"
      },
      "source": [
        "\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size = 34\n",
        "train_dataloader = DataLoader(\n",
        "            dataset,  # The training samples.\n",
        "            sampler = RandomSampler(dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), \n",
        "            batch_size = batch_size \n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2tmAMlw3khr"
      },
      "source": [
        "from transformers import BertModel, AdamW, BertConfig\n",
        "\n",
        "# # Loads BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# model = BertModel.from_pretrained(\n",
        "#     \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "# )\n",
        "\n",
        "# # Tell pytorch to run this model on the GPU.\n",
        "# model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkDmTZhVChN6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4c1f2fd-a5d7-4597-a9ab-3bac39827f60"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "set(test[\"question_answer\"].values).intersection(set(final_data[\"question_answer\"].values))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJ9iUjJiHI7k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4275dbab-05bc-4aa8-d293-4cbd28f3bfcd"
      },
      "source": [
        "!unzip \"/content/drive/MyDrive/research_skill_name_prediction/model_bert_multi_task_interactive_final.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/research_skill_name_prediction/model_bert_multi_task_interactive_final.zip\n",
            "   creating: model_bert_multi_task_interactive_final/\n",
            "  inflating: model_bert_multi_task_interactive_final/special_tokens_map.json  \n",
            " extracting: model_bert_multi_task_interactive_final/tokenizer_config.json  \n",
            "  inflating: model_bert_multi_task_interactive_final/vocab.txt  \n",
            "  inflating: model_bert_multi_task_interactive_final/model_weights  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip \"/content/drive/MyDrive/research_skill_name_prediction/model_bert_multi_task_prediction.zip\"\n",
        "!cp -r \"/content/drive/MyDrive/research_skill_name_prediction/model_bert_multi_task_prediction_final\" /content"
      ],
      "metadata": {
        "id": "V1d0rl8rINpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n"
      ],
      "metadata": {
        "id": "BzAqI9j7T7fE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g8cFpXrpo9Q"
      },
      "source": [
        "from torch import nn\n",
        "class MultiClassClassifier(nn.Module):\n",
        "    def __init__(self, bert_model_path, labels_count,skill_label_count, hidden_dim=768, mlp_dim=500, extras_dim=140, dropout=0.1, freeze_bert=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(bert_model_path,output_hidden_states=False,output_attentions=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim , mlp_dim),\n",
        "            nn.ReLU(),\n",
        "            # nn.Linear(mlp_dim, mlp_dim),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(mlp_dim, mlp_dim),\n",
        "            # nn.ReLU(),            \n",
        "            nn.Linear(mlp_dim, labels_count)\n",
        "        )\n",
        "        self.mlp2 = nn.Sequential(\n",
        "            nn.Linear(hidden_dim , mlp_dim),\n",
        "            nn.ReLU(),         \n",
        "            nn.Linear(mlp_dim, skill_label_count)\n",
        "        )\n",
        "        # self.softmax = nn.LogSoftmax(dim=1)\n",
        "        if freeze_bert:\n",
        "            print(\"Freezing layers\")\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, tokens, masks):\n",
        "        _,pooled_output = self.bert(tokens, attention_mask=masks)\n",
        "\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        concat_output = dropout_output\n",
        "        mlp_output = self.mlp(concat_output)\n",
        "        skill_output = self.mlp2(concat_output)\n",
        "        # proba = self.sigmoid(mlp_output)\n",
        "        # proba = self.softmax(mlp_output)\n",
        "\n",
        "        return mlp_output,skill_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzdVd6lUEfv8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99b9da96-f9f6-4fe4-ee48-0b9af7760ab4"
      },
      "source": [
        "num_classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kctN7UA1bhCx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e16d85e49b73429c82550e5562b95eb6",
            "df3d2ab35868498bbae512db1f0f5f44",
            "25d27ef2a6d14c299496ec86dc9f31bc",
            "e9558975644c422382a0aed781e035c6",
            "c0791b6a8fd447ada78584da000c25a7",
            "d1843a669c6c442da707a946fa74fac5",
            "1f54b0e1d0e149308f1503c2bad3d7db",
            "bde97c71bea54474adb0fb4143512cee",
            "a4ee5a1b95214e098ccb46e1be83b6a7",
            "eb4e5c99bdcf4542a219e6d81a7bc276",
            "9a109cd521644699a1b0db5fbd0543f3",
            "3109d2e2f8854aa4806a402440131b47",
            "bdb233fdb48a4535975dca9350196890",
            "0dcf9426666c40d28b0a95f78560975b",
            "7a21a23b3d564475acf6d4c08533ab72",
            "d8aaf31477144a2ca9294e1794feaedd",
            "c1f49f30560f46efaaecfa286324df63",
            "33d9be8d2d624ed6877803914d7b64ff",
            "3cef861b6be449ad9bf3806f663afa44",
            "c6d7b6319f794fa0b09f27236c29f790",
            "4ac2fbe9d2c94a96b5fc2a8b48e770ea",
            "d70887e57dd945cf97357e4e7c93fc1a"
          ]
        },
        "outputId": "7eb2b615-8630-4002-85fb-63981aeca7f0"
      },
      "source": [
        "model_multi_task = MultiClassClassifier('bert-base-uncased',3, 5,768,500,140,dropout=0.1,freeze_bert=False)\n",
        "model_multi_task.load_state_dict(torch.load('model_bert_multi_task_prediction_final/model_weights'))\n",
        "model_multi_task.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e16d85e49b73429c82550e5562b95eb6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3109d2e2f8854aa4806a402440131b47",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiClassClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (mlp): Sequential(\n",
              "    (0): Linear(in_features=768, out_features=500, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=500, out_features=3, bias=True)\n",
              "  )\n",
              "  (mlp2): Sequential(\n",
              "    (0): Linear(in_features=768, out_features=500, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=500, out_features=5, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYLxYivOFpKo"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "\n",
        "class AttentionBlock(nn.Module):\n",
        "  def __init__(self,vector_1_dim,vector_2_dim):\n",
        "    super(AttentionBlock, self).__init__()\n",
        "    self.Weights = nn.Parameter(torch.rand(vector_2_dim,vector_1_dim))\n",
        "    self.bias = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "  def forward(self,vector_1,vector_2):\n",
        "    #(batch_size,vector_2_dim,vector_1_dim)\n",
        "    weights = self.Weights.repeat(vector_2.size(0),1,1)\n",
        "    vector_1 = vector_1.unsqueeze(-1)  # (batch_size,vector_2_dim,vector_1_dim)\n",
        "    weights = weights.matmul(vector_1) # results in (batch_size,vector_2_dim,1)\n",
        "    weights = weights.repeat(vector_2.size(1),1,1,1).transpose(0,1)\n",
        "    vector_2 = vector_2.unsqueeze(-2)\n",
        "    attention_weights = torch.tanh(vector_2.matmul(weights).squeeze() + self.bias) # batch_size, vector_2_dim.size(0)\n",
        "    if len(attention_weights.shape) ==1:\n",
        "      attention_weights = attention_weights.squeeze()\n",
        "      attention_weights = attention_weights.reshape(1,-1)\n",
        "    attention_weights = attention_weights.squeeze()\n",
        "    # print(\"torch.exp(attention_weights)\",torch.exp(attention_weights).shape,attention_weights.shape,torch.exp(attention_weights).sum(dim=1).shape)\n",
        "    attention_weights = torch.exp(attention_weights)/ torch.exp(attention_weights).sum(dim=1,keepdim=True)\n",
        "\n",
        "    return attention_weights\n",
        "\n",
        "# bloom interactive attention\n",
        "class MultiClassClassifier(nn.Module):\n",
        "    def __init__(self, bert_model_path, labels_count,skill_label_count, hidden_dim=768, mlp_dim=500, extras_dim=140, dropout=0.1, freeze_bert=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(bert_model_path,output_hidden_states=True,output_attentions=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.bloom_attention = AttentionBlock(768, 768)\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim , mlp_dim),\n",
        "            nn.ReLU(),\n",
        "            # nn.Linear(mlp_dim, mlp_dim),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(mlp_dim, mlp_dim),\n",
        "            # nn.ReLU(),            \n",
        "            nn.Linear(mlp_dim, labels_count)\n",
        "        )\n",
        "        self.mlp2 = nn.Sequential(  \n",
        "            nn.Linear(hidden_dim , mlp_dim),\n",
        "            nn.ReLU(),         \n",
        "            nn.Linear(mlp_dim, skill_label_count)\n",
        "        )\n",
        "        # self.softmax = nn.LogSoftmax(dim=1)\n",
        "        if freeze_bert:\n",
        "            print(\"Freezing layers\")\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, tokens, masks):\n",
        "        _, pooled_output,hidden_states,attentions = self.bert(tokens, attention_mask=masks)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        concat_output = dropout_output\n",
        "\n",
        "        # mlp_output = self.mlp(concat_output)\n",
        "        skill_output_probas = self.mlp2(concat_output)\n",
        "        skill_output = torch.argmax(skill_output_probas,axis=1).cpu().numpy()\n",
        "        skill_output = LE_skill.inverse_transform(skill_output)\n",
        "        skill_input_ids = []\n",
        "        skill_attention_masks = []\n",
        "        for skill_text in skill_output:\n",
        "          encoded_skill_output = tokenizer.encode_plus(\n",
        "                          skill_text,                      # Sentence to encode.\n",
        "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                          max_length = 128,           # Pad & truncate all sentences.\n",
        "                          pad_to_max_length = True,\n",
        "                          truncation=True,\n",
        "                          return_attention_mask = True,   # Construct attn. masks.\n",
        "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                    )\n",
        "          skill_input_ids.append(encoded_skill_output['input_ids'])\n",
        "          skill_attention_masks.append(encoded_skill_output['attention_mask'])\n",
        "        skill_input_ids = torch.cat(skill_input_ids,dim=0).cuda()\n",
        "        skill_attention_masks = torch.cat(skill_attention_masks,dim=0).cuda()\n",
        "        _,_,hidden_states_skill,_ = self.bert(skill_input_ids,skill_attention_masks)\n",
        "\n",
        "        skill_hidden_averaged =  torch.sum(hidden_states_skill[12],dim=1)/hidden_states_skill[12].shape[1]\n",
        "\n",
        "        bloom_attention_weights = self.bloom_attention(skill_hidden_averaged, hidden_states[12])\n",
        "\n",
        "        bloom_attention_weights = bloom_attention_weights.unsqueeze(-2)\n",
        "        # print(\"context_attention_weights\",context_attention_weights.shape,context_out.shape)\n",
        "        input_attended_vector = bloom_attention_weights.matmul(hidden_states[12]).squeeze()\n",
        "\n",
        "        mlp_output = self.mlp(input_attended_vector)\n",
        "\n",
        "        # print(\"bloom attention weights\", bloom_attention_weights.shape)\n",
        "        # print(\"_hidden_states\",hidden_states_skill[12].shape, hidden_states[12].shape,skill_hidden_averaged.shape)\n",
        "\n",
        "        # proba = self.sigmoid(mlp_output)\n",
        "        # proba = self.softmax(mlp_output)\n",
        "\n",
        "        return mlp_output,skill_output_probas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xy6FOcfNRp0P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f53378bf-0114-475f-d010-eaa511294cfd"
      },
      "source": [
        "skill_label_count = len(list(set(new_data[\"skill_label\"].values)))\n",
        "skill_label_count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIbXoNcuUukV"
      },
      "source": [
        "!cp -r \"/content/drive/MyDrive/research_skill_name_prediction/model_bert_multi_task_interactive_final\" /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDaXrwL5Fut_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7628686-9712-4fbc-ccb9-388af943457f"
      },
      "source": [
        "model_interactive = MultiClassClassifier('bert-base-uncased',num_classes, skill_label_count,768,500,140,dropout=0.1,freeze_bert=False)\n",
        "model_interactive.load_state_dict(torch.load(\"model_bert_multi_task_interactive_final/model_weights\"))\n",
        "model_interactive.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiClassClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (bloom_attention): AttentionBlock()\n",
              "  (mlp): Sequential(\n",
              "    (0): Linear(in_features=768, out_features=500, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=500, out_features=3, bias=True)\n",
              "  )\n",
              "  (mlp2): Sequential(\n",
              "    (0): Linear(in_features=768, out_features=500, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=500, out_features=5, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gtKYG0VeVwk"
      },
      "source": [
        "# for param in model.bert.encoder.layer[0:12].parameters():\n",
        "#     param.requires_grad=False\n",
        "# for param in model.bert.embeddings.parameters():\n",
        "#     param.requires_grad=False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4178_yLFMWmx"
      },
      "source": [
        "test_features = test[\"question_answer\"].values\n",
        "test_labels = test[\"difficulty_label\"].values\n",
        "test_skill_labels = test[\"skill_label\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DggP9Sxdv_-l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f3fc054-10d7-4857-e4f0-e3576f2a7f75"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "test_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 0, ..., 2, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZpmBJuIC2nM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e13d3117-e023-490f-faa8-882eebf499a0"
      },
      "source": [
        "test_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' Write down the names of some common vegetables. Answer may vary Probable answer – Names of some common vegetables are potato, onion, tomato and carrot. ',\n",
              "       ' Name the series of hydrogen atom which lies in the U.V region. Lyman series lies in the U.V region. ',\n",
              "       ' Which of the following is not the element of an association? Relationships are abstract Each association has elements 1) a group of people, 2) voluntary Membership, 3) shared and common interests or needs as the basis, 4) some set of objective goals which are to be achieved collectively by all the members, 5) a voluntary organisation, and 6) co-operation among the members objectives pooled resources for funds needed for action.',\n",
              "       ...,\n",
              "       ' After passing electricity through a solution the change that takes place is a chemical change Physical changes are those changes that do not result in the production of a new substance whereas a chemical change involves the production of a new substance. For example: When electricity is passed in a solution containing water, bubbles of hydrogen and oxygen are formed.',\n",
              "       ' Identify the scientists who gave the “plum-pudding” model of the atom. J. J. Thomson The &ldquo;plum-pudding&rdquo; model of the atom was developed by the J. J Thomson. He compared his model used for describing the structure of atom with a plum pudding in which negatively charged electrons were surrounded by a positively charged &lsquo;pudding&rsquo;.',\n",
              "       ' What do you understand by the term static electricity? It is the electricity developed due to stationary electric charges on the body. '],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlOvANUwprAw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6c6ea8f7-5cb0-4e15-8c83-8d2ac8e78436"
      },
      "source": [
        "test_features[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' Write down the names of some common vegetables. Answer may vary Probable answer – Names of some common vegetables are potato, onion, tomato and carrot. '"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmmWYcW2sNHe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d01d3ae-9a7d-408b-8d4d-d86435496678"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "for sent in test_features:\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "test_skill_labels = torch.tensor(test_skill_labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 34\n",
        "\n",
        "# test_poincare_tensor = torch.tensor(poincare_embeddings_final,dtype=torch.float)\n",
        "# print(test_poincare_tensor.shape)\n",
        "# difficulty_tensor = torch.tensor(difficulty_level_vectors,dtype=torch.float)\n",
        "# print(\"difficulty_tensor\",difficulty_tensor.shape)\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, test_labels,test_skill_labels)\n",
        "# Create the DataLoader.\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX-RiYbQPDpx"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFediYEjlKjX"
      },
      "source": [
        "def get_confusion_matrix(predicted,actual):\n",
        "    conf_matrix = np.zeros((5, 5))\n",
        "    for pred,act in zip(predicted,actual):\n",
        "        conf_matrix[act,pred]+=1\n",
        "    return conf_matrix\n",
        "        \n",
        "def get_TP(confusion_matrix,label):\n",
        "    tp = confusion_matrix[label][label]\n",
        "    return tp\n",
        "\n",
        "def get_FN(confusion_matrix,label):\n",
        "    row = confusion_matrix[label,]\n",
        "    row_truepositives = row[label]\n",
        "    fn = row.sum() - row_truepositives\n",
        "    return fn\n",
        "\n",
        "def get_FP(confusion_matrix,tag):\n",
        "    col = confusion_matrix[:,tag]\n",
        "    col_tp = col[tag]\n",
        "    #  sum of all values in column except tp\n",
        "    fp = col.sum() - col_tp\n",
        "    return fp\n",
        "def Precision(conf_matrix):\n",
        "    precision = 0.0\n",
        "    for label in [0,1,2,3,4]:\n",
        "        dividor= get_TP(conf_matrix,label)+get_FP(conf_matrix,label)\n",
        "        if dividor != 0.0:\n",
        "            precision += (get_TP(conf_matrix,label))/dividor\n",
        "    return (precision / 5)\n",
        "\n",
        "def Recall(conf_matrix):\n",
        "    recall = 0.0\n",
        "    for label in [0,1,2,3,4]:\n",
        "        dividor=get_TP(conf_matrix,label)+get_FN(conf_matrix,label)\n",
        "        if dividor != 0.0:\n",
        "            recall += (get_TP(conf_matrix,label))/dividor\n",
        "    return (recall / 5)\n",
        "\n",
        "def F1(precision,recall):\n",
        "    return (2*precision*recall)/(precision+recall)\n",
        "def accuracy_per_class(preds_flat, labels_flat):\n",
        "\n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label}')\n",
        "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n",
        "def print_metrics(predictions,test_labels):\n",
        "    conf_matrix = get_confusion_matrix(predictions,test_labels)\n",
        "    precision = Precision(conf_matrix)\n",
        "    recall = Recall(conf_matrix)\n",
        "    f1_score = F1(precision,recall)\n",
        "    return (precision,recall,f1_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFEi23ejPfOm"
      },
      "source": [
        "\n",
        "def Precision_macro_weighted(conf_matrix,test_samples):\n",
        "    accum =0\n",
        "    label_wise_precision = dict()\n",
        "    for label in [0,1,2,3,4]:\n",
        "        true_sample = [sample for sample in test_samples if sample==label ]\n",
        "        if (get_TP(conf_matrix,label)+get_FP(conf_matrix,label))!=0:\n",
        "            accum+= float(len(true_sample)) *(get_TP(conf_matrix,label)/(get_TP(conf_matrix,label)+get_FP(conf_matrix,label)))\n",
        "            label_wise_precision[label] = get_TP(conf_matrix,label)/(get_TP(conf_matrix,label)+get_FP(conf_matrix,label))\n",
        "\n",
        "    \n",
        "    precision =  accum/len(test_samples)\n",
        "            \n",
        "    return precision\n",
        "\n",
        "\n",
        "def Recall_macro_weighted(conf_matrix,test_samples):\n",
        "    accum =0\n",
        "    label_wise_recall = dict()\n",
        "    for label in [0,1,2,3,4]:\n",
        "        true_sample = [sample for sample in test_samples if sample==label ]\n",
        "\n",
        "        if (get_TP(conf_matrix,label)+get_FN(conf_matrix,label))!=0:\n",
        "            accum+= float(len(true_sample)) * (get_TP(conf_matrix,label)/(get_TP(conf_matrix,label)+get_FN(conf_matrix,label)))\n",
        "            label_wise_recall[label] = get_TP(conf_matrix,label)/(get_TP(conf_matrix,label)+get_FN(conf_matrix,label))\n",
        "\n",
        "    \n",
        "    recall =  accum/len(test_samples)\n",
        "    return recall\n",
        "def print_weighted_metrics(predictions,test_labels):\n",
        "    conf_matrix = get_confusion_matrix(predictions,test_labels)\n",
        "    precision = Precision_macro_weighted(conf_matrix,test_labels)\n",
        "    recall = Recall_macro_weighted(conf_matrix,test_labels)\n",
        "    f1_score = F1(precision,recall)\n",
        "    return (precision,recall,f1_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9F7JWv8uFrL-"
      },
      "source": [
        "def make_lstm_and_gru_predictions(index, params):\n",
        "  model_lstm.eval()\n",
        "  model_gru.eval()\n",
        "  for i,batch in enumerate(test_iter):\n",
        "    outputs = []\n",
        "    if i == index:\n",
        "      # print(\"i\",i,index)\n",
        "      with torch.no_grad():\n",
        "          question, x_len = batch.text\n",
        "          x = question.cuda()\n",
        "          # outs = sigmoid(outs.cpu().data.numpy()).tolist()\n",
        "          y = batch.label.type(torch.long).cuda()\n",
        "          if params['lstm']>=0.5:\n",
        "            lstm_outputs = model_lstm(x,x_len)\n",
        "            outputs.append(lstm_outputs)\n",
        "          if params[\"gru\"]>=0.5:\n",
        "            gru_outputs = model_gru(x,x_len)\n",
        "            outputs.append(gru_outputs)\n",
        "          \n",
        "          return outputs\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBS6OmWO1DJ6"
      },
      "source": [
        "Now for comapring statistical significance between ensemble mlp and bo ensemble\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBqbaDo11IZc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "066eced3-9bec-4331-afb9-84d599d1ab1b"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=5, shuffle=True)\n",
        "kf.split(test_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object _BaseKFold.split at 0x7fd37bb7ac50>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6Fk2gObC8iw"
      },
      "source": [
        "def get_interactive_predictions(prediction_dataloader):\n",
        "  predictions=[]\n",
        "  true_labels=[]\n",
        "  for index,batch in enumerate(prediction_dataloader):\n",
        "      final_outputs = []\n",
        "      # Add batch to GPU\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      \n",
        "      # Unpack the inputs from our dataloader\n",
        "      b_input_ids, b_input_mask, b_labels, skill_labels = batch\n",
        "      # Telling the model not to compute or store gradients, saving memory and \n",
        "      # speeding up prediction\n",
        "      with torch.no_grad():\n",
        "          # Forward pass, calculate logit predictions\n",
        "            # print(\"multi\")\n",
        "          interactive_output,skill_output = model_interactive(b_input_ids,b_input_mask)\n",
        "          # final_outputs.append(interactive_output)\n",
        "      # logits_2 = outputs\n",
        "      # logist_1 = output_bert[0]\n",
        "      logits = skill_output\n",
        "      # logits = torch.mean(torch.stack(predictions_1), dim=0)\n",
        "      # else:\n",
        "        # logits = predictions_1[0]\n",
        "      # Move logits and labels to CPU\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      label_ids = skill_labels.to('cpu').numpy()\n",
        "\n",
        "      \n",
        "      # Store predictions and true labels\n",
        "      predictions.append(logits)\n",
        "      true_labels.append(label_ids)\n",
        "  flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "  flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "    # Combine the correct labels for each batch into a single list.\n",
        "  flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "  # metrics = precision_recall_fscore_support(flat_true_labels, flat_predictions, average='micro')\n",
        "  metrics = print_weighted_metrics(flat_predictions,flat_true_labels)\n",
        "  macro_metrics = print_metrics(flat_predictions,flat_true_labels)\n",
        "  return metrics[2],macro_metrics[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_multi_task_predictions(prediction_dataloader):\n",
        "  predictions=[]\n",
        "  true_labels=[]\n",
        "  for index,batch in enumerate(prediction_dataloader):\n",
        "      final_outputs = []\n",
        "      # Add batch to GPU\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      \n",
        "      # Unpack the inputs from our dataloader\n",
        "      b_input_ids, b_input_mask, b_labels, skill_labels = batch\n",
        "      # Telling the model not to compute or store gradients, saving memory and \n",
        "      # speeding up prediction\n",
        "      with torch.no_grad():\n",
        "          # Forward pass, calculate logit predictions\n",
        "            # print(\"multi\")\n",
        "          interactive_output,skill_output = model_multi_task(b_input_ids,b_input_mask)\n",
        "          # final_outputs.append(interactive_output)\n",
        "      # logits_2 = outputs\n",
        "      # logist_1 = output_bert[0]\n",
        "      logits = skill_output\n",
        "      # logits = torch.mean(torch.stack(predictions_1), dim=0)\n",
        "      # else:\n",
        "        # logits = predictions_1[0]\n",
        "      # Move logits and labels to CPU\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      label_ids = skill_labels.to('cpu').numpy()\n",
        "\n",
        "      \n",
        "      # Store predictions and true labels\n",
        "      predictions.append(logits)\n",
        "      true_labels.append(label_ids)\n",
        "  flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "  flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "    # Combine the correct labels for each batch into a single list.\n",
        "  flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "  # metrics = precision_recall_fscore_support(flat_true_labels, flat_predictions, average='micro')\n",
        "  metrics = print_weighted_metrics(flat_predictions,flat_true_labels)\n",
        "  macro_metrics = print_metrics(flat_predictions,flat_true_labels)\n",
        "  return metrics[2],macro_metrics[2]"
      ],
      "metadata": {
        "id": "NE_YHCjSKRqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QFUh7sqKv9n"
      },
      "source": [
        "test_labels = test[\"difficulty_label\"].values\n",
        "test_skill_labels = test[\"skill_label\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlXpc52FUTp1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "e75a4874-1594-4d1f-f607-41c2f71d0727"
      },
      "source": [
        "test.iloc[[2,3],:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fc6a94b4-ca07-4279-906e-9fac37d3ba05\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>board_syllabus</th>\n",
              "      <th>question_answer</th>\n",
              "      <th>skill_label</th>\n",
              "      <th>difficulty_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ICSE OLD&gt;&gt;XI&gt;&gt;Political Science&gt;&gt;State, Govern...</td>\n",
              "      <td>Which of the following is not the element of ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Maharashtra New&gt;&gt;VII&gt;&gt;General Science&gt;&gt;Static ...</td>\n",
              "      <td>The process of electrically charging an objec...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc6a94b4-ca07-4279-906e-9fac37d3ba05')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fc6a94b4-ca07-4279-906e-9fac37d3ba05 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fc6a94b4-ca07-4279-906e-9fac37d3ba05');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                      board_syllabus  ... difficulty_label\n",
              "2  ICSE OLD>>XI>>Political Science>>State, Govern...  ...                0\n",
              "3  Maharashtra New>>VII>>General Science>>Static ...  ...                1\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaozdK_RDJ0I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6807f800-3ce6-4ac4-b233-e917b0007368"
      },
      "source": [
        "for indices in kf.split(test_features):\n",
        "  print(len(indices[0]),len(indices[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3661 916\n",
            "3661 916\n",
            "3662 915\n",
            "3662 915\n",
            "3662 915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3gCmcJN2lJH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d11be6d8-6a8a-4921-b655-c7f6002dd9f3"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "f1_multi_ensemble = []\n",
        "f1_int_ensemble =[]\n",
        "macro_f1_inti_ensemble = []\n",
        "macro_f1_multi_ensemble = []\n",
        "for indices in kf.split(test_features):\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  for sent in test_features[indices[0]]:\n",
        "\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 256,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  test_labels_tensor = torch.tensor(test_labels[indices[0]])\n",
        "  test_skill_labels_tensor = torch.tensor(test_skill_labels[indices[0]])\n",
        "\n",
        "  # test_text = torchtext.data.TabularDataset(examples=test.iloc[indices[1],:],\n",
        "  #                                    fields={'difficulty_label': ('label', target_diff),\n",
        "  #                                            'question_answer': ('text',text)})\n",
        "  # test_iter = torchtext.data.Iterator(dataset=test_text, batch_size=34,train=False, sort=False, sort_within_batch=False,shuffle=False)\n",
        "# Set the batch size.  /\n",
        "  # batch_size = 34  \n",
        "\n",
        "  prediction_data = TensorDataset(input_ids, attention_masks, test_labels_tensor,test_skill_labels_tensor)\n",
        "  # Create the DataLoader.\n",
        "  prediction_sampler = SequentialSampler(prediction_data)\n",
        "  prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=32)\n",
        "  f1_bo,macro_f1_bo = get_interactive_predictions(prediction_dataloader)\n",
        "  f1_mlp,macro_f1_mlp = get_multi_task_predictions(prediction_dataloader)\n",
        "  f1_multi_ensemble.append(f1_mlp)\n",
        "  f1_int_ensemble.append(f1_bo)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2zdPrxg2WUfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66vXZkmEmukt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ad32d18-5fa2-4d4a-8885-278c11061abe"
      },
      "source": [
        "print(f1_int_ensemble)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5066994290780954, 0.5018330059044279, 0.5047516414065716, 0.5012649174396435, 0.500163852094701]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVuCIr5rmukv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1aa5af8-6557-43c2-d699-26451afb39cb"
      },
      "source": [
        "f1_multi_ensemble"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.49968921444726033,\n",
              " 0.5003590112112671,\n",
              " 0.49920685588526154,\n",
              " 0.4911688034307269,\n",
              " 0.49560711704471033]"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vts-3CwFmukw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a87c03e9-b264-433e-8437-4f5a049fc38c"
      },
      "source": [
        "from scipy import stats\n",
        "stats.ttest_rel(f1_int_ensemble,f1_multi_ensemble)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ttest_relResult(statistic=4.044807997617913, pvalue=0.015542167902253988)"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLO3BUOEKMpm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57c30443-78a0-4c45-b3ee-4e8b2a7d7c49"
      },
      "source": [
        "print(f1_int_ensemble)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5066994290780954, 0.5018330059044279, 0.5047516414065716, 0.5012649174396435, 0.500163852094701]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71jVD2AAcMPe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5b19a35-2884-4577-93ac-7d66d9d4fcb9"
      },
      "source": [
        "f1_multi_ensemble"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.49968921444726033,\n",
              " 0.5003590112112671,\n",
              " 0.49920685588526154,\n",
              " 0.4911688034307269,\n",
              " 0.49560711704471033]"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87jSlrNZJsfZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21f9ac39-01f4-49aa-e811-71d1fa915ac3"
      },
      "source": [
        "from scipy import stats\n",
        "stats.ttest_rel(f1_int_ensemble,f1_multi_ensemble)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ttest_relResult(statistic=4.044807997617913, pvalue=0.015542167902253988)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe4qYkV2C4fX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fa43b9f-7bfe-4788-d48c-c297544fa053"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "for sent in test_features:\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "test_skill_labels = torch.tensor(test_skill_labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 34\n",
        "# test_poincare_tensor = torch.tensor(poincare_embeddings_final,dtype=torch.float)\n",
        "# print(test_poincare_tensor.shape)\n",
        "# difficulty_tensor = torch.tensor(difficulty_level_vectors,dtype=torch.float)\n",
        "# print(\"difficulty_tensor\",difficulty_tensor.shape)\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, test_labels,test_skill_labels)\n",
        "# Create the DataLoader.\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPCktQT9DVT4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d68f0d09-b099-4289-d747-6f7fe7d9686d"
      },
      "source": [
        "# Prediction on test set\n",
        "# device = ''\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model_interactive.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions,skill_predictions , true_labels, true_skill_labels = [], [], [], []\n",
        "\n",
        "# Predict ea\n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels,skill_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  # print(\"b_input_ids\",b_input_ids.shape)\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs,skill_ouputs = model_interactive(b_input_ids,b_input_mask)\n",
        "\n",
        "  logits = outputs\n",
        "  skill_logits = skill_ouputs\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  skill_logits = skill_logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  skill_labels = skill_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  skill_predictions.append(skill_logits)\n",
        "  true_labels.append(label_ids)\n",
        "  true_skill_labels.append(skill_labels)\n",
        "\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 4,577 test sentences...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flat_predictions = np.concatenate(skill_predictions, axis=0)\n",
        "\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_skill_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "# mcc = matthews_corrcoef(flat_true_skill_labels, flat_skill_predictions)\n",
        "# \n",
        "# print('Total MCC: %.3f' % mcc)"
      ],
      "metadata": {
        "id": "dBaGljjsj6XF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbe2BbA4E20b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b1585a0-02b8-4c27-c8a9-d6eec506b1d1"
      },
      "source": [
        "#difficuty macro\n",
        "print_metrics(flat_predictions,flat_true_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.49691390428987053, 0.4473318465516504, 0.470821106020493)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNp29QbiA1B8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb45a65d-8351-45d4-b203-2d7fed8383fd"
      },
      "source": [
        "#difficulty\n",
        "print_weighted_metrics(flat_predictions,flat_true_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5021446160334097, 0.5064452698273979, 0.5042857738799726)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TJesN2Gm0OO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a6742b4-bddc-4749-a3a9-fb03c419eca7"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model_interactive.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions,skill_predictions , true_labels, true_skill_labels = [], [], [], []\n",
        "\n",
        "# Predict ea\n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels,skill_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  # print(\"b_input_ids\",b_input_ids.shape)\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs,skill_ouputs = model_multi_task(b_input_ids,b_input_mask)\n",
        "\n",
        "  logits = outputs\n",
        "  skill_logits = skill_ouputs\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  skill_logits = skill_logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  skill_labels = skill_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  skill_predictions.append(skill_logits)\n",
        "  true_labels.append(label_ids)\n",
        "  true_skill_labels.append(skill_labels)\n",
        "\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 4,577 test sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flat_predictions = np.concatenate(skill_predictions, axis=0)\n",
        "\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_skill_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "# mcc = matthews_corrcoef(flat_true_skill_labels, flat_skill_predictions)\n",
        "# \n",
        "# print('Total MCC: %.3f' % mcc)"
      ],
      "metadata": {
        "id": "CJT-yQtcm0OP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll6izlovm0OP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe23bb0a-fe6a-4d22-c8af-88c0e304f984"
      },
      "source": [
        "#difficuty macro\n",
        "print_metrics(flat_predictions,flat_true_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4899119674472249, 0.43949840785494443, 0.4633379084285248)"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xkrl5ZjNjgiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCtdzj5zm0OP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4fa4ccc-fdc0-4304-83ed-02110cf6e05f"
      },
      "source": [
        "#difficulty\n",
        "print_weighted_metrics(flat_predictions,flat_true_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4974388455737828, 0.4987983395237055, 0.4981176649464485)"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test_features))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdzoZCHNgQa7",
        "outputId": "ca12db88-3569-4fd8-c1ac-b99f7069b1d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_bo,f1_mlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXu2Zh14bNtO",
        "outputId": "2bcbedb1-4fa3-4770-cd86-0f83ea154858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5579003427739674, 0.5423183782002412)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDxKTJqNSnFp"
      },
      "source": [
        "Now for macro f1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9YL5hHaSmd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8a25969-6461-49dd-9d3e-2f15abd6ab97"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "f1_multi_ensemble = []\n",
        "f1_int_ensemble =[]\n",
        "macro_f1_inti_ensemble = []\n",
        "macro_f1_multi_ensemble = []\n",
        "for indices in kf.split(test_features):\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  for sent in test_features[indices[0]]:\n",
        "\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 256,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  test_labels_tensor = torch.tensor(test_labels[indices[0]])\n",
        "  test_skill_labels_tensor = torch.tensor(test_skill_labels[indices[0]])\n",
        "\n",
        "  # test_text = torchtext.data.TabularDataset(examples=test.iloc[indices[1],:],\n",
        "  #                                    fields={'difficulty_label': ('label', target_diff),\n",
        "  #                                            'question_answer': ('text',text)})\n",
        "  # test_iter = torchtext.data.Iterator(dataset=test_text, batch_size=34,train=False, sort=False, sort_within_batch=False,shuffle=False)\n",
        "# Set the batch size.  /\n",
        "  # batch_size = 34  \n",
        "\n",
        "  prediction_data = TensorDataset(input_ids, attention_masks, test_labels_tensor,test_skill_labels_tensor)\n",
        "  # Create the DataLoader.\n",
        "  prediction_sampler = SequentialSampler(prediction_data)\n",
        "  prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=32)\n",
        "  f1_bo,macro_f1_bo = get_interactive_predictions(prediction_dataloader)\n",
        "  f1_mlp,macro_f1_mlp = get_multi_task_predictions(prediction_dataloader)\n",
        "  macro_f1_multi_ensemble.append(macro_f1_mlp)\n",
        "  macro_f1_inti_ensemble.append(macro_f1_bo)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31_jaZqASy6P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "661e70fd-b971-44ba-b30e-6a22e66b3c2f"
      },
      "source": [
        "print(macro_f1_multi_ensemble)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.460443528794548, 0.4669730601865445, 0.45816721986870557, 0.4583621360511467, 0.46941458433799294]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoqkoAbaSy6Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6af05016-a365-4a74-cc37-2526d1c1c2a5"
      },
      "source": [
        "macro_f1_inti_ensemble"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.46674331176741635,\n",
              " 0.474384487358459,\n",
              " 0.4651434668782368,\n",
              " 0.4675024769108868,\n",
              " 0.469911005808828]"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ManKEa4kSy6R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0d46357-cca9-4fed-9382-d66543eaece4"
      },
      "source": [
        "from scipy import stats\n",
        "stats.ttest_rel(macro_f1_inti_ensemble,macro_f1_multi_ensemble)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ttest_relResult(statistic=4.128269164533023, pvalue=0.014514336353238679)"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPPkoifkKLxK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhb1vToRNmkx"
      },
      "source": [
        "def accuracy_per_class(preds_flat, labels_flat):\n",
        "\n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {get_labels(label)}')\n",
        "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n",
        "accuracy_per_class(flat_predictions,flat_true_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjdqIPm96UYJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Majority Voting"
      ],
      "metadata": {
        "id": "W10P9rK82085"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "    # Put model in evaluation mode\n",
        "    model.eval()\n",
        "    model_multi_task.eval()\n",
        "    model_cascade.eval()\n",
        "    model_interactive.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    predictions , true_labels,ids = [], [], []\n",
        "\n",
        "# 8 models in total\n",
        "    # Predict \n",
        "    for index,batch in enumerate(prediction_dataloader):\n",
        "      final_outputs = []\n",
        "      # Add batch to GPU\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      \n",
        "      # Unpack the inputs from our dataloader\n",
        "      b_input_ids, b_input_mask, b_labels, skill_labels = batch\n",
        "      # Telling the model not to compute or store gradients, saving memory and \n",
        "      # speeding up prediction\n",
        "      with torch.no_grad():\n",
        "          # Forward pass, calculate logit predictions\n",
        "            # print(\"multi\")\n",
        "\n",
        "          # multi task model\n",
        "          outputs,_ = model_multi_task(b_input_ids,b_input_mask)\n",
        "            # print(\"outputs\",outputs.shape,b_input_ids.shape,batch[0].shape,index)\n",
        "          final_outputs.append(outputs)\n",
        "            # print(\"cascade\")\n",
        "\n",
        "          # assuming skill is given interactive attention\n",
        "          output_skill_given = model_skill_given(b_input_ids,b_input_mask,skill_labels)\n",
        "          final_outputs.append(output_skill_given)\n",
        "\n",
        "          #bert cascade\n",
        "          output_cascade = model_cascade(b_input_ids,b_input_mask)\n",
        "          final_outputs.append(output_cascade)\n",
        "\n",
        "          # interactive bert with pretrained model for skilled prediction\n",
        "          outputs,_ = model_interactive_pre_trained(b_input_ids,b_input_mask)\n",
        "          final_outputs.append(outputs)\n",
        "\n",
        "            # print(\"normal\")\n",
        "          # output_difficulty = model(b_input_ids,b_input_mask)\n",
        "          # final_outputs.append(output_difficulty)\n",
        "\n",
        "          # interactive attention model (ours)\n",
        "          interactive_output,_ = model_interactive(b_input_ids,b_input_mask)\n",
        "          final_outputs.append(interactive_output)\n",
        "          params =dict()\n",
        "          params['lstm'] =1\n",
        "          params['gru'] = 1\n",
        "\n",
        "          # lstm plus GRU\n",
        "          out = make_lstm_and_gru_predictions(index,params)\n",
        "          final_outputs.append(out[0])\n",
        "          final_outputs.append(out[1])\n",
        "\n",
        "          # base difficulty bert model\n",
        "          output_difficulty = model(b_input_ids,b_input_mask)\n",
        "          final_outputs.append(output_difficulty)\n",
        "      # logits_2 = outputs\n",
        "      # logist_1 = output_bert[0]\n",
        "      predictions_1 = final_outputs\n",
        "      logits,_ = torch.max(torch.stack(predictions_1), dim=0)\n",
        "      # else:\n",
        "        # logits = predictions_1[0]\n",
        "      # Move logits and labels to CPU\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "      \n",
        "      # Store predictions and true labels\n",
        "      predictions.append(logits)\n",
        "      true_labels.append(label_ids)\n",
        "    flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "    flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "    # Combine the correct labels for each batch into a single list.\n",
        "    flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "    # metrics = precision_recall_fscore_support(flat_true_labels, flat_predictions, average='micro')\n",
        "    metrics = print_weighted_metrics(flat_predictions,flat_true_labels)\n",
        "    macro_metrics = print_metrics(flat_predictions,flat_true_labels)\n",
        "    print(\"macro_metrics\",macro_metrics)\n",
        "\n",
        "    print(\"weighted\",metrics)\n",
        "    print('    DONE.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHb5ELUF23GR",
        "outputId": "1207969c-f969-4561-f9bc-2ab80dd16a1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 4,577 test sentences...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning:\n",
            "\n",
            "The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "macro_metrics (0.5252243597242369, 0.4660716619455976, 0.49388312851016175)\n",
            "weighted (0.5499026145685715, 0.560847716845095, 0.5553212403284401)\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mean voting"
      ],
      "metadata": {
        "id": "6PgvQmCYEsoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "    # Put model in evaluation mode\n",
        "    model.eval()\n",
        "    model_multi_task.eval()\n",
        "    model_cascade.eval()\n",
        "    model_interactive.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    predictions , true_labels,ids = [], [], []\n",
        "\n",
        "\n",
        "    # Predict \n",
        "    for index,batch in enumerate(prediction_dataloader):\n",
        "      final_outputs = []\n",
        "      # Add batch to GPU\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      \n",
        "      # Unpack the inputs from our dataloader\n",
        "      b_input_ids, b_input_mask, b_labels, skill_labels = batch\n",
        "      # Telling the model not to compute or store gradients, saving memory and \n",
        "      # speeding up prediction\n",
        "      with torch.no_grad():\n",
        "          # Forward pass, calculate logit predictions\n",
        "            # print(\"multi\")\n",
        "          outputs,_ = model_multi_task(b_input_ids,b_input_mask)\n",
        "            # print(\"outputs\",outputs.shape,b_input_ids.shape,batch[0].shape,index)\n",
        "          final_outputs.append(outputs)\n",
        "            # print(\"cascade\")\n",
        "          output_skill_given = model_skill_given(b_input_ids,b_input_mask,skill_labels)\n",
        "          final_outputs.append(output_skill_given)\n",
        "          output_cascade = model_cascade(b_input_ids,b_input_mask)\n",
        "          final_outputs.append(output_cascade)\n",
        "          outputs,_ = model_interactive_pre_trained(b_input_ids,b_input_mask)\n",
        "          final_outputs.append(outputs)\n",
        "\n",
        "            # print(\"normal\")\n",
        "          # output_difficulty = model(b_input_ids,b_input_mask)\n",
        "          # final_outputs.append(output_difficulty)\n",
        "          interactive_output,_ = model_interactive(b_input_ids,b_input_mask)\n",
        "          final_outputs.append(interactive_output)\n",
        "          params =dict()\n",
        "          params['lstm'] =1\n",
        "          params['gru'] = 1\n",
        "          out = make_lstm_and_gru_predictions(index,params)\n",
        "          final_outputs.append(out[0])\n",
        "          final_outputs.append(out[1])\n",
        "          output_difficulty = model(b_input_ids,b_input_mask)\n",
        "          final_outputs.append(output_difficulty)\n",
        "      # logits_2 = outputs\n",
        "      # logist_1 = output_bert[0]\n",
        "      predictions_1 = final_outputs\n",
        "      logits = torch.mean(torch.stack(predictions_1), dim=0)\n",
        "      # else:\n",
        "        # logits = predictions_1[0]\n",
        "      # Move logits and labels to CPU\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "      \n",
        "      # Store predictions and true labels\n",
        "      predictions.append(logits)\n",
        "      true_labels.append(label_ids)\n",
        "    flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "    flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "    # Combine the correct labels for each batch into a single list.\n",
        "    flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "    # metrics = precision_recall_fscore_support(flat_true_labels, flat_predictions, average='micro')\n",
        "    metrics = print_weighted_metrics(flat_predictions,flat_true_labels)\n",
        "    macro_metrics = print_metrics(flat_predictions,flat_true_labels)\n",
        "    print(\"macro_metrics\",macro_metrics)\n",
        "\n",
        "    print(\"weighted\",metrics)\n",
        "    print('    DONE.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW217ax166ZA",
        "outputId": "0a307faf-53e2-4a9c-eaa2-8f5041ed8e14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 4,577 test sentences...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning:\n",
            "\n",
            "The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "macro_metrics (0.5471735665240417, 0.4572675311906578, 0.49819687081004643)\n",
            "weighted (0.5652408564340834, 0.5724273541621149, 0.5688114072262386)\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "r3y0fTWuErkO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}